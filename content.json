{"meta":{"title":"来杯冰镇可乐","subtitle":"","description":"","author":"lvtao","url":"http://yoursite.com","root":"/"},"pages":[{"title":"所有分类","date":"2020-09-29T01:49:01.545Z","updated":"2020-04-12T05:48:42.451Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"多线程(八) Lock","slug":"Lock","date":"2020-03-09T05:00:00.000Z","updated":"2020-09-18T03:20:45.272Z","comments":true,"path":"2020/03/09/Lock/","link":"","permalink":"http://yoursite.com/2020/03/09/Lock/","excerpt":"Lock的实现原理。","text":"Lock的实现原理。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(八) AQS","slug":"AQS","date":"2020-03-08T05:00:00.000Z","updated":"2020-09-16T07:06:57.664Z","comments":true,"path":"2020/03/08/AQS/","link":"","permalink":"http://yoursite.com/2020/03/08/AQS/","excerpt":"AQS的实现原理。","text":"AQS的实现原理。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(七) synchronized关键字","slug":"synchronized关键字","date":"2020-03-07T05:00:00.000Z","updated":"2020-09-30T04:32:55.564Z","comments":true,"path":"2020/03/07/synchronized关键字/","link":"","permalink":"http://yoursite.com/2020/03/07/synchronized%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"synchronized锁的实现原理。","text":"synchronized锁的实现原理。 简介如果我们想要保证单个共享变量的原子操作，可以借助CAS来实现，当我们想要保证多个共享变量的原子操作时，那就要把对多个变量的操作代码整合在一起建立临界区，临界区同一时刻只能有一个线程访问。而synchronized关键字就是java老牌的互斥锁，保证操作的原子性、可见性、有序性，同时还保证锁的可重入性。 synchronized使用 修饰方法的时候，如果是普通方法，加锁目标是此实例对象(new出来的、存放在堆中的某个对象) 修饰方法的时候，如果是静态方法，加锁目标是当前类的class对象(存在方法区的类结构对象) 修饰代码块的时候，需要指定某个实例对象或class对象作为加锁目标 jvm对象头无论哪种方式实现线程同步，都必须指定一个对象并获得此对象的锁才有资格执行同步方法或代码块，synchronized的实现完全依赖于jvm，因此理解synchronized的底层实现，就必须理解对象在jvm是如何存储的，关于锁的那部分数据信息又是如何维护的。 在JVM虚拟机中，对象在内存中的存储布局，一般情况下分为三个区域： 对象头(包括标记字段、类型指针) 实例数据(存储对象自身定义的数据) 对齐填充(jvm要求对象的内存大小必须是8字节整倍数，对齐填充用于补全大小到整倍数) 如果对象是数组，还会有个区域记录数组的长度，用于判断数组对象的内存大小 有关对象锁的数据全部存储在对象头区域中，我们使用java提供的jol工具来看看对象的头部信息详细结构(测试为64位操作系统): 1.先添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jol-core&lt;&#x2F;artifactId&gt; &lt;version&gt;0.9&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 2.创建测试用对象 12345678910111213141516171819public class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name &#x3D; name; this.age &#x3D; age; &#125; public synchronized void doSomething()&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; ... &#125; &#125;&#125; 3.执行main方法 1234public static void main(String[] args) &#123; Person person &#x3D; new Person(&quot;李逍遥&quot;,18); System.out.println(ClassLayout.parseInstance(person).toPrintable());&#125; 4.打印结果 表头代表的含义： 列名 描述 OFFSET 偏移地址，单位字节 SIZE 占用的内存大小，单位字节 TYPE DESCRIPTION 类型描述，其中object header为对象头类型 VALUE 类型对应的值 颜色标记区域代表的含义： 区域 描述 红色 标记字段，内部结构比较复杂，而且会不断变化，下面单独讲 蓝色 类型指针，通常由64位组成，但是我们jvm会默认对其压缩到32位，因此占用4字节 绿色 实例数据，基本数据类型会直接打印值，引用数据类型显示(object) 黄色 对齐填充，图中对象占用总内存为20字节，因此对齐填充补了4字节确保是8字节倍数 与synchronized底层原理关联最为密切的就是红色区域了，这个区域也比其他区域更为复杂一点，标记字段拥有8字节的内存大小(也就是64位)，对象锁状态的不同，这64位存储的内容也不同： 标记字段中存储的信息： hash:存储对象哈希码，只有在调用hashCode()方法的时候才会生成，默认是没值的 age:jvm分代年龄，用于判断是否晋升老年代 biased_lock:偏向锁标识位 lock:锁状态标识位 JavaThread:保存持有偏向锁的线程ID epoch:保存偏向时间戳 Pointer to Lock Record:指向线程栈中锁记录的地址 Pointer to Monitor:指向jvm监控对象的地址 无锁状态所谓无锁状态，就是对象还没有被加过锁，也就是说内部的synchronized修饰的方法还没有任何线程调用过，上面打印的截图是没有调用hashCode()方法的，我们写个调用hashCode()方法的测试代码： 123456public static void main(String[] args) &#123; Person person &#x3D; new Person(&quot;李逍遥&quot;,18); System.out.println(&quot;哈希码:&quot; + person.hashCode()); System.out.println(ClassLayout.parseInstance(person).toPrintable());&#125; 打印结果： 原图不好标注，重新做了一张： 2进制数据我们要从右往左看，然后从下往上看。 偏向锁偏向锁是jdk1.6引入的一项锁优化，意思是偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。 JVM启动时会进行一系列的复杂活动，比如装载配置，系统类初始化等等。在这个过程中会使用大量synchronized关键字对对象加锁，且这些锁大多数都不是偏向锁。为了减少初始化的时间，JVM默认采用延时加载偏向锁的机制，大概4秒左右，应用程序(包括main方法)刚启动的时候直接调用同步代码块，对象锁升级会忽略偏向锁直接升级到轻量级锁。因此我们想要看到偏向锁的头信息，增加jvm启动参数取消延迟加载:-XX:BiasedLockingStartupDelay=0 我们写个测试类: 12345public static void main(String[] args) &#123; Person person &#x3D; new Person(&quot;李逍遥&quot;,18); person.doSomething(); System.out.println(ClassLayout.parseInstance(person).toPrintable());&#125; 打印结果: 标注: 偏向锁工作流程图: 第一次看到这个图的时候十分懵逼，如果线程A获取偏向锁成功，在执行同步方法(或代码块)期间，线程B试图访问同步方法(或代码块)，此时使用CAS修改JavaThread是必然成功的(因为现在没其他线程修改JavaThread)，那岂不2个线程同时访问同步方法(或代码块)了？ 只有在001状态下试图升级偏向锁的时候才会进行CAS，多个线程对无锁状态的字段标记CAS只有一个会成功，其他失败的再次尝试时，发现已经升级为偏向锁(101)此次CAS直接失败，开始偏向锁撤销。安全点为jvm时间暂停 轻量级锁重量级锁synchronized优缺点","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"多线程(六) 锁分类","slug":"锁分类","date":"2020-03-06T05:00:00.000Z","updated":"2020-09-29T05:52:44.415Z","comments":true,"path":"2020/03/06/锁分类/","link":"","permalink":"http://yoursite.com/2020/03/06/%E9%94%81%E5%88%86%E7%B1%BB/","excerpt":"java中五花八门的锁","text":"java中五花八门的锁 前言java中的锁可谓是五花八门，各种锁功能相似又不同，有的是概念、有的是java接口、有的是实现类，让你很难找到明显的分界线去区分并记住他们。所以学习锁首先要打消一种想法，就是一个锁只属于一个分类，比如一个锁可以同时是乐观锁、可重入锁，公平锁，就像一个人可以是男人、程序员、健身爱好者。 synchronized与Lockjava代码中两种加锁方式 一种是用synchronized关键字，另一种是用Lock接口的实现类。形象地说，synchronized关键字是自动档，可以满足一切日常驾驶需求。但是如果你想要玩漂移或者各种骚操作，就需要手动档了——各种Lock的实现类，因为Lock的实现类可以通过设置不同的参数改变锁的作用达到灵活适应场景的作用，而synchronized是关键字，底层有jvm实现，很多参数都是写死的。 悲观锁与乐观锁锁的一种宏观分类方式是悲观锁和乐观锁。悲观锁与乐观锁并不是特指某个锁(Java中没有哪个Lock实现类就叫PessimisticLock或OptimisticLock)，而是在并发情况下的两种不同策略。 悲观锁(Pessimistic Lock)，就是很悲观，每次去拿数据的时候都认为别人会修改。所以每次在拿数据的时候都会上锁，这样别人想拿数据就被挡住，直到悲观锁被释放。比如上面说的synchronized与Lock。 乐观锁(Optimistic Lock), 就是很乐观，每次去拿数据的时候都认为别人不会修改。所以不会上锁，这里的上锁是指互斥性质的上锁，在说明白点就是我加锁了谁也别想碰，除非我释放锁，乐观锁采用的是类似CAS的方式，保证操作数据不会干扰到其他线程。 悲观锁阻塞事务，乐观锁回滚重试，它们各有优缺点，不要认为一种一定好于另一种。像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行重试，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 自旋锁有一种锁叫自旋锁。所谓自旋，说白了就是一个** while(true) ** 无限循环。这个自旋锁与Atomic类的while实现的自旋代码不是一回事，下一章AQS会详细讲 synchronized锁升级：偏向锁 → 轻量级锁 → 重量级锁前面提到synchronized关键字就像是汽车的自动档。一脚油门踩下去，synchronized会从无锁升级为偏向锁，再升级为轻量级锁，最后升级为重量级锁，就像自动换挡一样。那么自旋锁在哪里呢？这里的轻量级锁就是一种自旋锁。 初次执行到synchronized代码块的时候，锁对象变成偏向锁(通过CAS修改对象头里的锁标志位，说明白点就是锁记住了第一次和他发生关系的线程)，字面意思是“偏向于第一个获得它的线程”的锁，执行完同步代码块后，线程并不会主动释放偏向锁。第二次访问如果还是此线程，那么就没有加锁释放锁这一说，正常执行。 一旦有第二个线程加入锁竞争并发现锁是偏向锁，会去断线程A是否仍然存活。如果线程A仍然存活，将线程A暂停，此时偏向锁升级为轻量级锁，之后线程A继续执行，线程B自旋。但是如果判断结果是线程A不存在了，则线程B持有此偏向锁，锁不升级。 在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。 自旋锁避免不了的问题就是竞争特别激烈的情况下，其他线程只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做**忙等(busy-waiting)**。显然，此忙等是有限度的(有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改)。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁(依然是CAS修改锁标志位，但不修改持有锁的线程ID)。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起(而不是忙等)，等待将来被唤醒。在JDK1.6之前，synchronized直接加重量级锁，很明显现在得到了很好的优化。 一个锁只能按照 偏向锁、轻量级锁、重量级锁的顺序逐渐升级(也有叫锁膨胀的)，不允许降级。 可重入锁(递归锁)可重入锁的字面意思是“可以重新进入的锁”，即允许同一个线程多次获取同一把锁。比如一个递归函数里有加锁操作，递归过程中这个锁会阻塞自己吗？如果不会，那么这个锁就是可重入锁(因为这个原因可重入锁也叫做递归锁)。 公平锁、非公平锁如果多个线程申请一把公平锁，那么当锁释放的时候，先申请的先得到，非常公平。显然如果是非公平锁，后申请的线程可能先获取到锁，是随机或者按照其他优先级排序的。 对ReentrantLock类而言，通过构造函数传参可以指定该锁是否是公平锁，默认是非公平锁。一般情况下，非公平锁的吞吐量比公平锁大，如果没有特殊要求，优先使用非公平锁。对于synchronized而言，它也是一种非公平锁，但是并没有任何办法使其变成公平锁。 可中断锁这里的关键是理解什么是中断。Java并没有提供任何直接中断某线程的方法，只提供了中断机制。何谓“中断机制”？线程A向线程B发出“请你停止运行”的请求(线程B也可以自己给自己发送此请求)，但线程B并不会立刻停止运行，而是自行选择合适的时机以自己的方式响应中断，也可以直接忽略此中断。也就是说，Java的中断不能直接终止线程，而是需要被中断的线程自己决定怎么处理。这好比是父母叮嘱在外的子女要注意身体，但子女是否注意身体，怎么注意身体则完全取决于自己。 读写锁、共享锁、互斥锁读写锁其实是一对锁，一个读锁(共享锁)和一个写锁(互斥锁、排他锁)，Java提供了ReadWriteLock接口和实现类ReentrantReadWriteLock来实现读写锁。 读锁：防止读的时候其他线程写，允许读的时候其他线程读 写锁：防止写的时候其他线程读或写 使用锁带来的问题死锁、活锁、饥饿","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(五) CAS","slug":"CAS","date":"2020-03-05T05:00:00.000Z","updated":"2020-09-29T05:52:04.503Z","comments":true,"path":"2020/03/05/CAS/","link":"","permalink":"http://yoursite.com/2020/03/05/CAS/","excerpt":"CAS在CPU的实现，以及Java对CAS的封装","text":"CAS在CPU的实现，以及Java对CAS的封装 什么是CASCAS的全称是Compare and Swap(比较和交换)，是一种特殊的修改数据的方式，线程通过CAS修改数据时整个过程涉及到三个数据：要修改的内存数据V、执行CAS操作前读取V并将V的值复制到工作空间计作A(预期值)、修改后的数据B，执行CAS操作中当且仅当预期值A和内存值V相同时，将内存值V修改为B并返回true，否则视为修改失败返回false。 Atomic对CAS的应用Atomic包是Java.util.concurrent下的另一个专门为线程安全设计的Java包，包含多个原子操作类，我们以AtomicInteger为例看看java如何通过CAS实现原子性。 incrementAndGet方法，以原子方式将当前值增加1并返回增加后的值： 1234public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 我们发现incrementAndGet方法把这个操作委托给unsafe类的getAndAddInt方法处理，我们继续看getAndAddInt方法源码： 123456789101112public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; &#x2F;&#x2F; 读取AtomicInteger在内存中对应的值，并复制一份赋值给var5，作为期望值 var5 &#x3D; this.getIntVolatile(var1, var2); &#x2F;&#x2F; 将AtomicInteger对象引用、偏移量、预期值、修改后的值交给compareAndSwapInt也就是CAS方法循环执行，直到true &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 代码中我们可以看到，真正的CAS修改操作是compareAndSwapInt方法，我们继续往下看： 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 到这里的时候我们发现compareAndSwapInt方法是被native修饰的，说明接下来的代码是使用C++实现的了。源码就不贴了，这个方法实际上是利用处理器提供的汇编指令CMPXCHG。当CPU执行此修改指令时发现带有CMPXCHG前缀，那么会采用CAS方式(比较并交换操作数)修改数据，并且保证比较、交换俩个步骤不会被上下文切换打断。当且仅当预期值var4与要修改的内存值相等时，将内存值修改为var5。 如果你细心的话会发现，在多核CPU的操作系统中仅仅保证CAS的俩个步骤不被上下文切换打断没什么卵用，如果俩个线程并行同时对某个AtomicInteger(0)执行incrementAndGet方法，怎么保证高速缓存中取出的期望值不是脏数据？怎么保证多个处理器不会同时执行到CAS的比较操作并且都返回true，继而同时修改内存值为1，最终导致结果应该是2却因为线程安全问题变为1？ 我们回头看看AtomicInteger的其他源码： 12345678910111213141516... private volatile int value; public AtomicInteger(int initialValue) &#123; value &#x3D; initialValue; &#125; public AtomicInteger() &#123; &#125; public final int get() &#123; return value; &#125; ... AtomicInteger内部有个int类型的value属性，代表着自身的值，并且AtomicInteger读写操作都是围绕这个值进行的，并且这个类被volatile修饰的。到这里思路就清晰了，volatile修饰符保证了value值的可见性，线程不会出现读到脏数据的情况。 对于第二种情况百度的资料很少提及，所以也无法确定CPU到底如何解决这个问题。但是我在知乎上看到了俩个感觉还算靠谱的答案。首先被volatile修饰的变量会使用MESI协议确保同一时刻只有一个处理器修改值，并且把其他处理器此值的缓存设为无效，当第二个处理器想要修改值时发现无效，CAS操作失败，返回false，另一个答案则表示当多个处理器同时使用cmpxchg指令(也就是CAS)操作同一个数据时，总线会进行仲裁只有一个处理器执行CAS，其他处理器连比较操作都不会执行，直到上一个处理器执行完毕后总线再次仲裁并选中自己。 第一种答案强调使用MESI的失效机制解决问题，第二种答案则强调将CAS视为一个整体，在执行比较操作的时候就会利用MESI协议将数据修改为M状态。不同的CPU架构可能解决问题的方式也不同，总之CPU保证多处理器并行执行CAS不会出错，Java保证volatile+自旋CAS修改数据的原子性，以后搞懂了再更新。 ABA问题我实在是不想写这个问题，我也想不到ABA会带来什么后果，通过CAS修改数据也想不到啥业务场景需要记录修改了多少次，百度一堆人云亦云此A非彼A瞎鸡吧复制，就是讲不明白此A和彼A到底有啥区别。但是Java在1.5版本引进了AtomicStampedReference类，采用版本号的机制解决这个操蛋的问题。 总结 CAS是典型的乐观派操作，每次都迷之自信认为操作一定成功，但是在高并发比较严重的情况下会导致大量线程不断的循环，增大CPU的消耗。 CAS只能保证单个共享变量的原子操作，如果操作涉及多个共享变量，必须要排他锁解决 仅仅依靠CAS无法保证原子性，必须配合CPU缓存锁一起保证。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(四) volatile关键字","slug":"volatile关键字","date":"2020-03-04T05:00:00.000Z","updated":"2020-09-29T05:51:44.441Z","comments":true,"path":"2020/03/04/volatile关键字/","link":"","permalink":"http://yoursite.com/2020/03/04/volatile%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"volatile关键字的实现原理。","text":"volatile关键字的实现原理。 概述volatile是Java的一个修饰符，它在多线程编程开发中保证了共享变量的可见性和有序性。相对于各种排他锁，volatile在使用和执行成本上占用资源较少。 实现原理那么volatile如何保证可见性和有序性呢？我们写一段单例模式的java代码： 123456789101112131415161718192021package com.test;public class SingletonObject &#123; &#x2F;&#x2F; 单例对象 private static volatile SingletonObject instance; &#x2F;&#x2F; 获取单例对象方法 public static SingletonObject get()&#123; if(instance &#x3D;&#x3D; null)&#123; instance &#x3D; new SingletonObject(); &#125; return instance; &#125; public static void main(String[] args) &#123; SingletonObject.get(); &#125;&#125; 然后用idea运行main方法并打印汇编代码，jvm参数：-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly-XX:CompileCommand=compileonly,*SingletonObject.get (只打印SingletonObject的get方法) 运行打印结果： 1234567891011121314# &#123;method&#125; &#123;0x0000000128e022b0&#125; &#39;get&#39; &#39;()Lcom&#x2F;test&#x2F;SingletonObject;&#39; in &#39;com&#x2F;test&#x2F;SingletonObject&#39;# [sp+0x40] (sp of caller) 省略代码..... 0x000000010af1fb54: movb $0x0,(%rax,%rsi,1) 0x000000011b6f4e58: lock addl $0x0,(%rsp) ;*putstatic instance ; - com.test.SingletonObject::get@13 (line 12) 省略代码..... 0x000000010af1f701: mov %r12b,(%r11,%r10,1) 0x000000011b6f4a05: lock addl $0x0,(%rsp) ;*putstatic instance ; - com.test.SingletonObject::get@13 (line 12) 省略代码..... 我们可以看到被volatile修饰的共享变量进行写操作的时候，会比普通公共变量的读写操作多一行lock addl $0x0,(%rsp)前缀的代码，lock前缀指令有俩个作用： 使用总线锁或缓存一致性协议来保证数据的可见性。 不是内存屏障却能完成类似内存屏障的功能，阻止屏障两遍的指令重排序保证有序性。 总结volatile的使用场景不是很多，常用在多线程下的状态标记量和双重检查等，也有很多地方配合CAS来实现无锁编程。因为volatile只能保证线程每次拿到的数据是最新的，对于数据的单纯查询没有任何问题(jvm自动保证基本数据类型和引用的取值赋值为原子操作)，但是对于i++、懒汉式单例模式等对变量操作依赖当前值的情况，就显得无能为力。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(三) 生命周期和常用方法","slug":"多线程生命周期和常用方法","date":"2020-03-03T05:00:00.000Z","updated":"2020-09-29T05:51:20.998Z","comments":true,"path":"2020/03/03/多线程生命周期和常用方法/","link":"","permalink":"http://yoursite.com/2020/03/03/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%92%8C%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"线程七种状态以及转化、常用方法","text":"线程七种状态以及转化、常用方法 线程状态以及转化NEW(新建) 使用new创建出线程后，进入新建状态 此时jvm为其分配内存以及其成员变量 除此之外没有任何特征，方法也不会被执行 RUNNABLE(就绪) 调用对象的start()方法，进入就绪状态 此时jvm会为其创建方法调用栈和程序计数器 线程拥有被CPU调度资格，开始疯狂争夺使用权 RUNNING(运行) 抢到CPU使用权时，开始执行run()方法，进入运行状态 线程只有通过start()后争夺到CPU时间片的方式运行run()方法，才可以实现异步执行 如果直接调用run()方法运行，系统会当作普通方法，不会异步执行 BLOCKED(阻塞) 处于运行状态的线程在进入synchronized关键字修饰的方法或代码块时，进入阻塞状态 阻塞的过程就是线程在抢夺锁的过程，因此阻塞是被动的 阻塞在某个锁上的线程，在锁被释放后会主动去争取，争取到锁后回到运行状态，因此脱离阻塞状态是主动的 WAITING(等待) 调用wait()、join()方法时，进入等待状态 因此进入等待状态是主动的，需要有事件主动唤醒 TIMED_WAITING(等待) 调用sleep(long)、wait(long)、join(long)方法时，进入超时等待状态 同等待状态，到达参数指定时间自动唤醒 TERMINATED(终止) run()方法或call()方法运行完毕，线程正常结束 线程执行代码过程中抛出未捕获异常或直接ERROR 调用stop()方法，也是个奇葩的方法，不推荐使用 附加状态转化图： 类型转化。 isAlive()1public final native boolean isAlive(); 判断当前线程是否活着，只有当线程进入RUNNABLE(就绪)或RUNNING(运行)状态才返回true。 sleep(long millis)1public static native void sleep(long millis) throws InterruptedException; Thread的静态方法，使当前线程放弃CPU时间片，在指定时间内不参与CPU竞争，在到达指定时间后变为runnable状态并重新加入CPU竞争。如果当前线程持有锁，在睡眠过程中不会放弃锁的占有权 join(long millis)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#x2F;&#x2F; 无参方法，调用重载方法传入固定参数0public final void join() throws InterruptedException &#123; join(0);&#125;&#x2F;&#x2F; 支持超时的join方法public final synchronized void join(long millis) throws InterruptedException &#123; &#x2F;&#x2F; 获取当前时间戳 long base &#x3D; System.currentTimeMillis(); &#x2F;&#x2F; 记录已经延迟多久 long now &#x3D; 0; &#x2F;&#x2F; 参数校验，不能小于0 if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; &#x2F;&#x2F; 没有超时限制情况下 if (millis &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 线程只有处于活着状态才进行处理 while (isAlive()) &#123; &#x2F;&#x2F; 这里意味着调用此方法的线程直接被wait方法挂起，没有提供任何notify方法唤醒，只能被动的等待线程运行完毕后死亡 wait(0); &#125; &#125; else &#123; &#x2F;&#x2F; 线程只有处于活着状态才进行处理 while (isAlive()) &#123; &#x2F;&#x2F; 还需要延迟多久 long delay &#x3D; millis - now; &#x2F;&#x2F; 如果已达到延迟时间限制，跳出循环 if (delay &lt;&#x3D; 0) &#123; break; &#125; &#x2F;&#x2F; 挂起进入等待状态 wait(delay); &#x2F;&#x2F; 执行到这里说明等待时间已到，重新计算已经延迟多久了，等待下一次进入while循环调用break now &#x3D; System.currentTimeMillis() - base; &#125; &#125;&#125; 源码可以看出来join是用的wait()实现的，wait方法是object的方法，作用是让调用这个Object.wait()的线程处于等待状态，除非其他线程调用这个Object.notify()唤醒，或者这个Object死亡阻塞状态才会变成可运行状态，如果join方法带参数，那就等到参数时间结束自动唤醒自己。 如果在一个线程执行中创建另外一个线程并使用join()，那么主线程会被挂起，等待子线程执行完在继续往下执行。说白了和执行过程中调用另一个方法没什么区别，无非就是有个超时时间限制，超过时间限制主线程就取消等待继续执行。使用isAlive()进行判断，也就意味着线程如果没有进入RUNNABLE(就绪)或RUNNING(运行)状态，join方法不会起任何作用。 yield()1public static native void yield(); Thread的静态方法，暂停当前正在执行的线程对象，并执行其他线程。被暂停的线程会让出CPU的使用权给其他线程获得运行机会，自身转化为RUNNABLE(就绪)状态，但是这么做并不一定能达到让出CPU资源的目的，因为让出CPU使用权的时候，自身回到可运行状态与其他同优先级线程一起再去竞争CPU时间片，如果这个线程是个欧皇还会被再次选中，出现这种情况也就意味着此次yield()方法并没有任何效果。 目前想不到什么应用场景，如果一个线程的优先级特别低，执行内容也不是很重要，又怕他被CPU调度的次数多，可以适当的调用此方法减少执行的次数，把CPU资源给其他重要的线程工作。 interrupt()1234567891011121314151617public void interrupt() &#123; &#x2F;&#x2F;如果调用中断的是线程自身，则不需要进行安全性判断 if (this !&#x3D; Thread.currentThread()) checkAccess(); &#x2F;&#x2F; synchronized (blockerLock) &#123; Interruptible b &#x3D; blocker; if (b !&#x3D; null) &#123; interrupt0(); &#x2F;&#x2F; 只是设置中断标志 b.interrupt(this); return; &#125; &#125; interrupt0();&#125; 每个线程内部都维护了一个中断标志(默认false)，调用线程的interrupt()方法时会根据当前线程的中断标志和阻塞情况，判断是否需要抛出异常： 如果中断标志为false，且没有被阻塞，修改中断标志为true。 如果中断标志为true，此时调用wait、sleep、join方法时会抛出InterruptedException异常，恢复中断标志为false。 如果已经被wait、sleep、join方法阻塞，调用interrupt()会抛出InterruptedException异常，恢复中断标志为false。 这里提到的阻塞，只是因为wait、sleep、join方法导致线程被堵住无法继续执行，并不是线程七大状态的BLOCKED(阻塞)状态。BLOCKED(阻塞)状态只由synchronized导致，而且不能被打断，相同的，IO阻塞也不能被打断。 由此可以看出来interrupt()方法中断的不是线程的运行，而是中断线程的阻塞状态，并且采用抛异常的方式引起线程的注意，被中断线程可以通过try catch方式自己决定如何应对中断信号。 比如使用kafka采用while(true)的方式消费数据时，又希望在某个时刻终止这个线程，并且终止过程中要保证此刻正在处理的那条消息处理完毕后才能终止，可以采用interrupt()方法+wait、sleep、join的一种来实现： 1234567891011121314151617181920212223242526272829303132public void run()&#123; &#x2F;&#x2F; 创建消费者 Properties props &#x3D; createProperties(&quot;localhost:9092&quot;, &quot;groups&quot;); props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;); KafkaConsumer&lt;String, String&gt; consumer &#x3D; new KafkaConsumer&lt;&gt;(props); &#x2F;&#x2F; 设置消费topic consumer.subscribe(Arrays.asList(&quot;topic-name&quot;)); while (true) &#123; &#x2F;&#x2F; 每次拉取消息 ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(100); &#x2F;&#x2F; 循环处理 for (ConsumerRecord&lt;String, String&gt; record : records) &#123; &#x2F;&#x2F; 消费逻辑.. &#x2F;&#x2F; wait或sleep或join阻塞1毫秒，试探线程有没有被中断 try &#123; Thread.wait(1); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; 关闭消费者对象 consumer.close(); return; &#125; &#125; &#125;&#125; stop()强制终止线程的运行，并立即释放掉此线程持有的锁，这些锁可能用来维护数据一致性的，所以此方法被废弃。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(二) 并发编程三大特性","slug":"并发编程三大特性","date":"2020-03-02T05:00:00.000Z","updated":"2020-09-29T05:50:35.763Z","comments":true,"path":"2020/03/02/并发编程三大特性/","link":"","permalink":"http://yoursite.com/2020/03/02/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7/","excerpt":"JMM在并发编程中，对共享变量读写的原子性、可见性、一致性。","text":"JMM在并发编程中，对共享变量读写的原子性、可见性、一致性。 CPU读写内存数据计算机中程序的执行，本质上是线程指令在CPU处理器上的执行，并且在执行必然牵涉到数据的读和写，程序运行过程的临时数据都是存放在主内存(RAM)中，因此CPU在处理数据的时候也必然牵涉到和主内存的交互。处理器访问内存时，需要先获取内存总线的控制权，任何时刻只能有一个处理器获得内存总线的控制权，可以理解为同一时刻某个内存地址只可能被一个处理器访问。 随着硬件技术的不断发展，现在的CPU处理速度已经远远超过主内存的访问速度，如果任何时候对数据的操作都要和内存进行交互，会大大降低指令的执行速度，因此就有了CPU高速缓存： 高速缓存的产生大大减少了CPU直接访问主内存的频率，也减少了内存访问速度对CPU的拖累，提高了CPU的执行效率。如果是单核CPU的操作系统中，只有一个高速缓存，没有任何问题。但是在多核CPU的操作系统中，每个处理器都有自己的高速缓存，就带来了缓存一致性问题。 比如i++操作，编译成指令后大概有三步骤：1.将i=0从主内存复制到2.对i进行加1运算3.将运算后的值刷回 在多线程编程情况下，如果我们不做任何措施，会导致运行结果与预期不一致： 对此，早期的解决方案是总线加锁，一个处理器在总线上输出LOCK#信号，使得其他处理器对内存的操作请求都会被阻塞，该处理器独占共享内存。方法简单粗暴，就是锁定范围太大(整个共享内存)，导致CPU利用率急剧下降。 为了解决总线锁开销过大问题，CPU提出了缓存一致性解决方案，主要有Directory协议、Snoopy协议、MESI协议。这个说下MESI协议，这个协议只会对高速缓存中的某个数据加锁(如果数据不在缓存中，还是会总线加锁)，不会影响到内存中其他数据的读写。MESI协议将数据划分为四种状态，通过总线嗅探机制让所有处理器监听数据状态的变化，缓存一致的目的。 我们重点关注一下修改缓存数据的情况，对于E状态的数据，只有自己在读，可以直接把数据设置为M状态，对于S状态的数据，说明有多个处理器在读，必须将其他处理器对此数据的缓存作废，然后才能把数据的状态设置为M。当其他处理器发现自己的缓存是I状态时，就去主内存再次读取，而MESI协议保证其他处理器去主内存读取此数据前，将修改后的数据从高速缓存刷回主内存，并把数据状态改为E。 高并发情况下可能出现俩个处理器同时修改变量，并同时向总线发出将各自的缓存行更改为M状态的情况，此时总线会采取裁决机制进行裁决，将其中一个置为M状态，另一个置为I状态，且I状态的缓存行修改无效。 原子性原子性操作是指一个或多个操作，要么全部执行且在执行过程中不被任何因素打断，要么全部不执行。并且针对某个值的原子操作在被执行的过程中，CPU绝不会再去进行其他的针对该值的操作 java作为一门高级语言，一个可执行线程会被编译成多条指令序列交由CPU执行，既然是多条指令，在执行过程中就存在被上下文切换打断的可能。在多线程编程中如果有的操作不具有原子性，会导致运行结果与预期的不一致，比如i++操作： CPU如何保证原子性？首先，处理器自动保证单条指令、基本内存操作的原子性，因此中断只会发生在指令之间。在单核CPU中保证操作原子性非常简单，只要禁止CPU在原子操作过程中发生上下文切换，那么就可以保证多线程对某个公共变量的多步骤操作都是串行的。嗯，有点线程安全的味道了。到了多核CPU时代，仅仅保证原子操作的执行不被CPU打断已经没什么卵用了，因为多个线程可以并行执行修改一个公共变量，线程之间又出现了干扰。对此，CPU又提出了CAS来解决这个问题(CAS下一章会讲)。 Java自带的原子性操作： 基本数据类型的赋值(long、double无法保证) 所有引用类型的赋值 synchronized关键字(采用jvm的monitor，monitor底层采用CPU的CAS) Lock相关类(采用aqs，aqs底层采用CPU的CAS) java.concurrent.Atomic包下所有类(采用CPU的CAS) 注:CPU和Java(内存读写)的原子性与数据库的原子性还是有区别的，CPU和Java(内存读写)执行原子操作过程中发生中断的唯一可能就是断电，这时候所有内存数据全部消失，也就没讨论的意义了。而数据库的增删改操作涉及的都是持久化的磁盘数据，就算执行过程发生断电，持久化的数据仍然存在，因此数据库的原子操作增加了事务回滚概念，只要事务没提交，就相当于没执行。无论CPU还是Java还是数据库，都是强调整体的成败，不允许仅执行部分操作的存在。 可见性可见性是指一个线程对共享变量的修改，其他线程可以立即感知到这个变化 可见性问题主要发生在多核CPU的场景中，如果线程对数据的读取都是通过内存实现，不会有任何可见性问题，因为上面说过某个内存地址任何时刻只会被一个处理器访问，但是高速缓存的诞生打破了这个规则，如果高速缓存中存在就从缓存访问，这就意味着某个内存数据可以被多个处理器同时访问。处理器对数据的修改在没有做任何措施的情况下，不会及时通知到其他处理器的缓存，这就导致其他处理器的数据是脏数据。比如i++操作： CPU如何保证可见性？这个很明显了，MESI缓存一致协议。 Java自带的可见性操作： volatile关键字(采用MESI协议保证，如果数据不在缓存中就用总线锁) synchronized关键字(同一时刻就一个线程操作，还有啥不可见的) Lock相关类(跟synchronized一个套路) 有序性有序性是指程序按照写代码的顺序执行 处理器和编译器为了提高程序运行效率，可能会对输入代码进行优化，并且不保证程序中各个语句的执行先后顺序同代码中的顺序一致。当然，CPU和编译器是在遵循as-if-serial语意的前提下对指令重排，而不是随意重排。首先CPU保证调度线程过程中，单线程的执行结果不会受指令重排影响导致结果不一致，编译器保证编译过程中不会对有依赖关系的数据进行指令重排。由此看出多线程情况下还是会有问题： CPU如何保证有序性？处理器主要通过内存屏障机制来解决有序性问题，如果不想让它重排，在两条指令中间加一道屏障。拿X86平台来说，有几种主要的内存屏障： lfence，是一种Load Barrier(读屏障)，在lfence指令前的所有读操作当必须在lfence指令后的所有读操作前完成 sfence, 是一种Store Barrier(写屏障)，在sfence指令前的所有写操作当必须在sfence指令后的所有写操作前完成 mfence, 是一种General Barrier(通用屏障)，在mfence指令前的所有读写操作当必须在mfence指令后的所有读写操作前完成 除了内存屏障，也可以使用原子指令，如x86上的”lock…”前缀 Java自带的有序性操作： volatile关键字(内存屏障) synchronized关键字(单线程操作，as-if-serial语意自动保证) Lock相关类(单线程操作，as-if-serial语意自动保证) 总结原子性、可见性、有序性问题是一切线程安全问题的根源，单纯的保证操作具有某一种特性只能解决某一部分场景问题。Java提供了很多类以及修饰符，提供了不同维度的保证，底层也都是封装CPU提供的措施来实现。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(一) 基本概念","slug":"多线程基本概念","date":"2020-03-01T05:00:00.000Z","updated":"2020-09-29T05:50:11.611Z","comments":true,"path":"2020/03/01/多线程基本概念/","link":"","permalink":"http://yoursite.com/2020/03/01/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","excerpt":"线程进程相关基本概念。","text":"线程进程相关基本概念。 进程操作系统进行资源分配和调度的基本单位，每一个进程都是一个应用程序的执行实例，比如我们启动的一个java项目就是一个jvm进程，操作系统为jvm分配运行内存等资源，进程中包含一个或多个线程，线程之间共享进程的资源(比如堆、栈、方法区等)。 线程CPU运行的最小单位，线程之间共享进程的资源，也有自己的私有空间，比如虚拟机栈、本地方法栈、程序计数器。 进程上下文切换线程上下文切换CPU通过分配时间片来执行任务，当一个任务的时间片用完，就会切换到另一个任务。在切换之前会保存上一个任务的状态，当下次再切换到该任务，就会加载这个状态，任务从保存到再加载的过程就是一次上下文切换。 切出：一个线程被剥夺处理器的使用权而被暂停运行 切入：一个线程被系统选中占用处理器开始或继续运行 线程的上下文是什么？对于CPU来说一个线程就是多条指令集合，线程的运行实质上是多条指令在CPU上的运行，而上下文是指线程私有空间的内容。比如虚拟机栈、本地方法栈保存了某一时刻线程局部变量的值，程序计数器保存了线程此刻执行到哪一条指令的位置。 导致上下文切换的原因？ CPU分配的时间片用完了 有个优先级更高的线程需要被执行 手动操作比如java线程的sleep、yield、wait、join、synchronized、lock等 读取数据库操作由于数据量较大引起IO阻塞,线程会被挂起直到读取完毕再次回归等待被CPU调度 上下文切换的过程？放发生切换的时候，CPU会把被挂起线程的上下文保存在程序计数器和寄存器中，程序计数器存储正在执行的指令序列的位置、寄存器存储工作变量，然后从高速缓存中清除掉被挂起线程的上下文，去加载新线程的上下文到高速缓存中。因此线程上下文的切换需要消耗CPU的资源。 并发与并行单CPU操作系统中多个线程同时运行，实质上是交替占有CPU使用权的过程，同时运行只是CPU处理过快造成的错觉，这种现象可以称作为线程并发运行。 到了多CPU时代才实现真正意义上的多线程同时运行，比如4颗CPU的操作系统可以做到4个线程的同时运行，但是操作系统中可能有很多线程需要被执行，比如有16个线程在运行，那么平均4个线程仍然要争夺一个CPU的使用权，只是同一时刻必然有4个争夺到使用权，这种现象称作为线程并行运行。 由此可以看出，操作系统中CPU的数量对多线程编程非常重要。因此项目开发中要尽量参考所在服务器的CPU配置，作出适当的线程池参数以避免频繁的上下文切换带来的性能损耗。同样在选取机器配置上尽量考虑放置服务的线程特点，比如存放redis服务选用多处理器的CPU没有任何意义，redis永远只在一个处理器上面运行。 线程安全线程安全问题","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]}],"categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]}