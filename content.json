{"meta":{"title":"来杯冰镇可乐","subtitle":"","description":"","author":"lvtao","url":"http://yoursite.com","root":"/"},"pages":[{"title":"所有分类","date":"2020-09-29T01:49:01.545Z","updated":"2020-04-12T05:48:42.451Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"RocketMQ(十二)消息可靠性","slug":"RocketMQ消息可靠性","date":"2020-05-25T04:00:00.000Z","updated":"2020-12-22T13:04:49.338Z","comments":true,"path":"2020/05/25/RocketMQ消息可靠性/","link":"","permalink":"http://yoursite.com/2020/05/25/RocketMQ%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7/","excerpt":"","text":"测试","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(十一)消息堆积","slug":"RocketMQ消息堆积","date":"2020-05-23T04:00:00.000Z","updated":"2020-12-22T13:04:42.166Z","comments":true,"path":"2020/05/23/RocketMQ消息堆积/","link":"","permalink":"http://yoursite.com/2020/05/23/RocketMQ%E6%B6%88%E6%81%AF%E5%A0%86%E7%A7%AF/","excerpt":"","text":"测试","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(十)HA机制","slug":"RocketMQHA机制","date":"2020-05-21T04:00:00.000Z","updated":"2020-12-22T13:04:33.663Z","comments":true,"path":"2020/05/21/RocketMQHA机制/","link":"","permalink":"http://yoursite.com/2020/05/21/RocketMQHA%E6%9C%BA%E5%88%B6/","excerpt":"","text":"测试","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(九)分布式事务","slug":"RocketMQ分布式事务","date":"2020-05-18T10:00:00.000Z","updated":"2020-12-22T13:04:23.830Z","comments":true,"path":"2020/05/18/RocketMQ分布式事务/","link":"","permalink":"http://yoursite.com/2020/05/18/RocketMQ%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"测试","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(八)再均衡策略","slug":"RocketMQ再均衡策略","date":"2020-05-18T04:00:00.000Z","updated":"2020-12-22T13:05:38.071Z","comments":true,"path":"2020/05/18/RocketMQ再均衡策略/","link":"","permalink":"http://yoursite.com/2020/05/18/RocketMQ%E5%86%8D%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5/","excerpt":"","text":"测试","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(七)消费端","slug":"RocketMQ消费端","date":"2020-05-11T04:00:00.000Z","updated":"2020-12-24T16:12:50.497Z","comments":true,"path":"2020/05/11/RocketMQ消费端/","link":"","permalink":"http://yoursite.com/2020/05/11/RocketMQ%E6%B6%88%E8%B4%B9%E7%AB%AF/","excerpt":"","text":"springboot1.X集成RocketMQ依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;&#x2F;groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;&#x2F;artifactId&gt; &lt;version&gt;4.7.0&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; application.properties 12345678# 服务端口server.port&#x3D;8082# 消费者分组rocketmq.consumer.groupName&#x3D;GROUP_A# MQ注册中心地地址rocketmq.producer.namesrvAddr&#x3D;localhost:9876 启动Consumer 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Slf4j@Componentpublic class OrderReminderConsumer implements MessageListenerConcurrently &#123; @Value(&quot;$&#123;rocketmq.consumer.groupName&#125;&quot;) private String groupName; @Value(&quot;$&#123;rocketmq.producer.namesrvAddr&#125;&quot;) private String nameSrvAddr; private final DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(); /** * * 初始化 * * */ @PostConstruct public void start()&#123; try &#123; // 设置消费组 consumer.setConsumerGroup(groupName); // 设置注册中心地址 consumer.setNamesrvAddr(nameSrvAddr); // 设置偏移量 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET); // 设置消费模式 consumer.setMessageModel(MessageModel.CLUSTERING); // 设置订阅topic和tags，其中tags设置多个时使用||分割 consumer.subscribe(&quot;ORDER_REMINDER&quot;, &quot;*&quot;); // 设置消费失败重试次数 consumer.setMaxReconsumeTimes(16); // 设置监听者(自身) consumer.registerMessageListener(this); // 启动 consumer.start(); &#125; catch (Exception e) &#123; log.error(&quot;消费者启动失败......&quot;); &#125; &#125; /** * * 消费处理 * * */ @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messageExtList, ConsumeConcurrentlyContext context) &#123; for(MessageExt messageExt : messageExtList)&#123; try &#123; String message = new String(messageExt.getBody(), RemotingHelper.DEFAULT_CHARSET); log.info(&quot;接收消息成功, topic:&#123;&#125;, tags:&#123;&#125;, messageId:&#123;&#125;, messageKey:&#123;&#125;, message:&#123;&#125;&quot;, messageExt.getTopic(), messageExt.getTags(), messageExt.getMsgId(), messageExt.getKeys(), message); &#125; catch (Exception e) &#123; log.error(&quot;消费失败&quot;, e); return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; /** * * 关闭Consumer * * */ @PreDestroy public void stop() &#123; consumer.shutdown(); &#125;&#125; 推拉模式Consumer可以使用推模式、拉模式从Broker节点中获取消息并消费，分别对应DefaultMQPushConsumer(推模式)和DefaultMQPullConsumer(拉模式)俩个对象来实现。 拉模式(PULL)拉模式获取消息，具体实现需要使用者在Consumer自己编写代码，先通过NameServer获取订阅topic对应的MessageQueue列表，遍历此列表对每个MessageQueue对象批量获取消息，并记录该队列下一次要取的开始offset，获取完毕后在处理下一个MessageQueue。 这种模式由Consumer端主动向Broker节点发送请求拉取消息，拉取的相关逻辑可以自由控制(比如拉取频率、单次批量拉取数量等)，因此不会出现消息堆积的情况，只要专注维护每个队列的offset即可(最好在数据库维护，能与消费业务在一个事务中更好)。缺点也很明显，Consmuer端无法准确地决定何时去拉取最新的消息，循环时间间隔太短容易忙等，浪费CPU资源，时间间隔太长client的处理能力会下降，导致有些时候消息延迟。 于是阿里采用长轮询的方式来解决这个问题，Consumer发送请求到Broker拉取消息，如果Broker发现没有消息不会直接返回，而是把连接挂起(wait)，直到Producer投递新的消息过来在对请求线程进行唤醒返回(notify)。为了避免请求连接被阻塞对系统的开销，需要使用者根据自身业务场景合理的评估时间间隔，设置消费者对于长轮询的等待时间，由consumerTimeoutMillisWhenSuspend属性控制。 推模式(PUSH)推模式获取消息，DefaultMQPushConsumer在启动时需指定MessageListenerConcurrently监听器，用于监听最新的消息，达到实时消费的效果。然而严格意义上讲，RcoketMQ并没有提供任何Broker主动推消息的功能，PUSH的本质是consumer对PULL的一层封装，让使用者感觉消息是通过Broker推送过来的。 DefaultMQPushConsumer在启动成功后，会启动一个线程并运行类似while(true)的方法疯狂的去pullRequestQueue队列里面take()元素pullRequest，可以理解为队列里面的每一个pullRequest元素都是一个需求，需求的内容就是去Broker拉取消息(PullRequest对象就是拉取消息的参数)。如果没有元素说明此时不需要拉取消息，将线程自身挂起，如果有就取出并调用pullMessage方法访问Broker进行拉取，pullMessage方法内部是对PULL的一层封装，拉取到消息后扔给线程池的消费处理函数，无论拉没拉取到消息，都会将pullRequest元素放回队列。 由此可以看出推模式的本质还是拉模式，区别在于推模式是写个死循环一直调用PULL，相当于和Broker一直保持联系。拉消息、消费消息由不同的线程取处理，这就导致一个问题，如果订阅的主题，Producer投递消息的速度远超Consumer的消费能力，会导致消费端拉消息的线程拉取了大量的消息不能及时被消费线程处理掉，造成消息堆积。 最后messageListenerConcurrently的作用貌似是监听订阅的topic发生变化后，通知用。 消费模式RocketMQ的Consumer支持集群和广播俩种消费模式，可在初始化方法中指定，消费模式用于决定Consumer订阅Broker节点中topic-queue的分配规则。 集群模式 集群模式中，消费组名称相同的Consumer实例被视为一个Consumer集群，集群内部所有Consumer实例共同承担订阅的topic，在各个Borker节点中队列的消费工作。比如现在有个名为order的topic在Broker-a和Broker-b节点中各有4个队列，并且Group_A消费组有3个Consumer在订阅，Group_B消费组有4个Consumer在订阅: 图中可以看出不同的消费组分配情况相互隔离，互不影响。同一组内的各Consumer实例按照分配策略对应一部分队列，如果总队列数正好等于Consmuer数，那么直接按一对一方式分配；如果总队列数大于Consmuer数并且是其倍数，按照一对多的方式平均分配(如上图的GROUP_B)；如果总队列数大于Consmuer数但不是其倍数，仍然按照一对多的方式，会有个别Consumer被多分配一个(如上图的GROUP_A)；如果总队列数小于Consmuer数，先将队列按一对一分配出去，剩下的Consumer不会被分配到任何队列，也就接收不到任何消息。 将多个Consumer划分到一个组内的作用是topic的消息进行分片，采用并行处理的方式提高消费能力。另外一个作用是实现消费失败重试机制，因为Consumer在进行消费时可能因为各种异常导致消费逻辑执行失败，并返回RECONSUME_LATER状态，遇到这种情况会将消息回发到Broker，然后Broker尝试重新发送。 最后，在使用集群模式进行消费时，所有消费组名称以及订阅topic的所有队列的消费进度(逻辑偏移量)，全部存储在对应的Broker节点上(上篇文章讲到的config文件夹的consumerOffset.json文件中)，Consumer不进行任何进度的存储。 广播模式 广播模式中，任何一条消息都会发送到消费组内所有Consumer进行消费。也就是说消费组内有几个Consumer实例，消息就会被处理几遍。在实现方式上较集群模式简单一些，不用考虑队列分配情况: 与集群模式不同，广播模式下的Consumer在出现消费失败时(返回RECONSUME_LATER状态)不会进行失败重投，所以使用广播模式要额外关注消费失败情况，做好应对措施，防止消费失败引起的消息丢失。另外一个不同点是，消费组内每个Consumer消费进度由自身维护，源码中是LocalFileOffsetStore类负责记录存储。 消息过滤Tag、SQL92和类过滤器(新版去除) 消息回溯回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，消息回溯就是对这种场景的支持。Consumer是基于队列的offset进行拉取消息，因此消息回溯的只需要重新指定topic和queue的offset即可，另外RocketMQ还支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。 Consumer启动重置offset在Consumer端配置中，可以通过setConsumeFromWhere(ConsumeFromWhere)方法设置启动后消费的起点offset，其中传入参数ConsumeFromWhere是个枚举类: 123456789101112131415161718192021222324252627282930313233public enum ConsumeFromWhere &#123; &#x2F;** * 一个新的订阅组第一次启动从队列的最后位置开始消费&lt;br&gt; * 后续再启动接着上次消费的进度开始消费 *&#x2F; CONSUME_FROM_LAST_OFFSET, &#x2F;** @deprecated *&#x2F; @Deprecated CONSUME_FROM_LAST_OFFSET_AND_FROM_MIN_WHEN_BOOT_FIRST, &#x2F;** @deprecated *&#x2F; @Deprecated CONSUME_FROM_MIN_OFFSET, &#x2F;** @deprecated *&#x2F; @Deprecated CONSUME_FROM_MAX_OFFSET, &#x2F;** * 一个新的订阅组第一次启动从队列的最前位置开始消费 * 后续再启动接着上次消费的进度开始消费 *&#x2F; CONSUME_FROM_FIRST_OFFSET, &#x2F;** * 一个新的订阅组第一次启动从指定时间点开始消费 * 后续再启动接着上次消费的进度开始消费 * 时间点设置参见DefaultMQPushConsumer.consumeTimestamp参数 *&#x2F; CONSUME_FROM_TIMESTAMP;&#125; 控制台重置offset进入控制台点击Topic导航栏，筛选出topic行信息后，点击REST CONSUMER OFFSET按钮，选择要重置的消费组以及回溯时间: 订阅关系一致同一个消费组内的所有Consumer还需遵循订阅关系一致性原则，才能保证消息的正常消费。这个原则要求消费组内的所有Consumer订阅的topic和对应tags必须保持一致，一旦订阅关系不一致就会导致消费混乱，甚至消息丢失。 消费组的订阅信息在Broker的存储结构由ConsumerManager类的consumerTable进行维护: 12private final ConcurrentMap&lt;String, ConsumerGroupInfo&gt; consumerTable = new ConcurrentHashMap&lt;String, ConsumerGroupInfo&gt;(1024); ConsumerGroupInfo类存储了消费组的具体结构，类内部的subscriptionTable存储的topic的订阅详情: 12private final ConcurrentMap&lt;String, SubscriptionData&gt; subscriptionTable = new ConcurrentHashMap&lt;String, SubscriptionData&gt;(); SubscriptionData类存储了订阅的所有规则信息: 12345678910111213141516171819 public class SubscriptionData implements Comparable&lt;SubscriptionData&gt; &#123; public final static String SUB_ALL = &quot;*&quot;; // 过滤配置 private boolean classFilterMode = false; // topic名称 private String topic; // 订阅tags字符串 private String subString; // 订阅tags集合 private Set&lt;String&gt; tagsSet = new HashSet&lt;String&gt;(); // 暂时不知道.. private Set&lt;Integer&gt; codeSet = new HashSet&lt;Integer&gt;(); // 订阅版本时间戳 private long subVersion = System.currentTimeMillis(); // 表达式类型 private String expressionType = ExpressionType.TAG; // 构造器、hashCode、equals、getset等...&#125; 由上面结构可以看出，消费组的订阅信息是以groupName为单位进行保存。当Consumer启动后，会将自己的订阅信息(List)发送到对应的Broker中，之后还会采取心跳机制不断将这些信息刷新到Broker中。Broker以新的订阅信息为基准与本地的进行对比，该新增的新增，该删除的删除，如果topic对应的SubscriptionData已存在，则根据subVersion属性进行对比，新的覆盖旧的。也就是说如果同一组内的Consumer订阅关系不一致，会导致该组在Broker中的订阅信息会因为新Consumer的加入或者心跳机制的刷新，不断覆盖掉旧信息，那这和消费混乱有什么关系呢？ 要想搞清楚这个问题，还需要清楚Consumer是如何去Broker拉取消息的，上面的推拉模式也简单说过，推模式是将PullRequest作为参数拉取消息，那就要知道PullRequest对象内部都有什么属性: 123456789101112public class PullRequest &#123; // 消费组名 private String consumerGroup; // 消息队列对象，内部包含queueId以及topic private MessageQueue messageQueue; // 不重要 private ProcessQueue processQueue; // 拉取的坐标 private long nextOffset; // 不重要 private boolean lockedFirst = false;&#125; 到这里问题就差不多搞清楚了，Consumer在拉取消息时，根据consumerGroup和topic获取到SubscriptionData对象，也就是消费组的订阅信息。然后根据对应的queueId以及nextOffset拉取消息，并按照订阅消息配置的tags以及filter等对消息进行筛选拉取。例如名为GROUP_TEST的消费组内有Consumer-0以及Consumer-1俩个消费者，来捋一捋会发生什么情况。 如果俩Consumer订阅的topic一致，tags不一致: 如果俩Consumer订阅的topic不一致，tags一致: 消费重试Consumer端的消费失败分为俩种，一种是EXCEPTION，另一种是TIMEOUT，当Broker感知到Consumer端消费失败后，会根据不同的失败类型采取不同的措施。Consumer的消费重试机制，仅仅在集群模式中有效，广播模式不会进行消息重试。 EXCEPTIONexception是指Consumer正常接收到消息后，在进行消费处理过程中发生异常，比如要将消息的内容插入数据库，正巧此时数据库宕机，又或者消息对应数据库查询出来的数据是脏数据，导致逻辑处理走不通等。这些都会引起消费逻辑的异常，通常我们会将消息的处理代码块使用try catch包起来(上面的例子)，如果正常执行就返回CONSUME_SUCCESS，抓取到异常就返回RECONSUME_LATER。 无论如何，Broker都会收到Consumer端的消费结果情况，如果成功就更新offset，如果失败重新尝试推送，重试次数默认是16次，考虑到异常恢复起来需要一些时间，所以每次重试都有一定的时间间隔，间隔依次为1S,5S,10S,30S,1M,2M····2H。RocketMQ会为每个消费组创建一个格式为%RETRY%+consumerGroup的重试队列，对于消费失败的消息根据间隔时间将其放入延迟topic(SCHEDULE_TOPIC_XXXX)，到达延迟时间点后发送到对应的重试队列，然后再次投递到Consumer。 实际开发中也许并不需要这么多重试次数，比如只需要3次重试次数，超过这个次数就记录到数据库或缓存，然后开启定时器等扫描在处理，或者人为干涉修复。这种方式首先要在Consumer设置重试次数，然后在消费前调用MessageExt类的getReconsumeTimes()方法查看重试次数，如果超过设置次数则将消息保存到数据库或缓存，然后直接返回CONSUME_SUCCESS。 TIMEOUTTIMEOUT是指因为种种原因导致Consumer端没有及时给Broker反馈消息的处理状态，导致Broker认为消息并没有被消费掉，然后会一直发送消息。超时时间可以调用Consumer的setConsumeTimeout()方法设置，默认为15(单位分钟)。 死信队列","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(六)消息存储","slug":"RocketMQ消息存储","date":"2020-05-09T04:00:00.000Z","updated":"2020-12-24T14:14:54.524Z","comments":true,"path":"2020/05/09/RocketMQ消息存储/","link":"","permalink":"http://yoursite.com/2020/05/09/RocketMQ%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/","excerpt":"","text":"存储文件Broker负责存储消息、主题、对应队列等，将这些内容持久化到配置文件的store文件夹中: 当生产者通过路由信息将消息发送到Broker后，Broker先将消息写到内存中，然后通过线程刷到磁盘。刷盘方式分为同步和异步俩种方式，在配置文件的flushDiskType属性中进行设置: config此文件夹存储了Broker运行需要的各种配置信息，采用json文本形式存储配置文件以及对应的备份文件: 文件名称 解析存储类 描述 topics.json TopicConfigManager 存储每个topic的读写队列数、权限、是否顺序等信息 consumerOffset.json ConsumerOffsetManager 记录每个Consumer在每个topic上对于该topic的consumequeue队列的消费进度 consumerFilter.json ConsumerFilterManager 存储每个消费者Consumer的过滤信息 subscriptionGroup.json SubscriptionGroupManager 存储每个消费者Consumer的订阅信息 delayOffset.json ScheduleMessageService 记录对于延迟主题SCHEDULE_TOPIC_XXXX的每个consumequeue队列的消费进度 commitlog此文件夹负责存储Broker节点接收到的消息，存储消息的文件名长度为20位，以起始物理偏移量的值进行命名，如果长度不够20位则在左侧补零，每个文件的大小默认1G，也就是1073741824字节，当文件写满则创建下一个文件。比如Broker接收到第一个消息后创建00000000000000000000代表第一个文件，起始偏移量为0，当文件写满1G后，创建名为00000000001073741824的文件继续存储消息，起始偏移量为1073741824。 注:这里的偏移量是指物理偏移量(1个字节代表一个偏移量)，并非按消息数量递增的逻辑偏移量，物理偏移量用于定位某个消息在此文件中的物理位置 消息在commitlog文件中的存储格式如下: 存储结构中，各部位代表的含义: 名称 占用磁盘 描述 msgLen 4字节 消息长度，具体指整个消息体所占用的字节大小 magicCode 4字节 魔数，固定值daa320a7 bodyCRC 4字节 消息体验证码 queueId 4字节 消息体发送到了哪个MessageQueue flag 4字节 创建Message对象时由生产者通过构造器设定的flag值 queueOffset 8字节 表示在队列中逻辑的偏移量 physicalPosition 8字节 表示在存储文件中的偏移量 sysFlag 4字节 是生产者相关的信息标识 msg born timestamp 8字节 消息创建时间 msg host 8字节 消息生产者的host store timestamp 8字节 消息存储时间 store host 8字节 消息存储机器的host reconsume times 4字节 消息重复消费次数 prepare transaction offset 8字节 消息事务相关偏移量 body length 4字节 消息体的长度 msg body 不固定 消息内容 topic length 1 主题名称长度(1字节=8位，因此topic长度不会超过127) topic length 不固定 主题名称 properties lengh 不固定 Properties内容长度 properties 不固定 Properties的内容 某个Broker节点接收到的所有topic-queue消息，全部写入一个文件中(直到写满为止)，这一点与Kafka有很大不同。Kafka是以topic-partition为单位创建存储消息的文件，存储文件的分类粒度比RocketMQ要细很多，也意味着相同的业务场景，kafka节点创建存储消息的文件数量肯定会比RocketMQ节点要多，且随着节点中topic和queue/partition的激增，数量差距越来越大。 当kafka的存储文件越来越多(单机以64个partition为分水岭)，顺序写入特性会被大大破坏从而引起大量的随机I/O，吞吐量会急剧下降，而RocketMQ的这个设计，很好的避免了这个问题。 consumequeueBroker节点接收到的任何topic-queue消息都会写在commitlog文件中，并且没有规则的分布情况，如果消费者想要拉取某个topic-queue消息时，需要整体检索commitlog文件，这种方式的效率难以保障。这就需要对commitlog文件的消息建立索引来加快消息的检索，而这些索引数据就是在consumequeue文件夹进行存储。 例如现在某个Broker节点中负责订单的发货(DELIVER_PACKAGE)、到货(ARRIVAL_PACKAGE)、签收(SIGN_PACKAGE)的三个消息通知topic，每个topic都有4个队列，目录结构如下: 由此图可以看出，consumequeue目录结构的分类粒度与Kafka存储消息文件的粒度类似，只不过consumequeue目录不存储具体的消息内容，只存储路由到该queue中的消息在CommitLog中的物理偏移量(offset)、消息大小(size)、消息所属的tag的hash值(tagCode)三个属性，每条索引占用磁盘空间固定为20字节。 文件写入当Broker收到某个topic-queue消息时，先将消息写入commitlog文件中并得到物理偏移量，然后进入consumequeue目录对应的文件夹创建文件，文件名长度为20位，以起始物理偏移量的值进行命名，如果长度不够20位则在左侧补零。每个文件默认可以存储30W个消息索引，文件磁盘大小也就是60W字节，比如Broker收到某个topic-queue的第一条消息时，创建文件00000000000000000000，起始物理偏移量为0，将刚才的物理偏移量、消息大小、tag的hash值写入创建的文件中，当写满后30W条消息时创建第二个文件00000000000006000000，起始物理偏移量为60W，继续存储写入的数据。 文件读取当Broker收到Consumer的消息拉取请求时，根据topic、queueId找到对应文件夹，通过文件夹里面各文件的名称计算出存储的逻辑偏移量范围，然后根据Consumer提供的offset锁定到具体检索哪个文件。将Consumer提供的offset*20后减去文件名的数值，即可得到要查询的消息在consumequeue索引中的物理偏移量位置，往后取20字节的数据就是消息的索引信息，拿到物理偏移量去commitlog即可查询最终的消息。 consumequeue文件夹创建的文件命名虽然和commitlog同样都是物理偏移量，不过consumequeue文件存储的数据量固定，且布局有序、有固定规则，因此可以通过文件名去定位具体的物理偏移量，不会存在检索效率的问题。 indexBroker除了通过Consumer提供的offset获取消息外，还支持通过MessageID或者MessageKey查询消息。使用ID查询处理起来比较简单，因为MessageID就是根据Broker+offset生成的，因此很容易找到对应的commitlog文件来读取消息。而MessageKey由生产者自己设定，RocketMQ为了保证其查询的效率，使用index文件夹记录对应的索引信息。 index文件由IndexHeader、HashSlot、Index三部分构成: IndexHeader中存储的都是一些文件基础数据: 名称 占用磁盘 描述 beginTimestamp 8字节 该索引文件第一个消息的存储(落盘)时间 endTimestamp 8字节 该索引文件最后一个消息的存储(落盘)时间 beginPhyoffset 8字节 该索引文件第一个消息在commitlog的物理偏移量 endPhyoffset 8字节 该索引文件最后一个消息在commitlog的物理偏移量 hashSlotCount 4字节 该索引文件目前的哈希槽个数 indexCount 4字节 该索引文件目前已存储的索引数量 HashSlot负责对索引内容进行分片:消息在进行index存储时，通过消息key的哈希值%500W定位哈希槽(貌似500W这个值可以修改)，因此可以理解为一个index文件的哈希槽最多500W个，另外IndexHeader与HashSlot的大小都是固定的，再文件中的位置不需要额外标记，可以直接定位获取。 其中每个哈希槽固定占有4字节，仅仅用来存储当前卡槽最后一个key在index部分的逻辑位置(整个索引文件index区域中第几个写入的)，这么做的目的仍然是节省磁盘空间，如果直接存储物理偏移量需要8个字节，这里四个字节就够了，因为IndexHeader与HashSlot的大小是固定的，每个索引数据在整个index的物理偏移量为: IndexHeader大小(40字节) + hashSlot大小(4字节) * 数量(500w) + 逻辑位置 * 每个index大小(20字节) Index存储真正的索引信息: 名称 占用磁盘 描述 key hash value 4字节 消息key的哈希值 phyOffset 8字节 消息在commitlog的物理偏移量(索引的核心数据) timeDiff 4字节 消息落盘时间与IndexHeader中的beginTimestamp的差值(节省磁盘空间，如果直接存储落盘时间就需要占用8字节) prevIndex 4字节 哈希槽的第一个索引prevIndex=0，后续的索引prevIndex=前一个索引的物理偏移量 索引文件创建过程:当Broker接收到消息后，先将消息写入commitlog文件中并得到物理偏移量，然后进入index文件夹查询最新创建的索引文件，如果此索引文件的IndexHeader的indexCount等于2000W则表示已满，获取当前时间戳作为名称创建新的索引文件，如果小于2000W直接进入写文件环节。 获取消息key的哈希值并%500W计算出卡槽号，如果此卡槽存储的值为0，表示目前下面还没有存储索引，写入索引数据(其中prevIndex=0)，如果卡槽存储的值不为0，通过卡槽值计算出索引数据所在的物理偏移量并取出，然后将新的索引数据写入文件(其中prevIndex=当前卡槽值)，然后刷新卡槽值为当前索引数据的逻辑位置(整个索引文件index区域中第几个写入的)，其实就是类似HashMap的数组+链表。 消息key查询过程:查询的传入值除了key外，还包含一个时间起始值以及截止值(这玩意在控制台貌似不需要?)，时间范围参数用于定位具体的索引文件，根据消息key的哈希值锁定具体的卡槽。通过卡槽值计算出最后一个索引数据在索引文件中的物理偏移量并取出，紧接着通过prevIndex属性递归遍历，再加上时间范围与timeDiff属性对比筛选，得出符合条件的phyOffset属性集合，去commitlog捞消息。由于key的hash相同，内容不一定相同，所以在捞消息的时候还要对key的内容进行筛选。 abort文件Broker启动时会在store目录创建此文件，在正常退出后会删除此文件。如果Broker在启动时发现store目录中发现abort文件存在，那么说明上次服务退出属于异常退出(宕机或者手动kill进程等)，异常退出会导致部分文件的写入逻辑没有执行完就被打断(比如某条消息只写入一半)，造成脏数据影响后续的解析。 lock这叼毛文件完全搜不到是干啥的 checkpointcheckpoint文件的作用是记录commitlog、consumequeue、index最后一次刷盘时间，此文件固定长度为4k。但是Broker仅仅使用了前24个字节，这24个字节按照8字节为单位划分为三部分，使用16进制数字表示上述的三个刷盘时间戳。 使用文本打开此文件，内容如下: 删除策略读写性能无论是生产消息还是消费消息，本质上都是对磁盘文件的读写，上面的内容是通过优化文件结构的方式来提高分布式消息队列的性能，除此之外，RocketMQ还在操作系统层面对磁盘文件读写进行优化。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(五)生产端","slug":"RocketMQ生产端","date":"2020-05-07T05:00:00.000Z","updated":"2020-12-21T12:25:35.069Z","comments":true,"path":"2020/05/07/RocketMQ生产端/","link":"","permalink":"http://yoursite.com/2020/05/07/RocketMQ%E7%94%9F%E4%BA%A7%E7%AB%AF/","excerpt":"","text":"springboot集成RocketMQ依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;&#x2F;groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;&#x2F;artifactId&gt; &lt;version&gt;4.7.0&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; application.properties 1234567891011121314151617# 服务端口server.port&#x3D;8082# 生产者分组rocketmq.producer.groupName&#x3D;GROUP_A# MQ注册中心地地址rocketmq.producer.namesrvAddr&#x3D;localhost:9876# 消息最大长度 默认 1024 * 4 (4M)rocketmq.producer.maxMessageSize &#x3D; 4096# 发送消息超时时间，默认 3000rocketmq.producer.sendMsgTimeOut&#x3D;3000# 发送消息失败重试次数，默认2rocketmq.producer.retryTimesWhenSendFailed&#x3D;2 将生产者注册到IOC 123456789101112131415161718192021222324252627282930313233343536@Configurationpublic class RocketMQProducerConfig &#123; @Value(&quot;$&#123;rocketmq.producer.groupName&#125;&quot;) private String groupName; @Value(&quot;$&#123;rocketmq.producer.namesrvAddr&#125;&quot;) private String namesrvAddr; @Value(&quot;$&#123;rocketmq.producer.maxMessageSize&#125;&quot;) private Integer maxMessageSize; @Value(&quot;$&#123;rocketmq.producer.sendMsgTimeOut&#125;&quot;) private Integer sendMsgTimeOut; @Value(&quot;$&#123;rocketmq.producer.retryTimesWhenSendFailed&#125;&quot;) private Integer retryTimesWhenSendFailed; /** * RocketMQ生产者对象 */ @Bean public DefaultMQProducer defaultProducer() throws MQClientException &#123; DefaultMQProducer producer = new DefaultMQProducer(groupName); producer.setNamesrvAddr(namesrvAddr); producer.setVipChannelEnabled(false); producer.setMaxMessageSize(maxMessageSize); producer.setSendMsgTimeout(sendMsgTimeOut); producer.setRetryTimesWhenSendAsyncFailed(retryTimesWhenSendFailed); producer.start(); return producer; &#125;&#125; 路由选择DefaultMQProducer类提供了fetchPublishMessageQueues方法，可以查看当前Producer从NameServer同步过来的topic路由信息: 1List&lt;MessageQueue&gt; messageQueueList = producer.fetchPublishMessageQueues(&quot;TEST_TOPIC&quot;); Producer向某个topic发送消息时，如果从NameServer同步的路由信息中发现，此topic在多个Broker中都存在队列，那么就需要依靠某种策略从中选择一个进行发送，这个策略由MQFaultStrategy类的selectOneMessageQueue方法实现: 1234567891011121314151617181920212223242526public MessageQueue selectOneMessageQueue(String lastBrokerName) &#123; // 如果上次发送的brokerName为空，直接轮询 if (lastBrokerName == null) &#123; return this.selectOneMessageQueue(); &#125; else &#123; // 对messageQueueList进行轮询选取 int index = this.sendWhichQueue.getAndIncrement(); for(int i = 0; i &lt; this.messageQueueList.size(); ++i) &#123; int pos = Math.abs(index++) % this.messageQueueList.size(); if (pos &lt; 0) &#123; pos = 0; &#125; // 如果此次轮询到的MessageQueue对应的Broker节点没任何问题，直接返回 MessageQueue mq = (MessageQueue)this.messageQueueList.get(pos); if (!mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125; // 直接轮询 return this.selectOneMessageQueue(); &#125;&#125; Producer采用轮询的方式发送消息，每次发送消息时调用无参的selectOneMessageQueue()方法，这个方法就是一个单纯的轮询策略。只是消息并不能保证每次都会发送成功，如果发送失败并且设置了重试次数，那么Producer会调用有参的selectOneMessageQueue()方法，将发送失败的Broker名称作为参数传进去，并且此次轮询会忽略掉这个Broker名称。 当消息经过重试发送成功后，有问题的Broker并没有被记录下来，这就导致下次发送消息时并不会知晓这个Broker有问题，仍然在轮询策略的选择范围内，仍然有发送失败的情况出现。想要避免此问题，就需要开启延迟故障。 延迟故障延迟故障功能通过创建Producer时调用setSendLatencyFaultEnable(true)开启(默认false)，开启后对于高延迟、有故障的Broker都会记录下来，并且根据故障的严重程度，给予一段不可用的时间。具体的规则维护在MQFaultStrategy类的俩个数组中: 12private long[] latencyMax = new long[]&#123;50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L&#125;;private long[] notAvailableDuration = new long[]&#123;0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L&#125;; latencyMax数组元素表示各种延迟的时间，notAvailableDuration数组元素表示各种不可用时间，这俩个数组的同一个下坐标对应的值就是延迟时间对应的惩罚时间。由此可以看到100ms以内的延迟都是正常的，其余的规定时间内会排除掉，从正常的Broker中轮询获取。 如果在极端的情况，所有的Broker延迟都高于100，都被视为故不可用的故障节点，这段时间的消息发送如何处理呢。RocketMQ提供了pickOneAtLeast()方法，从故障Broker列表中选择最优的一个，也就是俗话矮子里面拔将军: 1234567891011121314151617181920212223242526272829public String pickOneAtLeast() &#123; final Enumeration&lt;FaultItem&gt; elements = this.faultItemTable.elements(); List&lt;FaultItem&gt; tmpList = new LinkedList&lt;FaultItem&gt;(); // 先把故障的broker列表复制一份，后面好做打乱 while (elements.hasMoreElements()) &#123; final FaultItem faultItem = elements.nextElement(); tmpList.add(faultItem); &#125; // 打乱该列表 if (!tmpList.isEmpty()) &#123; Collections.shuffle(tmpList); // 排序 Collections.sort(tmpList); // 从前50%里面递增选取一个 final int half = tmpList.size() / 2; if (half &lt;= 0) &#123; return tmpList.get(0).getName(); &#125; else &#123; final int i = this.whichItemWorst.getAndIncrement() % half; return tmpList.get(i).getName(); &#125; &#125; return null;&#125; 从故障Broker列表中按照规则排序，然后从前半部分中轮询获取一个作为发送的目的地，因此重点在于排序规则，这就需要查看FaultItem类重写的排序方法了: 1234567891011121314151617181920212223242526public int compareTo(final FaultItem other) &#123; // 可用的笔不可用的优先级高 if (this.isAvailable() != other.isAvailable()) &#123; if (this.isAvailable()) return -1; if (other.isAvailable()) return 1; &#125; // 延迟低的比延迟高的优先级高 if (this.currentLatency &lt; other.currentLatency) return -1; else if (this.currentLatency &gt; other.currentLatency) &#123; return 1; &#125; // 被惩罚时间早的比晚的优先级高 if (this.startTimestamp &lt; other.startTimestamp) return -1; else if (this.startTimestamp &gt; other.startTimestamp) &#123; return 1; &#125; return 0; &#125; 这里并没有将选择结果固定为排序规则中最好的那个，主要是为了避免topic的消息聚集在一个Broker的队列中造成负担过重，负载均衡到所有故障Broker又失去了故障延迟的初衷，因此选择折中的方式，将前50%的节点采用轮询方式进行负载均衡。 发送方式同步发送 同步发送消息时，线程进入阻塞状态，直到发送完毕返回SendResult类 如果发送失败，会在默认的超时时间进行重试，最多重试俩次 返回SendResult类，并不代表发送成功，需要根据sendStatus来判断是否成功 可以根据返回的结果作相应处理，因此理论上不会出现消息丢失(可靠) 12345678// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;ORDER_REMINDER&quot;, &quot;LOGISTICS&quot;, message.getBytes());// 同步发送SendResult sendResult = producer.send(sendMsg); 异步发送 异步调用不存在返回值，投递的结果信息SendResult类在成功回调onSuccess()方法中 异步发送没有retry机制，投递失败回调onException()方法 异步调用主要请求耗时过长，或者对响应时间过于敏感的请求，比如大数据量的excel导入，选择用户群体后批量推送消息等 可以根据onSuccess()方法返回的结果作相应处理，因此理论上不会出现消息丢失(可靠) 1234567891011121314151617// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;TEST_TOPIC&quot;, &quot;tag&quot;, message.getBytes());// 异步发送producer.send(sendMsg, new SendCallback()&#123; @Override public void onSuccess(SendResult sendResult) &#123; // 发送成功回调逻辑 &#125; @Override public void onException(Throwable e) &#123; // 发送失败回调逻辑 &#125;&#125;); 单向发送 单向发送仅仅处理消息的发送，由于发送是否成功无法知晓，因此有几率造成数据丢失(不可靠) 优点在于发送消息的耗时非常短，一般在微秒级别 12345678// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;TEST_TOPIC&quot;, &quot;tag&quot;, message.getBytes());// 单向发送producer.sendOneway(sendMsg); 发送特点顺序发送Producer将消息发送到Broker节点后，Broker会找到对应的队列文件，并采用追加的方式将消息内容写入文件中，可以理解为RocketMQ可以保证队列级别的消息顺序。因此我们只需要将同一类数据发送到同一个队列中，就可以保证消息的顺序发送，Consumer在进行消费时也就毫无悬念的顺序消费了。 最常见的顺序消费场景就是使用canal或maxwell来订阅Mysql数据库的Binlog，同一条数据会产生多条操作日志，如果不做任何措施可能会导致Insert日志和Update日志被投递到不同的Broker中，这就有很大几率出现Update日志抢先在Insert日志处理前被消费处理，造成数据不一致的情况。对此最常见的解决方案是提取消息的业务唯一标示(比如id等)，和队列长度取余运算定位需要发送的Broker的节点进行发送。 12345678910111213141516171819// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;TEST_TOPIC&quot;, &quot;tag&quot;, message.getBytes());// 假设此binlog消息的主键id为666Long id = 666L;// 顺序发送SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; // arg的值就是send方法第三个参数(id)的值 Long id = (Long) arg; // mqs为此Producer从注册中心拿到的，需要发送 int index = id % mqs.size(); return mqs.get(index); &#125;, id);&#125; 延迟发送延迟消息的使用场景很多，例如电商系统的订单业务场景，用户下单后发送一个30分钟的延迟消息，30分钟后Consumer会收到此消息，然后检查订单是否已付款，如果未付款执行自动取消逻辑处理。 12345678910// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;TEST_TOPIC&quot;, &quot;tag&quot;, message.getBytes());// 设置延迟级别sendMsg.setDelayTimeLevel(2);// 延迟发送SendResult sendResult = producer.send(sendMsg); RocketMQ商业版本支持任意精度的延迟消息，而开源版本仅仅支持18个特定时间的延迟功能，通过setDelayTimeLevel()方法进行控制，具体的延迟等级与延迟时间的对应关系如下: 延迟等级 延迟时间 1 1秒 2 5秒 3 10秒 4 30秒 5 1分钟 6 2分钟 7 3分钟 8 4分钟 9 5分钟 10 6分钟 11 7分钟 12 8分钟 13 9分钟 14 10分钟 15 20分钟 16 30分钟 17 1小时 18 2小时 Producer发送延迟消息时，消息首先会被投递到名为SCHEDULE_TOPIC_XXXX的topic中，这个topic是集群自动创建的，可以在控制台的Topic页面中勾选SYSTEM进行REFRESH查询，点开此topic的路由信息可以看到每个Broker节点都负责此topic的18个读写队列。 Producer会根据延迟等级值来决定将消息发送到SCHEDULE_TOPIC_XXXX的哪个队列号中，紧接着将真实的topic和queueId设置到Message的propertiesString属性中，然后选择一个Broker进行发送。每个Broker的SCHEDULE_TOPIC_XXXX的每个queue，都会对应一个定时器去刷新，是否有到达时间需要被发送的消息，若有就从propertiesString取出真实的topic和queueId发送出去。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(四)主题创建","slug":"RocketMQ主题创建","date":"2020-05-05T05:00:00.000Z","updated":"2020-12-19T07:55:50.337Z","comments":true,"path":"2020/05/05/RocketMQ主题创建/","link":"","permalink":"http://yoursite.com/2020/05/05/RocketMQ%E4%B8%BB%E9%A2%98%E5%88%9B%E5%BB%BA/","excerpt":"","text":"自动创建topic在默认情况下支持自动创建，开关由配置文件的autoCreateTopicEnable(默认true)属性决定，在项目启动后存储在BrokerConfig类中。如果某个Broker的自动创建设置为true，则Broker在启动后会在topicManager中创建名为TBW102的topic并向所有NameServer进行注册。 当Producer向某个topic投递消息时，首先会访问NameServer获取此topic的路由列表，这里假设此topic之前并没有被创建，那么得到的将是一个空列表，Producer会再次访问NameServer获取名为TBW102的topic的路由列表，如果整个集群中没有任何Broker支持自动创建，那么这个路由列表仍然是空的，此时会抛出No route info of this topic异常，如果集群中存在支持自动创建的Broker，那么就返回这些Broker的路由信息。 Producer拿到TBW102的路由列表后，会从中选择(默认轮询)一个Broker进行投递，Broker接收到此消息后会调用msgCheck方法对topic进行校验，先去topicConfigTable中查询此topic是否存在，在目前讨论的场景下是肯定不存在的，那么会以这个不存在的tpoic名称创建一个TopicConfig。这个类包含了topic的具体信息包括队列数、读写权限、同步/异步复制等，基本上沿用TBW102的属性，创建完毕后存入topicConfigTable中，然后将topicConfigTable中的所有数据同步到NameServer中。 topic自动创建流程图: 流程图可以看出，自动创建的topic仅仅在消息投递到的Broker节点中生成queue，一旦刷回注册中心，此topic的负载均衡能力就被固定(排除手动修改的情况)。如果某一时刻不存在的topic被多个Producer同时投递，且集群中支持自动创建的Broker节点数量还算可观，考虑到从投递消息开始直到刷回注册中心这段时间的并发情况，可能会有多个Broker都被分配此topic的queue，此topic仍然有很可观的并行执行能力。 这里换一种假设，不存在的topic第一次被Producer投递时，没有其他Producer同时进行，导致此topic仅仅分配在某一个Broker中。这就相当危险了，并行能力太差，如果消息量上来很容易造成积压。说这么多就是想表达自动创建的topic的配置信息，因为场景的不确定性很难达到理想值，因此在生产环境中最好关闭自动创建，所有topic都由开发人员根据业务场景主观判断并创建。 手动创建topic的手动创建可以通过linux命令来实现，也可以在console页面进行操作，命令操作相对于页面来说较麻烦一些，并且生产环境除非运维基本上不会有访问服务器的权限，所以这里只写控制台如何创建。 topic在控制台的创建界面: clusterName与BROKER_NAME clusterName与BROKER_NAME选项必须填写一个，用于指定topic在哪些Broker节点上创建。如果仅填写clusterName选项(支持多选)，则选中的集群所属Broker节点都会创建此topic信息，这种方式也叫集群创建。如果仅填写BROKER_NAME选项(支持多选)，则只在选中的Broker节点中创建，这种方式也叫Broker创建。如果俩个有存在选项值，则取并集。 writeQueueNums(写队列数)此参数决定了在每个选中的Broker节点中创建的队列数量，比如写队列数的值为4，在topic被创建后，涉及到的每个Broker对应的consumequeue文件夹下都会创建0、1、2、3四个文件夹(懒创建方式，只有消息投递到此文件夹才会被创建)，每个Producer启动后，都会从NameServer中获取到所有Broker的0、1、2、3号队列的路由信息，进行轮询投递消息。 readQueueNums(读队列数)此参数决定某个Broker负责的某个topic，同一个组内最多可连接的消费者数，在集群正常运行期间此参数似乎没有存在的意义。假设某个Broker上的写队列数是4，那么涉及到的每个Broker节点中都会创建0、1、2、3四个队列。如果设置的读队列数小于写队列数(比如3)，那么同一组内的Consumer只会从NameServer拿到1、2、3三个队列的路由信息，队列号3永远无法被消费。如果设置的读队列数大于写队列数(比如5)，由于一个队列在同一时刻只会被一个消费者连接(不考虑消费组不同和广播消费模式的情况)，即使启动了5个消费者，仍然只有4个消费者可以正常工作，多出来的那个消费者不会被分配任何路由信息，即使启动也没有意义。 扩容与缩容按照上述的理论，writeQueueNums小于readQueueNums情况下最多造成资源浪费，大于readQueueNums情况下则会导致个别队列无法被Consumer连接消费，造成严重的消息堆积问题，writeQueueNums与readQueueNums的值只有保持一致才是合理的，为什么不将俩个参数选项合并为一个呢? 其实这么设计的目的是方便队列的缩容与扩容，思考一个问题，假设某个topic在每个Broker上创建了128个队列，如果在用户无感知的情况下缩小到64个，或者扩容到256个？ 水平扩容关于扩容，可以先将读队列数修改为256，修改后触发再均衡，将队列重新分配给所有Consumer，并且此时队列号128-155虽然分配了Consumer，但是不会有任何消息进入，因为写队列数仍然是128，Producer投递消息只会路由队列号0-127。然后修改写队列数为256，Producer从NameServer获取到最新的关于此topic的路由信息变为0-255，后续投递消息就会覆盖到扩容的队列，供Consumer进行消费。 水平缩容关于缩容，可以先将写队列数修改为64，修改后会触发再均衡，将队列重新分配给所有Consumer，并且此时队列号64-127不会被路由到任何Producer，也就是说这些队列不会接收到新消息。由于读队列还是128，仍然可以继续消费队列号64-127的消息。直到队列号64-127全部消费完毕后(通过控制台查看)，修改读队列的值与写队列保持一致，Producer从NameServer获取到最新的关于此topic的路由信息变为0-63，后续不会对64-127号队列投递消息。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(三)注册中心","slug":"RocketMQ注册中心","date":"2020-05-04T05:00:00.000Z","updated":"2020-12-13T11:39:20.937Z","comments":true,"path":"2020/05/04/RocketMQ注册中心/","link":"","permalink":"http://yoursite.com/2020/05/04/RocketMQ%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/","excerpt":"","text":"前言高可用性NameServer作为一个十分重要的核心组件，在整个RockteMQ集群运作过程中发挥着重要作用，NameServer服务一旦宕机，整个集群就无法正常运转。因此NameServer一定要集群部署，这样才能保证高可用性。NameServer集群各节点彼此之间互不通信，也就是某一刻NameServer节点之间的数据并不完全相同，但这对消息发送不会造成任何影响。 路由信息在RocketMQ源码中，namesrv模块的org.apache.rocketmq.namesrv.routeinfo.RouteInfoManager类负责存储Broker集群各节点注册的路由信息: HashMap&lt;String, List&gt; topicQueueTable此变量以topic为单位，记录对应的所有队列信息，因为一个topic的数据可以分散到多个Broker中，所以topic与QueueData集合是一对多的关系，QueueData类数据结构: 123456789101112public class QueueData implements Comparable&lt;QueueData&gt; &#123; &#x2F;&#x2F; 队列所属的Broker名称 private String brokerName; &#x2F;&#x2F; 读队列数量 private int readQueueNums; &#x2F;&#x2F; 写队列数量 private int writeQueueNums; &#x2F;&#x2F; Topic的读写权限(2是写 4是读 6是读写) private int perm; &#x2F;&#x2F; 同步复制还是异步复制标记 private int topicSynFlag;&#125; HashMap&lt;String, BrokerData&gt; brokerAddrTable此变量以Broker名称为单位，记录对应的所有主从节点信息，Broker名称与主从节点也是一对多的关系，不过主从节点集合被设计到BrokerData类中: 12345678public class BrokerData implements Comparable&lt;BrokerData&gt; &#123; &#x2F;&#x2F; 所属集群名称 private String cluster; &#x2F;&#x2F; broker名称 private String brokerName; &#x2F;&#x2F; key为节点id，value为节点地址端口 private HashMap&lt;Long, String&gt; brokerAddrs;&#125; HashMap&lt;String, Set&gt; clusterAddrTable此变量以Broker集群名称为单位，记录每个集群对应的Broker名称集合。 brokerLiveTable此变量以Broker地址端口为单位，记录每个Broker的实时信息，与BrokerLiveInfo类是一对一的关系: 12345678910class BrokerLiveInfo &#123; &#x2F;&#x2F; 上次心跳时间戳 private long lastUpdateTimestamp; &#x2F;&#x2F; 数据版本 private DataVersion dataVersion; &#x2F;&#x2F; 长连接通道 private Channel channel; &#x2F;&#x2F; Ha地址 private String haServerAddr;&#125; HashMap&lt;String, List&gt; filterServerTable此变量以Broker地址端口为单位，记录每个Broker的消费者在进行消费时的过滤逻辑，后续会详细讲。 由clusterAddrTable的结构可以判断，一个注册中心集群可以包含多个Broker集群，同一个Broker名称可以出现在多个不同的Broker集群中。 不过我发现了一个奇怪的问题，我有一个名称为lvt-cluster的集群，内部有个broker-a的Broker，然后在test-cluster集群中也用broker-a这个名称启动了一个Broker，控制台能看到这俩个Broker，当我使用kill杀死test-cluster集群中的broker-a时，在控制台仍然存在，然后我又kill掉lvt-cluster集群中的broker-a，俩个Broker在控制台都消失了。再次启动lvt-cluster集群中的broker-a，又出现了2个Broker，直到我重启注册中心集群，才回归正常。 服务注册Broker在启动的时候，会向NameServer注册自己的服务信息，由于NameServer支持集群部署，并且集群中各节点之间没有任何数据交互。因此每个Broker节点启动时，会获取NameSever的地址列表(乱序)，采用遍历列表的方式向每一个NameServer节点注册自己的信息。 启动并注册完毕后，Broker会启动一个定时任务，每隔30s定时向NameServer进行心跳更新。无论是启动时注册，还是心跳注册，NameServer接收到注册信息都不会持久化到本地，而是保存在上述的各个map中。 源码中Broker是通过NamesrvStartup类的main方法启动，main方法先是创建了一个BrokerController，然后调用其start()方法，在该方法中有如下代码: 1234567891011121314151617181920212223if (!messageStoreConfig.isEnableDLegerCommitLog()) &#123; startProcessorByHa(messageStoreConfig.getBrokerRole()); handleSlaveSynchronize(messageStoreConfig.getBrokerRole()); &#x2F;&#x2F; 重点在这里 this.registerBrokerAll(true, false, true);&#125;&#x2F;&#x2F; 开启定时任务 this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; try &#123; &#x2F;&#x2F; Broker会每隔30s向NameSrv注册并更新自身topic信息,完成心跳功能 BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister()); &#125; catch (Throwable e) &#123; log.error(&quot;registerBrokerAll Exception&quot;, e); &#125; &#125; &#x2F;&#x2F; 定时器延迟10秒后开始运行，间隔时间用函数绕了一圈，其实就是1000*30，单位毫秒 &#125;, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS); Broker的服务注册逻辑全部包含在BrokerController类的registerBrokerAll方法中，此方法并没有真正去处理注册的事情，而是委托doRegisterBrokerAll方法来处理，doRegisterBrokerAll也没有亲自去进行注册，而是委托内部的BrokerOuterAPI类的registerBrokerAll方法来处理: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public List&lt;RegisterBrokerResult&gt; registerBrokerAll( final String clusterName, final String brokerAddr, final String brokerName, final long brokerId, final String haServerAddr, final TopicConfigSerializeWrapper topicConfigWrapper, final List&lt;String&gt; filterServerList, final boolean oneway, final int timeoutMills, final boolean compressed) &#123; &#x2F;&#x2F; 使用内部类remotingClient获取NameServer集群中所有节点的IP地址 final List&lt;RegisterBrokerResult&gt; registerBrokerResultList &#x3D; Lists.newArrayList(); List&lt;String&gt; nameServerAddressList &#x3D; this.remotingClient.getNameServerAddressList(); &#x2F;&#x2F; 如果获取的集合不为空 if (nameServerAddressList !&#x3D; null &amp;&amp; nameServerAddressList.size() &gt; 0) &#123; &#x2F;&#x2F; 将Broker自身的各种信息写入requestHeader中 final RegisterBrokerRequestHeader requestHeader &#x3D; new RegisterBrokerRequestHeader(); requestHeader.setBrokerAddr(brokerAddr); requestHeader.setBrokerId(brokerId); requestHeader.setBrokerName(brokerName); requestHeader.setClusterName(clusterName); requestHeader.setHaServerAddr(haServerAddr); requestHeader.setCompressed(compressed); &#x2F;&#x2F; 将Broker的topic配置信息、过滤信息写入requestBody中 RegisterBrokerBody requestBody &#x3D; new RegisterBrokerBody(); requestBody.setTopicConfigSerializeWrapper(topicConfigWrapper); requestBody.setFilterServerList(filterServerList); &#x2F;&#x2F; 转码 final byte[] body &#x3D; requestBody.encode(compressed); final int bodyCrc32 &#x3D; UtilAll.crc32(body); requestHeader.setBodyCrc32(bodyCrc32); &#x2F;&#x2F; 使用CountDownLatch机制 并行注册 final CountDownLatch countDownLatch &#x3D; new CountDownLatch(nameServerAddressList.size()); for (final String namesrvAddr : nameServerAddressList) &#123; brokerOuterExecutor.execute(new Runnable() &#123; &#x2F;&#x2F; 省略... &#125;); &#125; &#x2F;&#x2F; 进入超时等待 try &#123; countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; &#125; &#125; return registerBrokerResultList;&#125; Broker将需要注册的信息整理好发送后，我们再来看看NameServer是如何接收的，这部分逻辑在RouteInfoManager类的registerBroker方法中: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115public RegisterBrokerResult registerBroker( final String clusterName, final String brokerAddr, final String brokerName, final long brokerId, final String haServerAddr, final TopicConfigSerializeWrapper topicConfigWrapper, final List&lt;String&gt; filterServerList, final Channel channel) &#123; &#x2F;&#x2F; 创建返回值 RegisterBrokerResult result &#x3D; new RegisterBrokerResult(); try &#123; try &#123; &#x2F;&#x2F; 加锁 this.lock.writeLock().lockInterruptibly(); &#x2F;&#x2F; 获取Broker所属集群名称 Set&lt;String&gt; brokerNames &#x3D; this.clusterAddrTable.get(clusterName); &#x2F;&#x2F; 初始化或保存Broker的集群名称 if (null &#x3D;&#x3D; brokerNames) &#123; brokerNames &#x3D; new HashSet&lt;String&gt;(); this.clusterAddrTable.put(clusterName, brokerNames); &#125; brokerNames.add(brokerName); &#x2F;&#x2F; 默认此Broker名称不是第一次注册 boolean registerFirst &#x3D; false; &#x2F;&#x2F; 获取Broker名称对应的所有节点(主从)信息 BrokerData brokerData &#x3D; this.brokerAddrTable.get(brokerName); &#x2F;&#x2F; 如果broker名称是第一次注册，初始化并标记 if (null &#x3D;&#x3D; brokerData) &#123; registerFirst &#x3D; true; brokerData &#x3D; new BrokerData(clusterName, brokerName, new HashMap&lt;Long, String&gt;()); this.brokerAddrTable.put(brokerName, brokerData); &#125; &#x2F;&#x2F; 获取当前broker的所有主从节点Map&lt;brokerId, IP:PORT&gt; Map&lt;Long, String&gt; brokerAddrsMap &#x3D; brokerData.getBrokerAddrs(); &#x2F;&#x2F; 遍历 Iterator&lt;Entry&lt;Long, String&gt;&gt; it &#x3D; brokerAddrsMap.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;Long, String&gt; item &#x3D; it.next(); &#x2F;&#x2F; 如果要注册的broker的地址已经存在，但是id不同，这属于脏数据，需要删除掉 &#x2F;&#x2F; 主要考虑到服务更换brokerId后立刻重启的情况 if (null !&#x3D; brokerAddr &amp;&amp; brokerAddr.equals(item.getValue()) &amp;&amp; brokerId !&#x3D; item.getKey()) &#123; it.remove(); &#125; &#125; &#x2F;&#x2F; 将当前Broker的IP地址注册到map中，如果put没有冲突也视为第一次注册 String oldAddr &#x3D; brokerData.getBrokerAddrs().put(brokerId, brokerAddr); registerFirst &#x3D; registerFirst || (null &#x3D;&#x3D; oldAddr); &#x2F;&#x2F; 如果Broker是主节点并且对应名称是第一次注册，保存topic的配置信息 if (null !&#x3D; topicConfigWrapper &amp;&amp; MixAll.MASTER_ID &#x3D;&#x3D; brokerId) &#123; if (this.isBrokerTopicConfigChanged(brokerAddr, topicConfigWrapper.getDataVersion()) || registerFirst) &#123; ConcurrentMap&lt;String, TopicConfig&gt; tcTable &#x3D; topicConfigWrapper.getTopicConfigTable(); if (tcTable !&#x3D; null) &#123; for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) &#123; this.createAndUpdateQueueData(brokerName, entry.getValue()); &#125; &#125; &#125; &#125; &#x2F;&#x2F; 保存心跳信息 BrokerLiveInfo prevBrokerLiveInfo &#x3D; this.brokerLiveTable.put(brokerAddr, new BrokerLiveInfo( System.currentTimeMillis(), topicConfigWrapper.getDataVersion(), channel, haServerAddr)); if (null &#x3D;&#x3D; prevBrokerLiveInfo) &#123; log.info(&quot;new broker registered, &#123;&#125; HAServer: &#123;&#125;&quot;, brokerAddr, haServerAddr); &#125; &#x2F;&#x2F; 保存过滤信息 if (filterServerList !&#x3D; null) &#123; if (filterServerList.isEmpty()) &#123; this.filterServerTable.remove(brokerAddr); &#125; else &#123; this.filterServerTable.put(brokerAddr, filterServerList); &#125; &#125; &#x2F;&#x2F; 如果注册的broker是从节点，通过名称寻找对应主节点，并保存主节点的IP地址 if (MixAll.MASTER_ID !&#x3D; brokerId) &#123; String masterAddr &#x3D; brokerData.getBrokerAddrs().get(MixAll.MASTER_ID); if (masterAddr !&#x3D; null) &#123; BrokerLiveInfo brokerLiveInfo &#x3D; this.brokerLiveTable.get(masterAddr); if (brokerLiveInfo !&#x3D; null) &#123; result.setHaServerAddr(brokerLiveInfo.getHaServerAddr()); result.setMasterAddr(masterAddr); &#125; &#125; &#125; &#125; finally &#123; this.lock.writeLock().unlock(); &#125; &#125; catch (Exception e) &#123; log.error(&quot;registerBroker Exception&quot;, e); &#125; return result;&#125; 服务注册的代码不是很难理解，就是往RouteInfoManager类的5个Map中塞数据，另外slave节点在注册后的返回值中，还会拿到对应master节点的IP地址，方便注册后展开数据同步操作。 服务发现Producer与Consumer在启动后会定时向NameServer获取路由信息，以保证后续工作的正常运行，定时任务代码如下: 123456789101112131415161718private void startScheduledTask() &#123; &#x2F;&#x2F; 其他代码...... this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; try &#123; MQClientInstance.this.updateTopicRouteInfoFromNameServer(); &#125; catch (Exception e) &#123; log.error(&quot;ScheduledTask updateTopicRouteInfoFromNameServer exception&quot;, e); &#125; &#125; &#125;, 10, this.clientConfig.getPollNameServerInteval(), TimeUnit.MILLISECONDS); &#x2F;&#x2F; 其他代码......&#125; 源码就写到这吧，写多了基本就没看的欲望了，Producer与Consumer在服务发现完毕后会得到TopicRouteData集合: 123456public class TopicRouteData extends RemotingSerializable &#123; private String orderTopicConf; private List&lt;QueueData&gt; queueDatas; private List&lt;BrokerData&gt; brokerDatas; private HashMap&lt;String&#x2F;* brokerAddr *&#x2F;, List&lt;String&gt;&#x2F;* Filter Server *&#x2F;&gt; filterServerTable;&#125; 通过queueDatas可以知道当前topic有多少个队列、每个队列所在的Broker服务名称，有了名称就可以通过brokerDatas找到对应的主从节点地址，有了地址就可以通过filterServerTable处理过滤逻辑、生产/消费消息。 故障剔除Broker节点每隔30秒会向NameServer发送一次心跳，并更新自身在brokerLiveTable中的心跳时间戳，NameServer节点每隔10秒会扫描一次brokerLiveTable，如果发现某个Broker的上次更新时间戳距离当前时间超过2分钟，则认为Broker已死亡，剔除其注册信息并关闭长连接。 故障节点剔除后并不会像Kafka那样采用再均衡策略通知Producer与Consumer，而是等待他们的服务发现机制自己去感知。这就意味着某个Broker节点挂了之后Producer与Consumer最长要等30秒才会感知到。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"rocketmq(二)服务部署","slug":"RocketMQ服务部署","date":"2020-05-03T05:00:00.000Z","updated":"2020-12-19T09:13:32.209Z","comments":true,"path":"2020/05/03/RocketMQ服务部署/","link":"","permalink":"http://yoursite.com/2020/05/03/RocketMQ%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/","excerpt":"","text":"前言由于RocketMQ是使用纯Java编写的，所以NameServer、Broker的运行必须依赖于JDK环境，安装过程中需要下载依赖，因此也必须要用到maven依赖，JDK就不写了，从maven的安装开始写。 maven下载文件wget http:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;maven&#x2F;binaries&#x2F;apache-maven-3.2.2-bin.tar.gz 解压文件tar -zxvf apache-maven-3.2.2-bin.tar.gz 编辑环境变量:vim &#x2F;etc&#x2F;profile 添加环境变量:export MAVEN_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;apache-maven-3.2.2export PATH&#x3D;$MAVEN_HOME&#x2F;bin:$PATH 刷新环境变量source &#x2F;etc&#x2F;profile 检查是否安装成功mvn -v 进入配置文件夹cd &#x2F;usr&#x2F;local&#x2F;apache-maven-3.2.2&#x2F;conf 编辑xml配置文件vi setting.xml 修改镜像仓库&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt; &lt;settings xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;settings-1.0.0.xsd&quot;&gt; &lt;localRepository&gt;&#x2F;usr&#x2F;local&#x2F;repo&lt;&#x2F;localRepository&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;&#x2F;id&gt; &lt;name&gt;aliyun maven&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt; &lt;mirrorOf&gt;*&lt;&#x2F;mirrorOf&gt; &lt;&#x2F;mirror&gt; &lt;&#x2F;mirrors&gt; &lt;&#x2F;settings&gt; NameServer进入/apply/rocketmq/文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F; 下载安装包wget http:&#x2F;&#x2F;mirrors.hust.edu.cn&#x2F;apache&#x2F;rocketmq&#x2F;4.7.1&#x2F;rocketmq-all-4.7.1-source-release.zip 解压安装包unzip rocketmq-all-4.7.1-source-release.zip 重命名mv rocketmq-all-4.7.1-source-release &#x2F;apply&#x2F;rocketmq&#x2F;broker-a 进入文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;broker-a 下载依赖mvn -Prelease-all -DskipTests clean install -U 进入执行文件夹cd distribution&#x2F;target&#x2F;rocketmq-4.7.1&#x2F;rocketmq-4.7.1&#x2F;bin 编辑启动文件vim runserver.sh 修改jvm启动参数JAVA_OPT&#x3D;&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn512m -XX:MetaspaceSize&#x3D;128m -XX:MaxMetaspaceSize&#x3D;320m&quot; 创建conf文件夹mkdir -p &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf 创建propertiestouch &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;namesrv-a.properties 编辑propertiesvim &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;namesrv-a.properties 添加端口号# 服务端口号listenPort&#x3D;9876 进入执行文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;namesrv-a&#x2F;distribution&#x2F;target&#x2F;rocketmq-4.7.1&#x2F;rocketmq-4.7.1&#x2F;bin 启动nohup sh mqnamesrv -c &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;namesrv-a.properties &amp; 注:如果NameServer仅部署一台，或者每台都在不同的机器上，properties可以不配置(端口默认就是9876)，如果本地测试想要在一台服务器上配置多个，就需要区分端口 Broker进入/apply/rocketmq/文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F; 下载安装包wget http:&#x2F;&#x2F;mirrors.hust.edu.cn&#x2F;apache&#x2F;rocketmq&#x2F;4.7.1&#x2F;rocketmq-all-4.7.1-source-release.zip 解压安装包unzip rocketmq-all-4.7.1-source-release.zip 重命名mv rocketmq-all-4.7.1-source-release &#x2F;apply&#x2F;rocketmq&#x2F;broker-a 进入文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;broker-a 下载依赖mvn -Prelease-all -DskipTests clean install -U 进入执行文件夹cd distribution&#x2F;target&#x2F;rocketmq-4.7.1&#x2F;rocketmq-4.7.1&#x2F;bin 编辑启动文件vim runbroker.sh 修改jvm启动参数JAVA_OPT&#x3D;&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn512m&quot; 创建store文件夹mkdir -p &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;store-broker-a 创建commitlog文件夹mkdir -p &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;store-broker-a&#x2F;commitlog 创建propertiestouch &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;broker-a.properties 编辑propertiesvim &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;broker-a.properties 添加属性#服务端口号listenPort&#x3D;10911#集群名brokerClusterName &#x3D; lvt-cluster#broker服务名brokerName &#x3D; broker-a#0表示master，大于0表示各个slavebrokerId &#x3D; 0#删除文件时间点，默认凌晨 4点deleteWhen &#x3D; 04#文件保留时间,默认48小时fileReservedTime &#x3D; 48#Broker角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole &#x3D; ASYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType &#x3D; ASYNC_FLUSH#公网brokerIP1 &#x3D; 172.0.0.1#注册中心地址，多个使用;分开namesrvAddr&#x3D;172.0.0.1:9876#是否自动创建，生产建议关闭autoCreateTopicEnable&#x3D;true#持久化消息存储根路径storePathRootDir&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;store-broker-a#commitLog文件存储路径storePathCommitLog&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;store-broker-a&#x2F;commitlog 进入执行文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;broker-a&#x2F;distribution&#x2F;target&#x2F;rocketmq-4.7.1&#x2F;rocketmq-4.7.1&#x2F;bin 启动nohup sh mqbroker -c &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;broker-a.properties &amp; 注:在网上看到很多资料将配置写在broker.conf中，上述的不是方式不会读取这个配置文件，如果这么做也不会报错，因为这些参数全部自带默认值。 另外在配置属性中关于store的一些路径只能设置storePathRootDir、storePathCommitLog这俩个，其他的写进去会导致项目无法启动(如果写的路径是错的则不会，应该是没检测到路径就改用默认值了)。 还有个奇怪的事情，我在腾讯云部署的伪Broker集群，发现不同的节点端口号不能相邻，否则会报端口占用，目前是各服务的端口号隔几百。 Console进入git网址，下载源码(点击Download ZIP)https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;rocketmq-externals.git 上传到服务器/apply/rocketmq文件夹，并解压unzip &#x2F;apply&#x2F;rocketmq&#x2F;rocketmq-externals-master.zip 重命名文件夹mv &#x2F;apply&#x2F;rocketmq&#x2F;rocketmq-externals-master console 创建数据文件夹mkdir -p &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;console-data 编辑application.propertiesvim &#x2F;apply&#x2F;rocketmq&#x2F;console&#x2F;rocketmq-console&#x2F;src&#x2F;main&#x2F;resources&#x2F;application.properties 修改属性# 注册中心地址端口rocketmq.config.namesrvAddr&#x3D;172.0.0.1:9876# 存放数据路径rocketmq.config.dataPath&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;console-data# 是否需要登陆rocketmq.config.loginRequired&#x3D;true 编辑users.propertiesvim &#x2F;apply&#x2F;rocketmq&#x2F;console&#x2F;rocketmq-console&#x2F;src&#x2F;main&#x2F;resources&#x2F;users.properties 设置登录控制台的账号密码(注释的汉字别打进去，否则下面编译不通过)# 设置管理员，格式:username&#x3D;password[,N] 其中N是可选项:0为普通用户 1为管理员admin&#x3D;admin,1# 普通成员member&#x3D;member 进入解压文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;console&#x2F;rocketmq-console 执行编译(一定要编辑完配置在编译，否则配置无效)mvn clean package -Dmaven.test.skip&#x3D;true 进入jar包文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;console&#x2F;rocketmq-console&#x2F;target 启动服务nohup java -jar rocketmq-console-ng-2.0.0.jar &amp; 注:如果rocketmq.config.loginRequired设置为false，则不需要编辑users.properties设置登录用的账号密码。在设置为true的情况下，如果不编辑users.properties文件设置账号密码，会有个默认账号可以直接登录(admin/admin)，生产环境为了安全起见，建议自定义账号密码。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(一)架构原理","slug":"RocketMQ架构原理","date":"2020-05-01T05:00:00.000Z","updated":"2020-12-13T15:48:23.467Z","comments":true,"path":"2020/05/01/RocketMQ架构原理/","link":"","permalink":"http://yoursite.com/2020/05/01/RocketMQ%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86/","excerpt":"","text":"简介RocketMQ是阿里巴巴开源的消息中间件，使用Java语言开发，具有高吞吐量、高可用性，适合大规模分布式系统应用的特点。设计方面参考了kafka的整体机制和架构设计，并在此基础上添加了分布式事务、定时消息、消费失败重试、回溯消息等功能，虽然在吞吐量上无法企及kafka，但是扩展的诸多功能相对于kafka来说，更能胜任电商、金融等领域的复杂业务场景。 核心组件Broker:Broker是集群中最核心的，也是最复杂的组件，负责消息的存储、投递、查询，以及保证服务的高可用，支持容错机制、灾备机制、报警机制和丰富的监控指标。 NameServer:NameServer可以看作是RocketMQ的注册中心，类似于Dubbo、kafka的注册中心zookeeper，broker启动后会将自身管理的topic-queue信息注册到NameServer，为Producer或Consumer提供路由。 Name Server集群实例之间不会互相通讯，但是Broker会向所有的Name注册路由信息，所以每个NameServer实例上都保存了完整的路由信息。 Producer:Producer是发布消息的角色，在程序启动后通过NameServer获取所有Broker的路由信息，通过多种负载均衡的方式，选择相应的Broker Server 集群中的Queue发送消息。Producer 在发送消息时，支持快速失败，并且是低延迟的。 Consumer:Consumer是消费消息的角色，支持PUSH和PULL两种获取消息模式，支持集群和广播两种消费消息模式。 消息领域模型Topic:Topic的作用是将整个RocketMQ集群的消息进行划分，使不同类型的消息区分开来，以便于消费者针对不同的消息类型做不同的业务处理。 Tag:Tag可以看作是消息的二级分类，一般在相同业务模块中通过引入标签来标记不同用途的消息，另外RocketMQ允许消费者按照Tag对消息进行过滤，也可以通过Tag过滤不需要的数据。 Message:Message就是我们发送或消费的消息，用户在发送消息的时候可以设置messageKey，也就是消息的唯一识别MessageId，便于后续的查询和追踪。 Producer Group:开发者在启动Producer时可以指定一个生产组，如果没有指定会自动生成一个(默认为DEFAULT_PRODUCER)。Producer Group主要用于推送事务消息，比如Producer在投递事务消息时宕机，本地事务回滚，可以继续联系该组下的另外一个生产者实例，不至于导致业务走不下去。 Consumer Group:开发者在启动Producer时可以指定一个消费组，用于负载均衡共同消费消息。 部署模型 Broker特点:Broker服务分为Master与Slave，一个Master可以对应多个Slaver，Master与Slaver的对应关系通过指定相同的BrokerName、不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slaver。 Producer特点:Producer服务会随机与NameServer集群中的一个节点建立长连接，定期从NameServer获取topic-queue路由信息，然后与topic-queue所在的 BrokerServer的Master节点建立长连接，并且会定时向Master发送心跳。Producer集群完全是无状态的，可以随意集群部署。 Consumer特点:Consumer服务会随机与NameServer集群中的一个节点建立长连接，定期从NameServer获取topic-queue路由信息，然后与topic-queue所在的BrokerServer的Master节点建立长连接，并且会定时向Master和Salve发送心跳。 Consumer既可以从Master订阅消息，也可以从Salve订阅消息，Consumer在获取消息的时候，BrokerServer的Master节点会根据获取消息的偏移量与最大偏移量的距离、服务器是否可读等因素建议Consumer下次是从 Master或者Salve获取消息。 topic分布集群中所有topic都是以queue(1个或多个)的形式分散存储在各broker节点中，其中每个queue仅仅保存topic的一部分消息数据。这种架构设计与redis、elasticsearch的分片模式很相似，可以在整个RocketMQ集群服务运行过程中动态改变queue的数量，来控制同一时刻topic的并行处理能力。 假设一个Broker集群有3个节点，并且整个集群存储了3个topic: topic名称 queue数量 red 4 blue 5 green 6 topic在Broker的分布图: 注:不同的master节点存储的topic-queue数据完全不一致，而master与对应的slave节点负责的数据完全一致","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"多线程(十七) 线程池","slug":"线程池","date":"2020-03-17T05:00:00.000Z","updated":"2020-11-28T05:59:53.061Z","comments":true,"path":"2020/03/17/线程池/","link":"","permalink":"http://yoursite.com/2020/03/17/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"简介解释线程池之前要先说一下池化技术，池化技术简单点来说，就是提前保存大量的资源，以备不时之需。而线程池就是利用池化技术保存线程资源的容器，同样也是Java多线程编程的重要基础。 多线程优点: 避免线程频繁的创建以及销毁带来的资源浪费 提高响应速度，任务到达时提前保存的线程可以立即执行，不需要等待临时创建 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。 提供定时执行、定期执行、单线程、并发数控制等功能。 继承体系 Executor: 123public interface Executor &#123; void execute(Runnable command);&#125; Executor类是线程池顶级接口，只定义了一个执行无返回值任务的方法。 ExecutorService: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 public interface ExecutorService extends Executor &#123; &#x2F;&#x2F; 关闭线程池，不再接受新任务，但已经提交的任务会执行完成 void shutdown(); &#x2F;&#x2F; 立即关闭线程池，尝试停止正在运行的任务，未执行的任务将不再执行 &#x2F;&#x2F; 被迫停止及未执行的任务将以列表的形式返回 List&lt;Runnable&gt; shutdownNow(); &#x2F;&#x2F; 检查线程池是否已关闭 boolean isShutdown(); &#x2F;&#x2F; 检查线程池是否已终止，只有在shutdown()或shutdownNow()之后调用才有可能为true boolean isTerminated(); &#x2F;&#x2F; 在指定时间内线程池达到终止状态了才会返回true boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &#x2F;&#x2F; 执行有返回值的任务，任务的返回值为task.call()的结果 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &#x2F;&#x2F; 执行有返回值的任务，任务的返回值为这里传入的result,相当于给指针赋值 &#x2F;&#x2F; 当然只有当任务执行完成了调用get()时才会返回 &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); &#x2F;&#x2F; 执行有返回值的任务，返回值.get()为线程返回值 Future&lt;?&gt; submit(Runnable task); &#x2F;&#x2F; 批量执行任务，只有当这些任务都完成了这个方法才会返回，可以获取线程ID来区分集合中的返回值 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &#x2F;&#x2F; 在指定时间内批量执行任务，未执行完成的任务将被取消 &#x2F;&#x2F; 这里的timeout是所有任务的总时间，不是单个任务的时间 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &#x2F;&#x2F; 返回任意一个已完成任务的执行结果，未执行完成的任务将被取消 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &#x2F;&#x2F; 在指定时间内如果有任务已完成，则返回任意一个已完成任务的执行结果，未执行完成的任务将被取消 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ExecutorService类仍然只是接口，在Executor的基础上增加了关闭线程池、池内线程执行等相关操作。 ScheduledExecutorService: 12345678910111213141516171819202122 public interface ScheduledExecutorService extends ExecutorService &#123; &#x2F;&#x2F; 在指定延时后执行一次 public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit); &#x2F;&#x2F; 在指定延时后执行一次 public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); &#x2F;&#x2F; 在指定延时后开始执行，并在之后以指定时间间隔重复执行（间隔不包含任务执行的时间） &#x2F;&#x2F; 无论任务是否完成，只要到时间就执行下一次 public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); &#x2F;&#x2F; 在指定延时后开始执行，并在之后以指定延时重复执行（间隔包含任务执行的时间） &#x2F;&#x2F; 上次任务结束才开始倒计时，只可能一个线程在工作 public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);&#125; ScheduledExecutorService接口在ExecutorService的基础上增加了定时任务的相关功能，这些定时功能又分为单次执行和重复执行。 AbstractExecutorService: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191public class ThreadPoolExecutor extends AbstractExecutorService&#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; public Future&lt;?&gt; submit(Runnable task) &#123; if (task &#x3D;&#x3D; null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask &#x3D; newTaskFor(task, null); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task &#x3D;&#x3D; null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask &#x3D; newTaskFor(task, result); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task &#x3D;&#x3D; null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask &#x3D; newTaskFor(task); execute(ftask); return ftask; &#125; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; if (tasks &#x3D;&#x3D; null) throw new NullPointerException(); int ntasks &#x3D; tasks.size(); if (ntasks &#x3D;&#x3D; 0) throw new IllegalArgumentException(); ArrayList&lt;Future&lt;T&gt;&gt; futures &#x3D; new ArrayList&lt;Future&lt;T&gt;&gt;(ntasks); ExecutorCompletionService&lt;T&gt; ecs &#x3D; new ExecutorCompletionService&lt;T&gt;(this); try &#123; &#x2F;&#x2F; Record exceptions so that if we fail to obtain any &#x2F;&#x2F; result, we can throw the last exception we got. ExecutionException ee &#x3D; null; final long deadline &#x3D; timed ? System.nanoTime() + nanos : 0L; Iterator&lt;? extends Callable&lt;T&gt;&gt; it &#x3D; tasks.iterator(); &#x2F;&#x2F; Start one task for sure; the rest incrementally futures.add(ecs.submit(it.next())); --ntasks; int active &#x3D; 1; for (;;) &#123; Future&lt;T&gt; f &#x3D; ecs.poll(); if (f &#x3D;&#x3D; null) &#123; if (ntasks &gt; 0) &#123; --ntasks; futures.add(ecs.submit(it.next())); ++active; &#125; else if (active &#x3D;&#x3D; 0) break; else if (timed) &#123; f &#x3D; ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f &#x3D;&#x3D; null) throw new TimeoutException(); nanos &#x3D; deadline - System.nanoTime(); &#125; else f &#x3D; ecs.take(); &#125; if (f !&#x3D; null) &#123; --active; try &#123; return f.get(); &#125; catch (ExecutionException eex) &#123; ee &#x3D; eex; &#125; catch (RuntimeException rex) &#123; ee &#x3D; new ExecutionException(rex); &#125; &#125; &#125; if (ee &#x3D;&#x3D; null) ee &#x3D; new ExecutionException(); throw ee; &#125; finally &#123; for (int i &#x3D; 0, size &#x3D; futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; try &#123; return doInvokeAny(tasks, false, 0); &#125; catch (TimeoutException cannotHappen) &#123; assert false; return null; &#125; &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return doInvokeAny(tasks, true, unit.toNanos(timeout)); &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; if (tasks &#x3D;&#x3D; null) throw new NullPointerException(); ArrayList&lt;Future&lt;T&gt;&gt; futures &#x3D; new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done &#x3D; false; try &#123; for (Callable&lt;T&gt; t : tasks) &#123; RunnableFuture&lt;T&gt; f &#x3D; newTaskFor(t); futures.add(f); execute(f); &#125; for (int i &#x3D; 0, size &#x3D; futures.size(); i &lt; size; i++) &#123; Future&lt;T&gt; f &#x3D; futures.get(i); if (!f.isDone()) &#123; try &#123; f.get(); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; &#125; &#125; done &#x3D; true; return futures; &#125; finally &#123; if (!done) for (int i &#x3D; 0, size &#x3D; futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; if (tasks &#x3D;&#x3D; null) throw new NullPointerException(); long nanos &#x3D; unit.toNanos(timeout); ArrayList&lt;Future&lt;T&gt;&gt; futures &#x3D; new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done &#x3D; false; try &#123; for (Callable&lt;T&gt; t : tasks) futures.add(newTaskFor(t)); final long deadline &#x3D; System.nanoTime() + nanos; final int size &#x3D; futures.size(); &#x2F;&#x2F; Interleave time checks and calls to execute in case &#x2F;&#x2F; executor doesn&#39;t have any&#x2F;much parallelism. for (int i &#x3D; 0; i &lt; size; i++) &#123; execute((Runnable)futures.get(i)); nanos &#x3D; deadline - System.nanoTime(); if (nanos &lt;&#x3D; 0L) return futures; &#125; for (int i &#x3D; 0; i &lt; size; i++) &#123; Future&lt;T&gt; f &#x3D; futures.get(i); if (!f.isDone()) &#123; if (nanos &lt;&#x3D; 0L) return futures; try &#123; f.get(nanos, TimeUnit.NANOSECONDS); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; catch (TimeoutException toe) &#123; return futures; &#125; nanos &#x3D; deadline - System.nanoTime(); &#125; &#125; done &#x3D; true; return futures; &#125; finally &#123; if (!done) for (int i &#x3D; 0, size &#x3D; futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125;&#125; AbstractExecutorService是个抽象类，首先重写了ExecutorService类的submit()、invokeAny()、invokeAll()方法，另外还提供了一个newTaskFor方法用于构建RunnableFuture对象。 ThreadPoolExecutor: 123public class ThreadPoolExecutor extends AbstractExecutorService &#123; &#125; ThreadPoolExecutor是一个普通类，也是我们使用线程池时需要创建的实例，内部集成了AbstractExecutorService抽象类，也就意味着它包含了以上介绍的所有接口(除了ScheduledExecutorService)的处理逻辑，也是本章节要着重要分析的类。 ScheduledThreadPoolExecutor: 12345 public class ScheduledThreadPoolExecutor extends ThreadPoolExecutor implements ScheduledExecutorService &#123; &#x2F;&#x2F; 属性方法..&#125; ScheduledThreadPoolExecutor类看继承实现关系就能看明白，在继承了ThreadPoolExecutor类所有功能的情况下，通过实现ScheduledExecutorService接口又增加了线程定时任务执行的相关逻辑。 ForkJoinPool: 123public class ForkJoinPool extends AbstractExecutorService &#123; &#x2F;&#x2F; 属性方法..&#125; ForkJoinPool比较适合计算密集型的任务，以后有机会用到的话再写。 构造器参数在ThreadPoolExecutor类中有4个构造器，但最终调用的是如下这个构造器: 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize:核心线程大小，即在没有任务需要执行的时候线程池的大小，当所有核心线程都在执行任务时仍然有新任务提交，会直接进入阻塞队列。除非调用allowCoreThreadTimeOut()方法设置为true，这种情况下核心线程数空闲下来也会被回收掉。另外核心线程默认是懒加载模式，只有等到有任务的时候才会启动，比如常见的数据库连接池，在启动项目后首次访问数据库会打印{dataSource-1} inited日志，其实就是在懒加载核心线程，除非你调用prestartCoreThread()或prestartAllCoreThreads()方法提前启动核心线程。 maximumPoolSize:线程池中允许的最大线程数，如果说corePoolSize是控制同一时刻线程执行数量的下限，maximumPoolSize就是与之对应的上限。当阻塞队列已满并且当前线程个数小于maximumPoolSize，那么会创建新的线程来执行任务。这里值得一提的是getLargestPoolSize()方法，调用该方法会返回线程池在整个生命周期中曾经出现的最大线程个数。 keepAliveTime:线程空闲时的存活时间，当线程持续keepAliveTime时间处于空闲状态时，这个空闲线程会被销毁。默认情况下，该参数只会对非核心线程生效，如果调用allowCoreThreadTimeOut()被设置为true时，无论线程数多少，线程处于空闲状态超过一定时间就会被销毁掉。 unit:keepAliveTime的单位，TimeUnit是一个枚举类型，具体哪些就没必要讲了。 workQueue:阻塞队列，当所有核心线程都在执行任务时仍然有新任务提交时，会加入此队列等待。构造器中阻塞队列的范型必须是Runnable类型，换句话说只有实现Runnable接口的类才可以加入阻塞队列，这个下面会单独讲。 threadFactory:线程工厂，用于新线程的创建，创建时可以设定线程名、是否为daemon线程等等。 handler:拒绝策略，当阻塞队列已满并且线程池中的线程数量也达到最大限制，必须采取一种策略处理该任务。线程池提供了四种决绝策略，如果仍然无法满足业务需求，还可以通过实现RejectedExecutionHandler接口自定义拒绝策略。 阻塞队列线程池允许设置的阻塞队列对象，用来保存等待被执行的任务的阻塞队列，队列全部都是BlockingQueue接口的实现类，并且范型必须实现Runable接口，如下阻塞队列: ArrayBlockingQueue(有界队列):是一个基于数组实现的的阻塞队列，队列长度在创建后固定不可修改，此队列按照先进先出（FIFO）的原则对元素进行排序。ArrayBlockingQueue插入数据和获取数据，需要竞争到锁才可以执行，也就意味着这俩个操作无法并行执行，另外可以通过构造器参数设置竞争的公平性。 LinkedBlockingQueue(无界队列):是一个基于链表实现的的阻塞队列，如果在创建时没有在构造器中指定容量，那么容量默认为Integer.MAX_VALUE。LinkedBlockingQueue队列的插入和消费元素采用分离的锁控制，也就意味着这俩种操作可以并行执行，整体的吞吐性能要高于ArrayBlockingQueue，当队列达到最大容量时，插入元素的线程会进入阻塞，直到队列的元素被消费掉腾出空间才会被唤醒继续执行。 DelayQueue(延迟队列):此队列中在长度方面没有任何限制，因此往队列插入元素时不会产生任何阻塞，如果线程池任务想要加入此队列除了要实现Runnable接口外，还需要实现Delayed接口。获取元素时，只有当元素的延迟时间到了才可以从队列中获取到该元素，否则会进入阻塞。 PriorityBlockingQueue(优先级队列):此队列在长度方面仍然没有限制，插入元素操作也不会产生任何阻塞，如果线程池任务想要加入此队列除了要实现Runnable接口外，还需要实现Compator接口。在使用没有容量限制的队列时一定要注意，插入元素的速度绝对不能大于消费元素的速度，否则随着时间的积累，会耗尽系统的内存资源造成内存泄漏。 SynchronousQueue(无缓冲等待队列):队列中仅保存一个元素，只有对列为空才可以添加元素，之后只有等待元素被消费才可以继续添加。拥有公平(FIFO)和非公平(LIFO)策略，可以在创建时指定。 拒绝策略线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务。拒绝策略并不是设置就一定生效，比如阻塞队列选择无界的情况下，基本上队列堆积的任务没有到达Inteher.MAX_VALUE时，内存就爆了。java提供了四种线程池拒绝策略，当然你也可以通过继承这四个策略类，或者实现RejectedExecutionHandler接口自定义拒绝策略: AbortPolicy(异常中止策略):直接抛出RejectedExecutionException异常，也是线程池的默认拒绝策略。这种策略使用的时候要处理好抛出的异常，避免调用线程池的主线程因为异常打断后续的执行流程。 DiscardPolicy(丢弃策略):直接丢弃任务，因为此类在实现RejectedExecutionHandler接口并重写的rejectedExecution方法中啥都没做。如果你提交的任务无关紧要，可以选择使用此策略，我个人感觉这个策略几乎用不上，但凡有点良心的开发都会打印一行日志意思意思… DiscardOldestPolicy(弃老策略):放弃阻塞队列中最靠前的任务，并尝试让线程池执行当前线程。这种策略仍然会悄悄的丢掉任务，只不过保证新产生的任务优先执行，应该是满足特定场景使用的吧。 CallerRunsPolicy(调用者运行策略):当触发拒绝策略时，只要线程池没有关闭，就由提交任务的当前线程处理。原理是直接运行Runnable的run()方法，直接调用run()的方式都懂得，会阻塞调用者直到执行完毕。这种方式看似比较稳妥，能保证所有的任务都会被执行，但是拒绝策略的rejectedExecution()方法是包含在线程池的execute()方法中调用，execute()在执行过程中会占用一条线程，如果多个线程进入此阻塞策略并且线程执行时间过长，会严重影响线程池处理任务的吞吐量。因此这种策略一般在不允许失败、对性能要求不高、并发亮较小的场景下使用。 自定义:如果以上四种策略无法满足你的需求，那就需要考虑自定义策略了。比如dubbo的工作线程池自定义的拒绝策略是继承AbortPolicy类，打印完日志后调用父类抛异常、比如ActiveMQ中的拒绝策略属于最大努力执行任务型，当触发拒绝策略时，在尝试一分钟的时间重新将任务塞进任务队列，当一分钟超时还没成功时，就抛出异常。 参数设置线程池的使用难度不大，但用好线程池就需要对常用参数的含义有一定的理解，并且要考虑到应用程序所在服务器的CPU配置、任务的执行特点、任务执行过程中的内存使用率等，如果任务中涉及下游服务的调用，还要考虑到下游服务的抗并发能力等。可以将线程池要执行的任务进行分类: CPU密集型:例如内存中的计算、比较、转化等，尽量使用较小的线程池，一般为CPU核心数+1。即使当计算密集型的线程偶尔由于缺失故障或者其他原因而暂停时，这个额外的线程也能确保CPU的时钟周期不会被浪费。因为CPU密集型任务使得CPU使用率很高，尽量减少线程之间竞争引起的上下文切换带来的资源浪费。 IO密集型:例如网络IO(调用其他服务或接口)、磁盘IO(读写文件)等，可以使用稍大的线程池，一般为2*CPU核心数+1(如果调用下游服务还要考虑抗并发因素)。因为IO操作期间不占用CPU，不要让CPU闲下来，应加大线程数量，因此可以让CPU在等待IO的时候去处理别的任务，充分利用CPU时间。 混合型:可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。 注:通过公式推算出的线程池参数仅仅只是理想状态下的最优方案，实际最优参数需要根据服务器运行情况比，如线程执行过程中占用CPU时间、最大线程数峰值、拒绝策略出现频率等不断调整参数。 springboot线程池配置自定义线程池: 1234567891011121314151617181920212223242526272829@Configuration@EnableAsyncpublic class ThreadPoolConfig implements AsyncConfigurer &#123; &#x2F;** * 自定义线程池，若不重写会使用默认的线程池 *&#x2F; @Bean(&quot;asyncExecutor&quot;) @Override public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor asyncExecutor &#x3D; new ThreadPoolTaskExecutor(); asyncExecutor.setCorePoolSize(16); asyncExecutor.setMaxPoolSize(32); asyncExecutor.setKeepAliveSeconds(180); asyncExecutor.setQueueCapacity(200); asyncExecutor.setThreadNamePrefix(&quot;buss-thread&quot;); &#x2F;&#x2F; 线程命名前缀 asyncExecutor.initialize(); return asyncExecutor; &#125; &#x2F;** * 自定义拒绝策略 *&#x2F; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return new AbortPolicy(); &#125;&#125; 注: @EnableAsync注解一定要加，否则线程池异步调用不生效。 配置异步任务: 1234567891011121314151617181920212223242526@Servicepublic class UserServiceImpl implements UserService &#123; @Override public void updateById(UserTo to) &#123; &#x2F;&#x2F; ... &#125; @Async @Override public void asyncUpdateById(UserTo to) &#123; updateById(to); &#125; @Async @Override public Future&lt;Boolean&gt; asyncUpdateById(UserTo to) &#123; try&#123; updateById(to); &#125; catch()&#123; return new AsyncResult&lt;&gt;(Boolean.FALSE); &#125; return new AsyncResult&lt;&gt;(Boolean.TRUE); &#125;&#125; 如果想要使用异步方式调用某个方法，只需要加上@Async注解即可，如果需要返回值必须使用Future，其他返回值类型在调用后会立刻返回null，如果不需要返回值直接将方法返回值设置为void。最好封装一个异步方法，减少对原始方法的破坏，避免其他非异步使用的线程调用后返回null导致程序错误。 注:如果应用配置了多个线程池，则需要在@Async注解的value属性中指定线程池Bean名称，没有指定的情况下使用默认线程池(@primary注解的bean) 总结","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十六) ThreadLocal","slug":"ThreadLocal","date":"2020-03-16T05:00:00.000Z","updated":"2020-11-24T07:53:13.897Z","comments":true,"path":"2020/03/16/ThreadLocal/","link":"","permalink":"http://yoursite.com/2020/03/16/ThreadLocal/","excerpt":"","text":"简介ThreadLocal用于存储线程的局部变量，通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题，每个线程都可以通过set()和get()来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离。ThreadLocal诞生于JDK 1.2，直到JDK5.0开始支持范型。 应用场景ThreadLocal的应用场景比较广泛，例如web项目中登陆信息的存储、IOC中Request作用域的实现、Spring事物管理的实现、线程同步工具Exchanger的实现等。除了登录信息的存储以外，其他的多多少少都是涉及到底层的源码，写出来篇幅太大，所以下面简单讲述一下如何使用ThreadLocal存储登陆信息。 一般浏览器发送http请求到后端服务器，都会将用户信息的token以cookie或header形式携带过去，并在后端拦截器中对token校验是否合法。如果请求的接口中需要用到一次或多次用户信息(比如ID、名称、生日、职级等)进行业务处理，这就需要将用户信息从controller一层一层作为参数传递下去，这无疑增加了代码的复杂程度，重点是不够优雅，使用ThreadLocal完全可以避免这个问题。 1.用户信息对象: 12345678910111213141516@Data@ToStringpublic class UserInfo &#123; private Long id; private Long deptId; private String name; private String phone; private String email; private String birthday;&#125; 2.创建一个ThreadLocal封装类，内部定义一个私有ThreadLocal并对外提供get、set方法: 1234567891011121314151617181920212223242526public class UserInfoThreadLocal &#123; private static final ThreadLocal&lt;UserInfo&gt; threadLocal &#x3D; new ThreadLocal&lt;&gt;(); public static void set(UserInfo value)&#123; threadLocal.set(value); &#125; public static UserInfo get()&#123; return threadLocal.get(); &#125; public static void remove()&#123; threadLocal.remove(); &#125; public static UserInfo getAndValidate()&#123; UserInfo userInfo &#x3D; get(); if(userInfo &#x3D;&#x3D; null)&#123; &#x2F;&#x2F; 抛业务异常 &#125; return userInfo; &#125;&#125; 3.拦截器负责校验信息，并将合法的用户信息注册到ThreadLocal中: 12345678910111213141516171819202122232425262728293031@Componentpublic class LoginInfoInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String token &#x3D; request.getHeader(&quot;token&quot;); if(StringUtils.isEmpty(token))&#123; &#x2F;&#x2F; 抛业务异常 &#125; &#x2F;&#x2F; 模拟查询用户信息 UserInfo userInfo &#x3D; new UserInfo(); userInfo.setId(323L); userInfo.setDeptId(542L); userInfo.setPhone(&quot;110&quot;); userInfo.setEmail(&quot;110@163.com&quot;); userInfo.setBirthday(&quot;1995-12-20&quot;); &#x2F;&#x2F; 放入UserInfoThreadLocal UserInfoThreadLocal.set(userInfo); return true; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; UserInfoThreadLocal.remove(); &#125;&#125; 4.web项目的controller层，获取并打印拦截器查询并校验通过的用户信息: 1234567891011121314151617@RestControllerpublic class TestController &#123; @Autowired private TestService testService; @RequestMapping(&quot;&#x2F;test&quot;) public void test()&#123; &#x2F;&#x2F; 获取用户信息并打印 UserInfo userInfo &#x3D; UserInfoThreadLocal.getAndValidate(); System.out.println(&quot;controller:&quot; + JSONObject.toJSONString(userInfo)); &#x2F;&#x2F; 调用service testService.testQuery(); &#125;&#125; 5.web项目的service层，获取并打印拦截器查询并校验通过的用户信息: 123456789101112131415161718192021@Servicepublic class TestServiceImpl implements TestService &#123; @Override public void testQuery() &#123; &#x2F;&#x2F; 获取用户信息并打印 UserInfo userInfo &#x3D; UserInfoThreadLocal.getAndValidate(); System.out.println(&quot;testQuery:&quot; + JSONObject.toJSONString(userInfo)); &#x2F;&#x2F; 调用私有方法 testMethod(); &#125; private void testMethod()&#123; &#x2F;&#x2F; 获取用户信息并打印 UserInfo userInfo &#x3D; UserInfoThreadLocal.getAndValidate(); System.out.println(&quot;testMethod:&quot; + JSONObject.toJSONString(userInfo)); &#125;&#125; 打印结果:controller:{“birthday”:”1995-12-20”,”deptId”:542,”email”:”&#49;&#x31;&#x30;&#x40;&#49;&#x36;&#51;&#46;&#x63;&#111;&#x6d;“,”id”:323,”phone”:”110”}testQuery:{“birthday”:”1995-12-20”,”deptId”:542,”email”:”&#49;&#x31;&#x30;&#64;&#x31;&#x36;&#51;&#x2e;&#x63;&#x6f;&#109;“,”id”:323,”phone”:”110”}testMethod:{“birthday”:”1995-12-20”,”deptId”:542,”email”:”&#x31;&#x31;&#x30;&#x40;&#x31;&#x36;&#x33;&#x2e;&#99;&#111;&#x6d;“,”id”:323,”phone”:”110”} 从上面的Demo代码可以看出来，只要在拦截器层面对token的验证通过，并将用户信息存储在创建的ThreadLocal对象中，就可以在任何逻辑层、任何方法直接获取用户信息，提高了代码的简介程度。 存储原理Thread类中有个成员变量threadLocals，这个变量的引用类型是ThreadLocal中的一个内部类ThreadLocalMap，这个类没有实现Map接口，本质上是一个table数组，数组中每个元素都是K-V键值对组成的Entry对象，其中K就是ThreadLocal实例，V就是要存储的局部变量对象。 源码解析hash算法ThreadLocalMap的存储逻辑和HashMap有一些相似的地方，内部都是维护一个Entry类型数组，然后通过对key的哈希码进行位与运算，定位出存储的数组坐标。ThreadLocal作为key提供的哈希码查询方法并非hashCode()，而是通过成员变量threadLocalHashCode去表达。 12345678910111213141516public class ThreadLocal&lt;T&gt; &#123; &#x2F;&#x2F; 哈希码 private final int threadLocalHashCode &#x3D; nextHashCode(); &#x2F;&#x2F; 下一个哈希码 private static AtomicInteger nextHashCode &#x3D; new AtomicInteger(); &#x2F;&#x2F; 哈希码递增跨度值 private static final int HASH_INCREMENT &#x3D; 0x61c88647; &#x2F;&#x2F; 哈希码递增方法 private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125;&#125; 存储哈希码的成员变量threadLocalHashCode被final修饰，也就意味着实例被创建时内部threadLocalHashCode固定为nextHashCode()方法返回的值。这个方法很有意思，每次调用都是将nextHashCode递增0x61c88647，并返回递增后的值。按照这个设计逻辑，每次创建的ThreadLocal实例的哈希值都是不同的，都会比上一次的哈希值高0x61c88647，并且考虑到会被多个线程创建，使用AtomicInteger维护递增值确保线程安全。 因此线程的threadLocals值必须由同一个实例进行存取，这样才能定位到同一个数组下坐标，这也是上述的例子中把ThreadLocal设计成static、final的原因。 set()源码ThreadLocal的set方法: 1234567891011121314public void set(T value) &#123; &#x2F;&#x2F; 获取调用set方法的当前线程 Thread t &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取当前线程的threadLocals属性 ThreadLocalMap map &#x3D; getMap(t); &#x2F;&#x2F; 如果已经初始化，继续往里面增加键值对 if (map !&#x3D; null) map.set(this, value); &#x2F;&#x2F; 如果没有初始化，创建一个ThreadLocalMap并增加一个键值对 else createMap(t, value);&#125; 如果ThreadLocalMap为null，调用createMap()初始化: 12345678910111213141516171819202122232425&#x2F;&#x2F; 为调用set方法的当前线程初始化threadLocals属性void createMap(Thread t, T firstValue) &#123; &#x2F;&#x2F; 使用带参数构造器 t.threadLocals &#x3D; new ThreadLocalMap(this, firstValue);&#125;&#x2F;&#x2F; ThreadLocalMap重载构造器 ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; &#x2F;&#x2F; 初始化table数组容量为16 table &#x3D; new Entry[INITIAL_CAPACITY]; &#x2F;&#x2F; 对key的hashCode进行位与运算取余数，计算出存储到table数组的坐标 int i &#x3D; firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); &#x2F;&#x2F; 将Entry插入ThreadLocalMap中，Entry构造器没啥复杂逻辑，不写了 table[i] &#x3D; new Entry(firstKey, firstValue); &#x2F;&#x2F; 此时长度固定为1，因为就一个Entry size &#x3D; 1; &#x2F;&#x2F; 这个方法是设置ThreadLocalMap扩容的阈值(固定为容量的2&#x2F;3)，类似HashMap的负载因子 setThreshold(INITIAL_CAPACITY);&#125; 如果Map已经被初始化，调用set()方法添加一个键值对: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; &#x2F;&#x2F; 获取Entry类型数组 Entry[] tab &#x3D; table; &#x2F;&#x2F; 获取数组长度 int len &#x3D; tab.length; &#x2F;&#x2F; 对哈希值使用位与运算定位到存储的数组坐标计作i int i &#x3D; key.threadLocalHashCode &amp; (len-1); &#x2F;&#x2F; 将i坐标在数据中的值取出，赋值给e &#x2F;&#x2F; 即使ThreadLocal实例的哈希值不同，位与运算后仍然会计算出相同的数组坐标，只要计算出的坐标已存储元素，for循环就继续下去 &#x2F;&#x2F; 每次循环完将i值重新赋值为i+1(如果+1后下标越界则赋值0)，并将新赋值的i坐标对应的数组元素赋值给e &#x2F;** * 1.每次循环取出数组坐标i对应的值，赋值给e * 2.虽然每个ThreadLocal实例的哈希值不同，但是经过位于运算后仍然会冲突，并且数组中每个坐标只会存储一个对象， * 不会像HashMap那样相同坐标使用链表或红黑树存储。 * 3.如果通过i取出的Entry为空，则跳出for循环 * 4.如果通过i取出的Entry不为空，进入循环体的逻辑处理，并且在处理完后对i+1操作(如果+1之后大于等于数组长度则设置为0) *&#x2F; for (Entry e &#x3D; tab[i]; e !&#x3D; null; e &#x3D; tab[i &#x3D; nextIndex(i, len)]) &#123; &#x2F;&#x2F; 执行到这里，说明数组下坐标i对应的Entry不为空，将Entry的key提取出来 ThreadLocal&lt;?&gt; k &#x3D; e.get(); &#x2F;&#x2F; 如果提取出来的key与需要set的key地址一致，直接覆盖其value if (k &#x3D;&#x3D; key) &#123; e.value &#x3D; value; return; &#125; &#x2F;&#x2F; 如果实体类Entry不为null，所属的key不为null(下面统一称为过期元素) if (k &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; k被回收，所在的e也没有存在的意义了，将需要设置的key、value覆盖到e中，覆盖完返回 replaceStaleEntry(key, value, i); return; &#125; &#125; &#x2F;&#x2F; 到这里说明i的值已经递增到对应下坐标为null了，直接new一个Entry存储进去 tab[i] &#x3D; new Entry(key, value); &#x2F;&#x2F; 数组长度+1 int sz &#x3D; ++size; &#x2F;&#x2F; 如果没有找到过期元素，并且新增后数组的长度超过阈值，进行扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;&#x3D; threshold) rehash();&#125; 如果Entry是过期元素，那么这个Entry也没有任何存在的意义，因为没有任何途径能拿到此Entry的value。这时候就需要调用replaceStaleEntry()方法将此Entry替换掉，将此数组坐标重新利用起来: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value,int staleSlot) &#123; Entry[] tab &#x3D; table; int len &#x3D; tab.length; Entry e; &#x2F;&#x2F; staleSlot是前面set方法中检查出来的过期元素所在的坐标 int slotToExpunge &#x3D; staleSlot; &#x2F;&#x2F; 对数组从slotToExpunge坐标向前遍历，直到碰到过期元素后终止 for (int i &#x3D; prevIndex(staleSlot, len); (e &#x3D; tab[i]) !&#x3D; null; i &#x3D; prevIndex(i, len)) &#x2F;* * 如果此Entry是过期元素，则将当前坐标赋值给slotToExpunge * 可以理解为循环结束后，slotToExpunge的值会变为:坐标staleSlot往左最左边的过期元素 * 这个变量的作用是定位一个范围，清理过期元素工作就是将当前值作为数组坐标向右检查 *&#x2F; if (e.get() &#x3D;&#x3D; null) slotToExpunge &#x3D; i; &#x2F;&#x2F; 这个循环是向后遍历，与上面的循环正好相反 for (int i &#x3D; nextIndex(staleSlot, len); (e &#x3D; tab[i]) !&#x3D; null; i &#x3D; nextIndex(i, len)) &#123; &#x2F;&#x2F; 获取数组中Entry的key ThreadLocal&lt;?&gt; k &#x3D; e.get(); &#x2F;&#x2F; 如果之前存在相同的key if (k &#x3D;&#x3D; key) &#123; &#x2F;&#x2F; 覆盖原value值 e.value &#x3D; value; &#x2F;&#x2F; staleSlot是前面set方法查询到的过期元素，与当前循环的坐标i交换位置 tab[i] &#x3D; tab[staleSlot]; tab[staleSlot] &#x3D; e; &#x2F;&#x2F; 这俩值相等说明上一个for循环，往左没有找到任何E过期元素 &#x2F;&#x2F; 到目前为止需要清理的过期元素只有set方法检查出来的那一个，当前坐标的key和value都有值 &#x2F;&#x2F; 然而上面俩行代码已经将当前坐标的Entry与set检查出来的Entry交换位置了 &#x2F;&#x2F; 所以当前坐标对应的Entry是过期数据，将当前坐标赋值给slotToExpunge，准备后续清理工作 if (slotToExpunge &#x3D;&#x3D; staleSlot) slotToExpunge &#x3D; i; &#x2F;&#x2F; 清理过期的数据 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#x2F;&#x2F; key的位置已经定位并覆盖value了，所有逻辑处理到此结束 return; &#125; &#x2F;&#x2F; 到这里说明要设置的key在数组中还没找到，并且左边的循环查询过期元素 &#x2F;&#x2F; 换句话说就是当前坐标i往左的元素都没毛病，往右检查清理元素的起点坐标要从i开始 if (k &#x3D;&#x3D; null &amp;&amp; slotToExpunge &#x3D;&#x3D; staleSlot) slotToExpunge &#x3D; i; &#125; &#x2F;&#x2F; 到这里说明数组遍历完了也没存在key，重新创建一个Entry并覆盖当前坐标 tab[staleSlot].value &#x3D; null; tab[staleSlot] &#x3D; new Entry(key, value); &#x2F;&#x2F; 如果这俩值相等，说明staleSlot坐标的左右元素都没问题，而且当前坐标也被新的Entry覆盖了，不需要清理 &#x2F;&#x2F; 如果不相等，要么坐标staleSlot的左边存在要清理的元素，要么就是右边，执行清理 if (slotToExpunge !&#x3D; staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125; 上面对数组中Entry的检查中不难发现，无论往左还是往右一旦碰到为null的元素检查就停止了，这会漏掉一部分Entry的检查。因此在每次清理的时候，顺带将不为空的元素左移，挤出所有值为null的下坐标，确保所有不为null的Entry连续挨在一起。这些逻辑都在expungeStaleEntry方法中实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab &#x3D; table; int len &#x3D; tab.length; &#x2F;&#x2F;将上个方法检查出来的过期元素以及所属value的引用设置为null，方便GC回收 tab[staleSlot].value &#x3D; null; tab[staleSlot] &#x3D; null; &#x2F;&#x2F; 数组长度减1 size--; &#x2F;&#x2F; 顺着坐标向右遍历 Entry e; int i; for (i &#x3D; nextIndex(staleSlot, len); (e &#x3D; tab[i]) !&#x3D; null; i &#x3D; nextIndex(i, len)) &#123; &#x2F;&#x2F; 取出当前坐标的key ThreadLocal&lt;?&gt; k &#x3D; e.get(); &#x2F;&#x2F; 如果key为空，则将Entry和内部value设置为null，方便GC回收，数组长度也要减1 if (k &#x3D;&#x3D; null) &#123; e.value &#x3D; null; tab[i] &#x3D; null; size--; &#125; else &#123; &#x2F;&#x2F; 如果不为空,重新通过哈希值计算安插的数组坐标 int h &#x3D; k.threadLocalHashCode &amp; (len - 1); &#x2F;&#x2F; 如果通过哈希值计算的坐标不是当前坐标 if (h !&#x3D; i) &#123; &#x2F;&#x2F; 将当前坐标清空，对应的Entry已经被e指向，并不会丢掉 tab[i] &#x3D; null; &#x2F;&#x2F; 从哈希值计算的坐标开始，往右寻找null的坐标安放e，一旦发现要安插的坐标h左边有为null的坐标，就填充过去 while (tab[h] !&#x3D; null) h &#x3D; nextIndex(h, len); &#x2F;&#x2F; 将e赋值到最终计算出的坐标 tab[h] &#x3D; e; &#125; &#125; &#125; &#x2F;&#x2F; 返回值i代表从staleSlot往右循环过程中，碰到的第一个为null的坐标 return i;&#125; cleanSomeSlots主要用于控制扫描，检查还存不存在有问题的元素，如果有就清理掉。扫描的趟数为log2(数组长度)，执行过程中一旦发现了过期元素，扫描趟数会重置，并且返回值变为true: 12345678910111213141516171819202122232425262728293031private boolean cleanSomeSlots(int i, int n) &#123; boolean removed &#x3D; false; Entry[] tab &#x3D; table; int len &#x3D; tab.length; do &#123; &#x2F;&#x2F; 获取i的下一个坐标 i &#x3D; nextIndex(i, len); &#x2F;&#x2F; 取出Entry Entry e &#x3D; tab[i]; &#x2F;&#x2F; 如果循环过程中发现了过期元素 if (e !&#x3D; null &amp;&amp; e.get() &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; 重置n的值，也就是需要再次扫描log2(n)趟 n &#x3D; len; &#x2F;&#x2F; 返回值removed设置为true removed &#x3D; true; &#x2F;&#x2F; 清理元素并记录清理的坐标 i &#x3D; expungeStaleEntry(i); &#125; &#x2F;&#x2F; n每右移一次相当于n除以2，直到n除以2后小于0终止循环 &#125; while ( (n &gt;&gt;&gt;&#x3D; 1) !&#x3D; 0); &#x2F;&#x2F; 如果为true，代表执行过程中出现需要清理的元素 return removed;&#125; 数组扩容: 123456789private void rehash() &#123; &#x2F;&#x2F; 判断是否需要扩容前，再次清理一遍过期元素 expungeStaleEntries(); &#x2F;&#x2F; 超过阈值的3&#x2F;4，进行扩容 if (size &gt;&#x3D; threshold - threshold &#x2F; 4) resize();&#125; 整个set方法的执行过程分为俩部分，一部分是通过哈希值与数组长度的取余运算，定位到要存储的坐标，并解决坐标冲突的问题。另一部分也是最复杂的一部分，主要涉及到对过期元素的清理工作并防止内存泄漏，因为Entry对象中key的引用是弱引用，所指向的实例如果没有其他强引用指向，随时可能被回收掉。 通过实例的哈希值(threadLocalHashCode属性)，定位到要存储的坐标。 计算出的坐标可能会冲突(类似hashMap的哈希碰撞)，这时需要对比已存储的Entry的key与要存储的key是否一致。 如果key地址相同，直接覆盖value值，结束。 如果key为null(过期元素)，将要set的值包装成Entry覆盖当前坐标，然后进行扫描并清除所有过期元素 如果计算出来的坐标不存在冲突，直接插入此坐标 如果达到扩容的阈值，对数组进行扩容 get()源码ThreadLocal的get方法: 12345678910111213141516171819202122232425public T get() &#123; &#x2F;&#x2F; 获取调用此方法的线程 Thread t &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取线程的ThreadLocalMap ThreadLocalMap map &#x3D; getMap(t); &#x2F;&#x2F; 如果map不为null if (map !&#x3D; null) &#123; &#x2F;&#x2F; 获取数组元素Entry ThreadLocalMap.Entry e &#x3D; map.getEntry(this); &#x2F;&#x2F; 如果不为空，根据范型强转并返回，get方法到此结束 if (e !&#x3D; null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result &#x3D; (T)e.value; return result; &#125; &#125; &#x2F;&#x2F; 到这里说明map为null，或者获取的Entry为null，初始化 return setInitialValue();&#125; ThreadLocalMap的getEntry方法: 12345678910111213private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; &#x2F;&#x2F; 通过hashcode定位数组坐标 int i &#x3D; key.threadLocalHashCode &amp; (table.length - 1); Entry e &#x3D; table[i]; &#x2F;&#x2F; 如果坐标的Entry所属的key正是要提取的key，直接返回 if (e !&#x3D; null &amp;&amp; e.get() &#x3D;&#x3D; key) return e; else &#x2F;&#x2F; 顺着坐标往右寻找 return getEntryAfterMiss(key, i, e);&#125; 如果通过哈希值寻找Entry失败，也就是出现了坐标冲突，那就要往后遍历寻找: 12345678910111213141516171819202122232425private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab &#x3D; table; int len &#x3D; tab.length; &#x2F;&#x2F; 只要e不为null，就循环下去 while (e !&#x3D; null) &#123; ThreadLocal&lt;?&gt; k &#x3D; e.get(); &#x2F;&#x2F; 地址吻合说明当前Entry就是要找的对象，直接返回 if (k &#x3D;&#x3D; key) return e; &#x2F;&#x2F; 如果发现过期元素，执行清除方法 if (k &#x3D;&#x3D; null) expungeStaleEntry(i); else &#x2F;&#x2F; 记录遍历坐标的i+1 i &#x3D; nextIndex(i, len); &#x2F;&#x2F; 下一个Entry赋值给e e &#x3D; tab[i]; &#125; &#x2F;&#x2F; 到这里说明整个数组就不存在这个key return null; &#125; setInitialValue方法没啥逻辑，就是初始化线程的threadLocals: 12345678910111213141516171819private T setInitialValue() &#123; &#x2F;&#x2F; 这个方法写死的，返回null T value &#x3D; initialValue(); &#x2F;&#x2F;获取当前线程 Thread t &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取当前线程的threadLocals ThreadLocalMap map &#x3D; getMap(t); &#x2F;&#x2F; 通过get方法进入的，map肯定为null if (map !&#x3D; null) map.set(this, value); else &#x2F;&#x2F; 初始化threadLocals，并插入一个value为null的Entry createMap(t, value); return value;&#125; get方法相对于set方法而言要简单很多，无非就是根据哈希值计算数组坐标，顺带也会清理过期元素。 remove()源码ThreadLocal的remove()方法: 12345678public void remove() &#123; &#x2F;&#x2F; 获取当前线程的map ThreadLocalMap m &#x3D; getMap(Thread.currentThread()); &#x2F;&#x2F; 如果猫已经初始化，调用map的remove方法 if (m !&#x3D; null) m.remove(this);&#125; ThreadLocalMap的remove方法: 1234567891011121314151617181920212223242526private void remove(ThreadLocal&lt;?&gt; key) &#123; &#x2F;&#x2F; 获取数组信息 Entry[] tab &#x3D; table; int len &#x3D; tab.length; &#x2F;&#x2F; 通过哈希值计算数组坐标赋值给i int i &#x3D; key.threadLocalHashCode &amp; (len-1); &#x2F;&#x2F; 顺着坐标i往右遍历 for (Entry e &#x3D; tab[i]; e !&#x3D; null; e &#x3D; tab[i &#x3D; nextIndex(i, len)]) &#123; &#x2F;&#x2F; 如果发现过期元素 if (e.get() &#x3D;&#x3D; key) &#123; &#x2F;&#x2F; 对当前Entry进行清理，方便GC回收 e.clear(); &#x2F;&#x2F; 这个方法上面已经讲过了，向右扫描并清理过期元素 expungeStaleEntry(i); return; &#125; &#125;&#125; remove方法的作用不仅仅是清除指定的key，还会调用expungeStaleEntry()方法将清除的坐标继续向右遍历，清除遇到的所有过期元素，并且将null的坐标剔除掉。 内存泄漏以上面提到的储用户信息的场景为例，展示某请求线程在整个栈内存和堆内存的引用情况: 图中可以看出来ThreadLocal实例被一个强引用和一个弱引用(具体作用就不说了)指向，由于强引用是静态常量不可能被GC回收掉，请求线程必须要等到生命周期结束，自身包括内部的ThreadLocals才会被GC回收掉。因此ThreadLocal内存泄漏的本质是局部变量已经使用完但是没有及时清理，直到线程被回收才释放掉，后面这段时间是没有存在的意义的，白白浪费了内存空间。 解决内存泄漏的办法就是在使用完毕后手动调用remove()方法释放掉，按照这种说法上面例举的存储登录信息的代码还可以优化，将remove()方法的调用从拦截器提前到业务代码中，保证使用完立即清除。个人觉得项目规模较小，随意在接口的调用链中使用remove()方法，对后期的修改维护很不友好，并且web请求线程生命周期不会很长，完全可以舍弃掉这个优化。 但是很多时候我们存储的局部变量占用的内存远比登陆信息高得多，并且线程在使用完局部变量后，仍然需要很长一段时间才会死亡，甚至使用线程池时压根就不会死亡，这些场景下就必须要在使用完毕后立刻调用remove方法。另一种做法是利用弱引用机制在恰当的时机将Entry设置为过期元素，我特地去翻了spring的Request作用域、Mybatis事务控制源码，无一列外都是创建一个静态变量(强引用)来存取数据，并没有每次使用都创建新的ThreadLocal实例来处理，所以弱引用就不写了。 总结线程的局部变量是存储在线程自身的ThreadLocalMap中，而ThreadLocal对象仅仅只是个方便存取数据的快捷键而已，一般都是创建静态变量并提供静态存取方法，使用起来比较方便。另外在使用完毕后尽量使用remove()方法进行清理，方便GC尽快回收。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十五) 同步工具类-Phaser","slug":"同步工具类-Phaser","date":"2020-03-15T05:00:00.000Z","updated":"2020-11-09T13:13:19.578Z","comments":true,"path":"2020/03/15/同步工具类-Phaser/","link":"","permalink":"http://yoursite.com/2020/03/15/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-Phaser/","excerpt":"","text":"简介Phaser表示阶段器，用来解决控制多个线程分阶段共同完成任务的情景问题。它的功能与 CyclicBarrier和CountDownLatch有些类似，类似于一个多阶段的栅栏，并且功能更强大。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十四) 同步工具类-Exchanger","slug":"同步工具类-Exchanger","date":"2020-03-14T05:00:00.000Z","updated":"2020-11-09T13:12:57.421Z","comments":true,"path":"2020/03/14/同步工具类-Exchanger/","link":"","permalink":"http://yoursite.com/2020/03/14/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-Exchanger/","excerpt":"","text":"简介Exchanger也是一个线程同步的辅助类，用于两个线程之间交换信息。通过exchange方法相互交换数据，如果第一个执行到exchange方法，会等待第二个线程执行exchange，当两个线程都到达时，会进行数据交换。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十三) 同步工具类-Semaphore","slug":"同步工具类-Semaphore","date":"2020-03-13T05:00:00.000Z","updated":"2020-11-10T07:43:28.121Z","comments":true,"path":"2020/03/13/同步工具类-Semaphore/","link":"","permalink":"http://yoursite.com/2020/03/13/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-Semaphore/","excerpt":"","text":"基本概念Semaphore也是一个线程同步的辅助类，在多线程环境下用于协调各个线程, 以保证它们能够正确、合理的使用公共资源。信号量维护了一个许可集，我们在初始化Semaphore时需要为这个许可集传入一个数量值，该数量值代表同一时间能访问共享资源的线程数量。 使用场景这个应用就比较广泛了，主要用于流量控制，例如限制某接口或者静态资源的最大并发访问数，上代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Test &#123; private static Semaphore semaphore &#x3D; new Semaphore(2); public static void main(String[] args) &#123; for(int i &#x3D;1; i &lt;&#x3D; 10; i++)&#123; Thread thread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; select(); &#125; &#125;); thread.setName(&quot;线程序号&quot; + i); thread.start(); &#125; &#125; private static Object select()&#123; try &#123; &#x2F;&#x2F; 注册 semaphore.acquire(); &#x2F;&#x2F; 模拟查询耗时 Thread.currentThread().sleep(500L); &#x2F;&#x2F; 打印信息 StringBuilder info &#x3D; new StringBuilder(); info.append(Thread.currentThread().getName()); info.append(&quot;进入查询方法,&quot;); info.append(&quot;空闲通道:&quot;).append(semaphore.drainPermits()); info.append(&quot;,&quot;); info.append(&quot;等待线程数:&quot;).append(semaphore.getQueueLength()); System.out.println(info.toString()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; &#x2F;&#x2F; 释放 semaphore.release(); &#125; return new Object(); &#125;&#125; 打印结果:线程序号1进入查询方法,空闲通道:0,等待线程数:8线程序号2进入查询方法,空闲通道:0,等待线程数:8线程序号3进入查询方法,空闲通道:0,等待线程数:6线程序号4进入查询方法,空闲通道:0,等待线程数:6线程序号5进入查询方法,空闲通道:0,等待线程数:4线程序号6进入查询方法,空闲通道:1,等待线程数:4线程序号7进入查询方法,空闲通道:0,等待线程数:3线程序号8进入查询方法,空闲通道:0,等待线程数:2线程序号9进入查询方法,空闲通道:0,等待线程数:1线程序号10进入查询方法,空闲通道:0,等待线程数:0 打印结果可以看出来，同一时刻只能有2个线程对方法进行访问。 构造器源码12345678910&#x2F;&#x2F; 默认使用非公平锁public Semaphore(int permits) &#123; sync &#x3D; new NonfairSync(permits);&#125;&#x2F;&#x2F; 可以通过构造器参数指定是否公平竞争public Semaphore(int permits, boolean fair) &#123; sync &#x3D; fair ? new FairSync(permits) : new NonfairSync(permits);&#125; Semaphore对象可以通过构造器指定访问限制，还可以指定争夺的公平方式。 Sync源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID &#x3D; 1192457210091910933L; &#x2F;&#x2F; 初始化访问 Sync(int permits) &#123; setState(permits); &#125; final int getPermits() &#123; return getState(); &#125; &#x2F;&#x2F; 非公平方式获取AQS共享式资源 final int nonfairTryAcquireShared(int acquires) &#123; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F; 获取state值 int available &#x3D; getState(); &#x2F;&#x2F; 计算获取资源后值应该是多少 int remaining &#x3D; available - acquires; &#x2F;&#x2F; 如果大于等于0说明满足条件，将计算后值通过CAS修改后返回，如果小于0直接返回 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; &#x2F;&#x2F; 释放锁，就是把state加回来 protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; &#x2F;&#x2F; 获取state值 int current &#x3D; getState(); &#x2F;&#x2F; 计算加后的值 int next &#x3D; current + releases; &#x2F;&#x2F; 如果加后值小于当前state值，说明参数为负数，抛异常 if (next &lt; current) &#x2F;&#x2F; overflow throw new Error(&quot;Maximum permit count exceeded&quot;); &#x2F;&#x2F; 使用CAS方式修改值 if (compareAndSetState(current, next)) return true; &#125; &#125; &#x2F;&#x2F; state减操作 final void reducePermits(int reductions) &#123; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F; 获取state值 int current &#x3D; getState(); &#x2F;&#x2F; 计算减后的值 int next &#x3D; current - reductions; &#x2F;&#x2F; 如果减后值大于当前state值，说明参数为负数，抛异常 if (next &gt; current) &#x2F;&#x2F; underflow throw new Error(&quot;Permit count underflow&quot;); &#x2F;&#x2F; 使用CAS方式修改值 if (compareAndSetState(current, next)) return; &#125; &#125; &#x2F;&#x2F; 将state归零 final int drainPermits() &#123; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F; 获取state int current &#x3D; getState(); &#x2F;&#x2F; 如果是0直接返回0，不是0使用CAS设置成0在返回0，这是要干啥？ if (current &#x3D;&#x3D; 0 || compareAndSetState(current, 0)) return current; &#125; &#125;&#125; Sync类实现了很多方法: nonfairTryAcquireShared():非公平性获取共享式锁，不进行排队直接自旋获取。 tryReleaseShared():释放共享式锁，使用CAS方式对state执行加操作。 reducePermits():使用CAS方式对state执行减操作。 drainPermits():将state设置为0并返回，不知道想干啥? 公平/非公平Sync源码1234567891011121314151617181920212223242526272829303132333435363738&#x2F;&#x2F; 非公平static final class NonfairSync extends Sync &#123; private static final long serialVersionUID &#x3D; -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; &#x2F;&#x2F; 调用父类写好的方法，非公平式获取锁 protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125;&#125;&#x2F;&#x2F; 公平static final class FairSync extends Sync &#123; private static final long serialVersionUID &#x3D; 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; &#x2F;&#x2F; 无限自旋直到CAS修改成功 protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; &#x2F;&#x2F; 比非公平锁多了一个步骤，判断前面是否有人,如果前面有人就放弃 if (hasQueuedPredecessors()) return -1; int available &#x3D; getState(); int remaining &#x3D; available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125;&#125; 公平与非公平Sync逻辑几乎一样，只是公平锁在尝试获取资源的时候会先去判断前面是否已经有人，如果有人就放弃尝试，进入AQS的等待阻塞方法。而非公平锁不管前面有没有人都会尝试获取直到成功。 acquire()源码123456789101112131415161718192021public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; &#x2F;&#x2F; 先判断是否已经被中断 if (Thread.interrupted()) throw new InterruptedException(); &#x2F;&#x2F; 如果访问次数已经耗尽，进入doAcquireSharedInterruptibly()方法阻塞 if (tryAcquireShared(arg) &lt; 0) &#x2F;* * 源码就不贴了，AQS写好的方法: * 排在等待队列的第一个，自旋等待直到重写方法tryAcquireShared(arg)返回值大于0跳出自旋 * 排在等待队列的第二个开始，直接挂起一边呆着去... *&#x2F; doAcquireSharedInterruptibly(arg);&#125; 总结这没啥好说的，只不过现在都是分布式项目，如果限流的目的是减少数据库或静态资源的访问，单靠Semaphore无法实现，还需要依靠基于Redis或Zookeeper的分布式锁实现，感觉用处不多。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十二) 同步工具类-CyclicBarrier","slug":"同步工具类-CyclicBarrier","date":"2020-03-12T05:00:00.000Z","updated":"2020-11-10T07:19:10.297Z","comments":true,"path":"2020/03/12/同步工具类-CyclicBarrier/","link":"","permalink":"http://yoursite.com/2020/03/12/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-CyclicBarrier/","excerpt":"","text":"基本概念CyclicBarrier是一个同步的辅助类，允许一组线程相互之间等待，并设置一个公共屏障点，当组内线程达到这个屏障点的时候阻塞，阻塞在这个屏障点的线程数达到指定数量时，释放所有线程继续往下执行。CyclicBarrier在释放完线程后相当于重置之前的记录可以循环使用，所以称之为Cyclic(循环)Barrier(屏障)。 使用场景开发经历有限，目前为止还真没用过CyclicBarrier，一般场景使用CountDownLatch就够了，就随便写点吧。 1234567891011121314151617181920212223242526272829303132public class Test &#123; private static CyclicBarrier cyclicBarrier &#x3D; new CyclicBarrier(5, new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;屏障点回调线程，执行者:&quot; + Thread.currentThread().getName()); &#125; &#125;); public static void main(String[] args) &#123; for(int i &#x3D; 0; i&lt; 5;i++)&#123; Thread thread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;开始运行&quot;); cyclicBarrier.await(); System.out.println(Thread.currentThread().getName() + &quot;结束运行&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); thread.setName(&quot;线程&quot; + i); thread.start(); &#125; &#125;&#125; 打印结果:线程1开始运行线程0开始运行线程2开始运行线程3开始运行线程4开始运行屏障点回调线程，执行者:线程4线程4结束运行线程1结束运行线程0结束运行线程2结束运行线程3结束运行 打印结果可以看出来，当指定数量(构造器参数决定)的线程到达屏障点(await代码行)后，才能继续往下执行。如果在构造器中指定了回调线程，还需要等待回调线程执行完才可以往下执行，回调线程由最后一个阻塞的线程执行。 构造器源码12345678910111213&#x2F;&#x2F; 设置屏障阈值public CyclicBarrier(int parties) &#123; this(parties, null);&#125;&#x2F;&#x2F; 设置屏障阈值，同时增加回调线程功能public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;&#x3D; 0) throw new IllegalArgumentException(); this.parties &#x3D; parties; this.count &#x3D; parties; this.barrierCommand &#x3D; barrierAction;&#125; 成员变量1234567891011121314151617181920&#x2F;&#x2F; lock对象private final ReentrantLock lock &#x3D; new ReentrantLock();&#x2F;&#x2F; 跳闸，可以理解为打开屏障private final Condition trip &#x3D; lock.newCondition();&#x2F;&#x2F; 屏障阈值private final int parties;&#x2F;&#x2F; 回调线程private final Runnable barrierCommand;&#x2F;&#x2F; 每次使用屏障都会生成，内部的broken标记屏障是否破损private Generation generation &#x3D; new Generation();&#x2F;&#x2F; 默认设置falseprivate static class Generation &#123; boolean broken &#x3D; false;&#125; await()源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192 &#x2F;&#x2F; 内部调用dowait()方法，并且参数传false，不支持超时 public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); &#x2F;&#x2F; cannot happen &#125; &#125; &#x2F;&#x2F; 真正进入等待的逻辑 private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock &#x3D; this.lock; &#x2F;&#x2F; 获取排他锁 lock.lock(); try &#123; final Generation g &#x3D; generation; &#x2F;&#x2F; 屏障被破坏则抛异常 if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; &#x2F;&#x2F; 线程中断 则退出屏障 breakBarrier(); throw new InterruptedException(); &#125; &#x2F;&#x2F; 到达屏障的计数-1 int index &#x3D; --count; if (index &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; tripped &#x2F;&#x2F; index &#x3D;&#x3D; 0, 说明指定 count 的线程均到达屏障，此时可以打开屏障 boolean ranAction &#x3D; false; try &#123; final Runnable command &#x3D; barrierCommand; if (command !&#x3D; null) &#x2F;&#x2F; 若指定了 barrierCommand 则执行 command.run(); ranAction &#x3D; true; &#x2F;&#x2F; 唤醒阻塞在屏障的线程并重置 generation nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier(); &#125; &#125; &#x2F;&#x2F; loop until tripped, broken, interrupted, or timed out for (;;) &#123; try &#123; if (!timed) &#x2F;&#x2F; 若未指定阻塞在屏障处的等待时间，则一直等待；直至最后一个线程到达屏障处的时候被唤醒 trip.await(); else if (nanos &gt; 0L) &#x2F;&#x2F; 若指定了阻塞在屏障处的等待时间，则在指定时间到达时会返回 nanos &#x3D; trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g &#x3D;&#x3D; generation &amp;&amp; ! g.broken) &#123; &#x2F;&#x2F; 若等待过程中，线程发生了中断，则退出屏障 breakBarrier(); throw ie; &#125; else &#123; &#x2F;&#x2F; We&#39;re about to finish waiting even if we had not &#x2F;&#x2F; been interrupted, so this interrupt is deemed to &#x2F;&#x2F; &quot;belong&quot; to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; &#x2F;&#x2F; 屏障被破坏 则抛出异常 if (g.broken) throw new BrokenBarrierException(); if (g !&#x3D; generation) &#x2F;&#x2F; g !&#x3D; generation 说明所有线程均到达屏障处 可直接返回 &#x2F;&#x2F; 因为所有线程到达屏障处的时候，会重置 generation &#x2F;&#x2F; 参考 nextGeneration return index; if (timed &amp;&amp; nanos &lt;&#x3D; 0L) &#123; &#x2F;&#x2F; 说明指定时间内，还有线程未到达屏障处，也就是等待超时 &#x2F;&#x2F; 退出屏障 breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; nextGeneration()源码1234567891011private void nextGeneration() &#123; &#x2F;&#x2F; 唤醒阻塞在等待队列的线程 trip.signalAll(); &#x2F;&#x2F; 重置 count count &#x3D; parties; &#x2F;&#x2F; 重置 generation generation &#x3D; new Generation();&#125; breakBarrier()源码1234567891011private void breakBarrier() &#123; &#x2F;&#x2F; broken 设置为 true generation.broken &#x3D; true; &#x2F;&#x2F; 重置 count count &#x3D; parties; &#x2F;&#x2F; 唤醒等待队列的线程 trip.signalAll();&#125; reset()源码12345678910final ReentrantLock lock &#x3D; this.lock;lock.lock();try &#123; &#x2F;&#x2F; 唤醒阻塞的线程 breakBarrier(); &#x2F;&#x2F; break the current generation &#x2F;&#x2F; 重新设置 generation nextGeneration(); &#x2F;&#x2F; start a new generation&#125; finally &#123; lock.unlock();&#125; 总结CyclicBarrier依赖与Lock与Condition实现，await()方法使用Lock进行互斥，Condition对象负责挂起被屏障挡住的线程。Lock与Condition底层是基于AQS的，所以CyclicBarrier还是通过AQS实现。 CyclicBarrier内部有个屏障是否被打破的概念，维护在内部类Generation的broken属性中(默认是false)，并且可以通过breakBarrier()方法进行打破(修改为true)，调用这个方法的地方有三个，检测到中断、等待超时、reset()方法。当某个线程在等待过程中被中断或超时，会直接抛中断异常退出等待，不会对count执行-1操作，这会导致同一组线程会无限等待下去，因为count值永远无法到达0。使用reset()方法会重置count值，为了避免重置时还有残余线程没执行到await()方法，干扰重置后的count值导致下一轮提前结束。当遇到这些情况时，CyclicBarrier会修改broken=true来通知其他线程不要再等下去了。 CountDownLatch与CyclicBarrier区别: CountDownLatch CyclicBarrier 一个线程(或多个)线程等待另N个线程完成某事后才能继续执行 N个线程相互在某个点等待，知道所有线程都到达这个点解除等待 无法重复利用，没有提供state属性的重置方法 可以重复利用，提供reset()方法重置","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十一) 同步工具类-CountDownLatch","slug":"同步工具类-CountDownLatch","date":"2020-03-11T05:00:00.000Z","updated":"2020-11-17T14:38:18.233Z","comments":true,"path":"2020/03/11/同步工具类-CountDownLatch/","link":"","permalink":"http://yoursite.com/2020/03/11/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-CountDownLatch/","excerpt":"","text":"基本概念CountDownLatch是一种线程同步工具类，它允许一个或多个线程等待直到在其他线程中一组操作执行完成。你可以把它理解为一个计数器，对象被创建的时候指定总数，每有一个线程到达指定条件总数减1，当减到为0时代表所有线程都达到条件，所有等待线程被唤醒继续往下执行，因此CountDownlatch也被称为倒计时锁。 使用场景例如运营系统的流量、业务等统计功能，页面需要统计展示每日的新增用户量、订单数量、商品销售总量、商品销售总额等。如果每个统计类型的查询需要2秒，4个统计类型就需要8秒的时间才能返回给前端，用户显然是无法接受的。我们只需要将4个统计类型的查询由串行执行改为并行执行，等待所有线程都查询完在组装返回，那么整个请求的响应时间就缩短到的了2秒。 写个简单的Demo: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class Test &#123; public static void main(String[] args) &#123; long startTimeMillis &#x3D; System.currentTimeMillis(); CountDownLatch countDownLatch &#x3D; new CountDownLatch(4); Map&lt;String, Long&gt; statisticsMap &#x3D; new Hashtable&lt;&gt;(); &#x2F;&#x2F; 1.查询新增用户量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;addUserCount&quot;, 1000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 2.查询订单数量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;orderCount&quot;, 248300L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 3.查询商品销售总量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;commodityCount&quot;, 300L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 4.查询商品销售总额 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;totalSales&quot;, 9073180L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; long takeTimeMillis &#x3D; System.currentTimeMillis() - startTimeMillis; System.out.println(&quot;耗时:&quot; + takeTimeMillis + &quot;ms&quot;); System.out.println(&quot;返回值:&quot; + statisticsMap); &#125;&#125; 耗时:2006ms返回值:{commodityCount=300, totalSales=9073180, orderCount=248300, addUserCount=1000} 构造器源码1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync &#x3D; new Sync(count);&#125; CountDownLatch底层基于AQS实现，当我们调用CountDownLatch countDownLatch= new CountDownLatch(4) 创建一个实例时，会在对象内部创建一个继承AQS的Sync类，并将构造器的参数值赋值给state，所以state的值也代表CountDownLatch所剩余的计数次数。 Sync源码1234567891011121314151617181920212223242526272829303132333435363738private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID &#x3D; 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; &#x2F;&#x2F; 根据计数值是否耗尽(为0就算耗尽)，返回正数(1)或者负数(-1) protected int tryAcquireShared(int acquires) &#123; return (getState() &#x3D;&#x3D; 0) ? 1 : -1; &#125; &#x2F;&#x2F; 共享式释放锁的逻辑重写，主要提供给countDown()使用 protected boolean tryReleaseShared(int releases) &#123; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F; 获取当前state值 int c &#x3D; getState(); &#x2F;&#x2F; 如果state&#x3D;0，说明计数值已经耗尽了，不需要继续释放 if (c &#x3D;&#x3D; 0) return false; &#x2F;&#x2F; 使用CAS方式-1 int nextc &#x3D; c-1; &#x2F;&#x2F; 如果减完为0，证明是最后一个释放的，返回true if (compareAndSetState(c, nextc)) return nextc &#x3D;&#x3D; 0; &#125; &#125;&#125; Sync除了维护了state值以外，分别重写了tryAcquireShared()与tryReleaseShared()方法，主要提供给CountDownLatch的countDown()与await()方法调用。 countDown()源码1234567891011121314151617181920 &#x2F;&#x2F; 内部调用AQS的共享式释放锁public void countDown() &#123; sync.releaseShared(1); &#125; &#x2F;&#x2F; AQS的共享式释放锁 public final boolean releaseShared(int arg) &#123; &#x2F;&#x2F; if中的方法被CountDownLatch重写，仅当state不为0并且修改后为0时才返回true if (tryReleaseShared(arg)) &#123; &#x2F;&#x2F; 如果state修改后是0，说明自己是最后一个执行完毕的，需要唤醒所有等待的线程 doReleaseShared(); &#x2F;&#x2F; countDown()方法并没有利用返回值做其他事情，可以无视 return true; &#125; return false; &#125; countDown()方法的逻辑非常简单，就是利用静态内部类Sync的重写方法tryReleaseShared()，使用CAS方式对计数值(state)-1操作。如果返回true证明自身是最后一个执行完成的，还需要唤醒所有阻塞的等待线程。 await()源码12345678910111213141516171819 &#x2F;&#x2F; 内部调用AQS的共享式获取锁方式(支持中断)public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; &#x2F;&#x2F; AQS共享式获取锁方式(支持中断) public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; &#x2F;&#x2F; 如果已经是中断状态，直接抛出来 if (Thread.interrupted()) throw new InterruptedException(); &#x2F;&#x2F; 调用重写的共享式获取锁方法，如果返回值小于0证明计数值还没有耗尽，需要加入等待队列 if (tryAcquireShared(arg) &lt; 0) &#x2F;&#x2F; AQS的方法，前面已经解释过了，排队的第一个自旋等待，后面的挂起等待，直到tryAcquireShared()&gt;&#x3D;0 doAcquireSharedInterruptibly(arg); &#125; await()方法无非就是阻塞，第一个调用此方法的线程是自旋等待，直到计数值耗尽(state=0)跳出，如果有多个线程调用此方法等待，则使用park()函数挂起直到被唤醒。并且提供重载方法支持超时放弃，等待过程中支持中断响应。 await(timeout, unit)源码12345678910111213141516171819&#x2F;&#x2F; 内部调用AQS的共享式获取锁方式(支持超时与中断)public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));&#125;&#x2F;&#x2F; AQS的共享式获取锁方式(支持超时与中断)public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; &#x2F;&#x2F; 先做中断校验 if (Thread.interrupted()) throw new InterruptedException(); &#x2F;&#x2F; 如果tryAcquireShared()方法返回值大于0，也就是已经计数值已耗尽(state&#x3D;0) 直接返回就好了 &#x2F;&#x2F; 如果没有耗尽，进入阻塞方法，也是AQS源码 不解释了... return tryAcquireShared(arg) &gt;&#x3D; 0 || doAcquireSharedNanos(arg, nanosTimeout);&#125; 在await()基础上增加超时功能，防止意外情况导致条件永远无法满足，等待线程一直阻塞。 总结CountDownLatch的作用是牺牲运行内存(额外创建的线程需要额外的栈空间支出)以及CPU资源(请求过程中会有额外的线程加入CPU使用权争夺)来提高请求的响应效率。因此CountDownLatch不能盲目使用，要参考JVM大小、CPU核数等配置信息，还要估算接口的QPS，避免大量请求导致JVM栈溢出或CPU使用率到100%。 在创建CountDownLatch时，构造器参数值一定要和处理任务的子线程数相等，避免高于子线程数量造成死锁，或者低于子线程数造成部门数据丢失。子线程的countDown()方法最好放在finally代码块中，避免执行过程中出现异常导致没有被执行。为了保险起见，主线程最好使用支持超时的await()进行等待，彻底解决可能出现的死锁情况。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十) 线程通信","slug":"线程通信","date":"2020-03-10T05:00:00.000Z","updated":"2020-11-10T08:44:22.994Z","comments":true,"path":"2020/03/10/线程通信/","link":"","permalink":"http://yoursite.com/2020/03/10/%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1/","excerpt":"","text":"简介线程与线程之间不是相互独立的个体，有些时候需要相互通信来共同完成某个业务场景，多线程之间通信总体来说分为共享内存和消息通信机制。 wait/notify概念wait/notify采用消息通信机制来进行线程间的通信，某个线程必须达到特定条件才能继续执行下去，没有达到就将自己挂起等待，另一个线程的执行过程中会使条件达成并通知挂起等待的线程继续执行下去。 wait/notify都属于Object的方法，利用java自带的对象加锁机制争夺对应monitor，当线程不满足执行条件时调用Object的wait方法将自己挂起在monitor对象的_WaitSet上，其他线程在执行过程中将条件满足，紧接着使用Object的notify或notifyAll方法唤醒前述的等待线程，重新加入锁的竞争。 使用场景例如线程独有的join()方法就是通过wait/notify实现线程的合并(非异步调用)，在join线程执行过程中调用者线程只能等待，为了避免CPU的浪费，使用wait()方法将自己挂起在join线程的monitor对象的_WaitSet中，当join线程执行完毕后使用notify()唤醒调用者线程，继续往下执行。 在例如生产者/消费者模式，消费者线程使用while循环监听消息，如果消息队列为空则使用wait()将自己挂起，同样避免忙等造成CPU的浪费，生产者线程每次生产完数据都必须调用notify()方法，唤醒因消息队列为空而将自己挂起的消费者线程。下面是一段基于wait/notify机制的生产/消费模型： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Test &#123; private static Object obj &#x3D; new Object(); private static final Queue&lt;String&gt; messageQueue &#x3D; new LinkedBlockingDeque&lt;&gt;(); public static void main(String[] args) throws Exception &#123; Thread producerThread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i &#x3D; 1; i &lt;&#x3D; 9; i++) &#123; &#x2F;&#x2F; 生产消息 synchronized (obj) &#123; messageQueue.add(&quot;第&quot; + i + &quot;条消息&quot;); obj.notify(); &#125; &#x2F;&#x2F; 每生产三条暂停1秒 if (i &gt; 1 &amp;&amp; i % 3 &#x3D;&#x3D; 0) &#123; try &#123; System.out.println(&quot;暂停&quot;); Thread.currentThread().sleep(1000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#x2F;&#x2F; ... &#125; &#125; &#x2F;&#x2F; ... &#125;); Thread consumerThread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (obj) &#123; try &#123; while (true) &#123; if (messageQueue.isEmpty()) &#123; obj.wait(); &#125; String message &#x3D; messageQueue.poll(); System.out.println(&quot;消费者:&quot; + message); &#125; &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#x2F;&#x2F; ... &#125;); producerThread.start(); consumerThread.start(); &#125;&#125; 使用细节为什么wait()、notify()、notifyAll()必须在同步代码块中？这三个方法都是对对象的monitor中的_WaitSet进行操作，而进入同步代码块意味着已经持有对象锁，也就持有了monitor，才有资格对_WaitSet进行操作，因此必须在同步代码块中。 为什么wait()方法要放在while()循环而不是if中？被唤醒后线程从wait()代码之后继续执行，但是并不能保证每次被唤醒都是符合继续执行条件的，用while()被唤醒还会继续判断，不符合条件永远在while()中，而if不会。在N个线程通信的情况下，不能保证那一时刻条件被某个线程改变。 为什么wait()、notify()要定义在Object中而不是线程中？wait()与notify()的基本思想是把某个对象作为联络点，利用锁机制拿到monitor进行联络通信，而java提供的锁是对象级的而不是线程级的，锁属于对象而不是线程专有，因此wait()、notify()、notifyAll()这种锁级别操作属于Object而不是线程专有方法。 lock/condition概念既然java支持使用锁进行线程通信，synchronized可以，Lock必然也可以。lock/condition与wait/notify功能类似，通过Lcok对象创建Condition对象，利用Condition对象的await()与signal()方法来阻塞唤醒。 使用场景无 简单总结","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(九) Lock家族","slug":"Lock家族","date":"2020-03-09T05:00:00.000Z","updated":"2020-10-22T07:48:58.201Z","comments":true,"path":"2020/03/09/Lock家族/","link":"","permalink":"http://yoursite.com/2020/03/09/Lock%E5%AE%B6%E6%97%8F/","excerpt":"","text":"Lock继承体系Lock接口Lock接口诞生于JDK1.5，接口内部提供了最基本的加锁、释放锁方法: 1234567891011121314151617181920public interface Lock &#123; &#x2F;&#x2F; 直接加锁 void lock(); &#x2F;&#x2F; 支持可中断的加锁 void lockInterruptibly() throws InterruptedException; &#x2F;&#x2F; 尝试一次加锁 boolean tryLock(); &#x2F;&#x2F; 尝试一次加锁(支持超时停止阻塞) boolean tryLock(long time, TimeUnit unit) throws InterruptedException; &#x2F;&#x2F; 解锁 void unlock(); &#x2F;&#x2F; 创建一个Condition(作用于线程通信，后面会讲) Condition newCondition(); 使用层面既然是接口，就是提供给开发者实现用的，Java自带了ReentrantLock、Condition、ReentrantReadWriteLock实现类供开发者使用。如果这些类无法满足业务需求，开发者可以通过实现Lock接口并利用AQS框架，自己定义一个Lock的具体实现锁(是否公平、是否支持超时、是否支持重入等)，从而提高锁的灵活性。 与synchronized区别由于Lock可以自己定义是否公平、是否支持超时、是否支持重入等功能，相对于synchronized关键字来说可发挥的空间更多，也更灵活。但是Lock的加锁、释放锁需要开发者自己编写，如果考虑不周很可能造成死锁情况(最好在try中加锁，finally中释放锁)，而synchronized由JVM实现，完全不需要担心这些情况。 ReentrantLockReentrantLock就是Java自带的Lock实现类，字面的意思就能看出来是一把可重入锁，并且功能几乎与synchronized相似，我们看看源码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; &#x2F;&#x2F; 定义一个顶级同步器(内部包含一个非公平加锁方法，一个释放锁方法) abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID &#x3D; -5179523762034025860L; abstract void lock(); &#x2F;&#x2F; 非公平方式尝试一次加锁 final boolean nonfairTryAcquire(int acquires) &#123; &#x2F;&#x2F; 获取试图尝试加锁的线程 final Thread current &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取公共资源状态 int c &#x3D; getState(); &#x2F;&#x2F; 如果没其他线程持有锁，进行加锁 if (c &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 加锁前并没有校验等待队列是否已经有节点在等待了，这个if完全体现了非公平性 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; &#x2F;&#x2F; 如果有线程持有锁并且是自身，重入次数递增 else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123; int nextc &#x3D; c + acquires; if (nextc &lt; 0) &#x2F;&#x2F; overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; &#x2F;&#x2F; 到这里说明锁被其他线程占了，直接返回false return false; &#125; &#x2F;&#x2F; 释放锁 protected final boolean tryRelease(int releases) &#123; &#x2F;&#x2F; 计算递减后的重入次数 int c &#x3D; getState() - releases; &#x2F;&#x2F; 如果释放锁线程不是持有锁线程，抛异常(一般能执行这方法的都是持有锁线程) if (Thread.currentThread() !&#x3D; getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); &#x2F;&#x2F; 如果递减后为0，那就是真的释放锁了，清空自己的独占状态并返回 boolean free &#x3D; false; if (c &#x3D;&#x3D; 0) &#123; free &#x3D; true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; &#x2F;&#x2F; 返回调用此方法的线程是否持有锁 protected final boolean isHeldExclusively() &#123; return getExclusiveOwnerThread() &#x3D;&#x3D; Thread.currentThread(); &#125; &#x2F;&#x2F; 其他方法... &#125; &#x2F;&#x2F; 定义一个非公平同步器，继承顶级同步器 static final class NonfairSync extends Sync &#123; private static final long serialVersionUID &#x3D; 7316153563782823691L; &#x2F;&#x2F; 实现顶级同步器的lock加锁方法 final void lock() &#123; &#x2F;&#x2F; 尝试CAS 如果成功说明之前没线程加锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); &#x2F;&#x2F; 失败就在尝试获取一次，这里调用AQS的acquire()方法， &#x2F;&#x2F; AQS的acquire()方法又调用下面重写的tryAcquire方法 else acquire(1); &#125; &#x2F;&#x2F; 绕了一大圈，其实就是用非公平锁方式加锁 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125; &#x2F;&#x2F; 定义一个公平同步器，继承顶级同步器 static final class FairSync extends Sync &#123; private static final long serialVersionUID &#x3D; -3000897897090466540L; final void lock() &#123; acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current &#x3D; Thread.currentThread(); int c &#x3D; getState(); if (c &#x3D;&#x3D; 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123; int nextc &#x3D; c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; &#125; &#x2F;&#x2F; 无参构造器，默认使用非公平锁 public ReentrantLock() &#123; sync &#x3D; new NonfairSync(); &#125; &#x2F;&#x2F; 参数构造器，自行选择是否公平 public ReentrantLock(boolean fair) &#123; sync &#x3D; fair ? new FairSync() : new NonfairSync(); &#125; &#x2F;&#x2F; 加锁 public void lock() &#123; sync.lock(); &#125; &#x2F;&#x2F; 支持可中断加锁 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; &#x2F;&#x2F; 尝试一次加锁 public boolean tryLock() &#123; return sync.nonfairTryAcquire(1); &#125; &#x2F;&#x2F; 支持超时的加锁 public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; &#x2F;&#x2F; 解锁 public void unlock() &#123; sync.release(1); &#125; &#x2F;&#x2F; 其他方法....&#125; 重入支持ReentrantLock通过state属性控制重入，每次重入state+1、退出state-1，为0时代表释放锁。 是否公平锁 ReentrantLock类支持公平锁与非公平锁，并根据构造器初始化一个Sync(公平锁创建FairSync，非公平锁创建NonfairSync)，后续加锁释放锁等操作完全调用Sync实现。FairSync与NonfairSync除了加锁逻辑不一样，其他的逻辑(比如释放锁等)完全一样。 ReentrantLock加锁是使用Sync的lock()实现，公平锁(FairSync)是直接调用AQS的acquire()方法获取锁，然后调用重写的tryAcquire()方法。在重写方法里面如果可以加锁(state=0)，会先判断等待队列是否有元素在等待，如果没有元素可以直接加锁，如果加锁失败或存在元素，则加入等待队列尾部等待(按顺序排队)。 非公平锁(NonFairSync)在调用Sync的lock()方法时，只要可以加锁(state=0)，会直接使用CAS进行加锁(无视等待队列是否有元素)，如果插队失败了在调用AQS的acquire()再次加锁，重写的tryAcquire()方法还是会再次尝试插队，如果还是失败才会加入等待队列，因此非公平锁存在2次插队的操作。 ReadWriteLock接口没啥好写的 ReentrantReadWriteLock没啥好写的","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(八) AQS","slug":"AQS","date":"2020-03-08T05:00:00.000Z","updated":"2020-11-09T04:31:26.002Z","comments":true,"path":"2020/03/08/AQS/","link":"","permalink":"http://yoursite.com/2020/03/08/AQS/","excerpt":"","text":"AQS简介AQS的全称是AbstractQueuedSynchronizer，类内部定义了一套多线程访问共享资源的同步器框架，Java许多同步类的实现都依赖于它，比如常用的ReentrantLock、Semaphore、CountDownLatch等，我们也可以利用AQS自己实现一个锁。 AQS类内部的核心为volatile int state(共享资源)和CLH线程等待队列(阻塞队列)，整个AQS类内部大量的方法都是围绕state、CLH队列在处理逻辑。 statestate作为共享资源被应用在多线程竞争上，自带的volatile关键字可以保证可见性、有序性，在搭配CAS使用后可以保证操作的原子性。state初始状态为0，线程使用CAS对state+1成功后持有锁，后续每次重入state+1、退出state-1，state递减为0时代表锁释放。 CLH队列当线程竞争失败后会被封装成Node节点加入CLH队列，CLH队列在AQS中是以前驱节点(head)、后驱节点(tail)俩个成员构成的Node类型链表: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&#x2F;&#x2F; 前驱节点private transient volatile Node head;&#x2F;&#x2F; 后驱节点private transient volatile Node tail;&#x2F;&#x2F; 静态内部类Nodestatic final class Node &#123; &#x2F;** 共享锁 *&#x2F; static final Node SHARED &#x3D; new Node(); &#x2F;** 独占锁 *&#x2F; static final Node EXCLUSIVE &#x3D; null; &#x2F;** 表示线程已被取消 *&#x2F; static final int CANCELLED &#x3D; 1; &#x2F;** 表示后续线程需要取消阻塞 *&#x2F; static final int SIGNAL &#x3D; -1; &#x2F;** 表示线程在条件下等待 *&#x2F; static final int CONDITION &#x3D; -2; &#x2F;** 表示下一个获取共享应无条件传播 *&#x2F; static final int PROPAGATE &#x3D; -3; &#x2F;** * 节点等待状态 * 等于0:该节点尚未被初始化完成 * 大于0:说明该线程中断或者等待超时，需要移除该线程 * 小于0:该线程处于可以被唤醒的状态 *&#x2F; volatile int waitStatus; &#x2F;** 前驱节点 *&#x2F; volatile Node prev; &#x2F;** 后继节点 *&#x2F; volatile Node next; &#x2F;** 获取同步状态的线程 *&#x2F; volatile Thread thread; &#x2F;** 将单向列表变成双向列表 *&#x2F; Node nextWaiter; &#x2F;&#x2F; 是否为共享节点 final boolean isShared() &#123; return nextWaiter &#x3D;&#x3D; SHARED; &#125; &#x2F;&#x2F; 获取前继节点，没有就抛出异常 final Node predecessor() throws NullPointerException &#123; Node p &#x3D; prev; if (p &#x3D;&#x3D; null) throw new NullPointerException(); else return p; &#125; &#x2F;&#x2F; 无参构造器 Node() &#123; &#125; &#x2F;&#x2F; 构造器 Node(Thread thread, Node mode) &#123; &#x2F;&#x2F; Used by addWaiter this.nextWaiter &#x3D; mode; this.thread &#x3D; thread; &#125; &#x2F;&#x2F; 构造器 Node(Thread thread, int waitStatus) &#123; &#x2F;&#x2F; Used by Condition this.waitStatus &#x3D; waitStatus; this.thread &#x3D; thread; &#125;&#125; Node内部类主要通过waitStatus来表示状态，主要有五种状态: 状态 状态值 描述 INITAL 0 初始状态 CANCELLED 1 此节点的后继节点(或即将)被阻塞，因此当前节点在释放或取消时必须取消对其后继节点的阻塞 SIGNAL -1 此节点的后继节点(或将很快)被阻塞(通过park)，因此当前节点在释放或取消时必须取消对其后继节点的阻塞。为了避免争用，获取方法必须首先表明它们需要一个信号，然后重试原子获取，然后在失败时阻塞 CONDITION -2 节点线程等待在Condition上，当其他线程对Condition调用了signal()方法后，该节点从等待队列中转移到同步队列中，加入到对同步状态的获取中 PROPAGATE -3 与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态 链表入列链表的入列采用CAS方式进行，前驱节点与后驱节都是被volatile修饰的，因此使用CAS修改可以保证绝对安全，在enq方法中AQS使用死循环保证节点可以正确添加，只有成功添加后，当前线程才会从该方法返回，否则会一直执行下去: 123456789101112131415161718192021222324252627282930313233343536private Node addWaiter(Node mode) &#123; &#x2F;&#x2F; 新建Node Node node &#x3D; new Node(Thread.currentThread(), mode); &#x2F;&#x2F; CAS快速尝试添加尾节点(侥幸心理，万一成功了呢) Node pred &#x3D; tail; if (pred !&#x3D; null) &#123; node.prev &#x3D; pred; &#x2F;&#x2F;CAS设置尾节点 if (compareAndSetTail(pred, node)) &#123; pred.next &#x3D; node; return node; &#125; &#125; &#x2F;&#x2F;多次尝试 enq(node); return node;&#125; private Node enq(final Node node) &#123; &#x2F;&#x2F;多次尝试，直到成功为止 for (;;) &#123; Node t &#x3D; tail; &#x2F;&#x2F;tail不存在，设置为首节点 if (t &#x3D;&#x3D; null) &#123; if (compareAndSetHead(new Node())) tail &#x3D; head; &#125; else &#123; &#x2F;&#x2F;设置为尾节点 node.prev &#x3D; t; if (compareAndSetTail(t, node)) &#123; t.next &#x3D; node; return t; &#125; &#125; &#125; &#125; 当线程被封装成Node节点成功追加到等待队列尾部后，为了节约CPU资源就需要将当前线程挂起了(被阻塞的线程如果支持可中断并且被中断，自动唤醒并抛出中断异常): 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051final boolean acquireQueued(final Node node, int arg) &#123; &#x2F;&#x2F; 获取资源是否失败标记 boolean failed &#x3D; true; try &#123; &#x2F;&#x2F;标记等待过程中是否被中断过 boolean interrupted &#x3D; false; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F;拿到前驱节点 final Node p &#x3D; node.predecessor(); &#x2F;* * 如果前驱是head，说明自己排在第二位，有可能马上就被执行 * 所以再次尝试tryAcquire()获取，如果失败就挂起等待 * 当然有可能是第一位搞完了释放资源唤醒自己，也有可能被interrupt *&#x2F; if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123; &#x2F;&#x2F; 获取到资源后，把自己设置为head，也就是说head指向的永远是当前拿到资源的 setHead(node); &#x2F;&#x2F; 断绝与前驱节点的联系，方便被GC回收 p.next &#x3D; null; &#x2F;&#x2F; 成功获取资源后将失败标记为false failed &#x3D; false; &#x2F;&#x2F; 返回等待过程中是否被中断过 return interrupted; &#125; &#x2F;* * 先去检查自己是否真的可以被挂起了，如果不符合条件会进入下一次循环直到符合为止 * 调用park()方法将自己挂起，直到被唤醒 * 唤醒后会返回是否被中断标记，方便下次return出去 *&#x2F; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted &#x3D; true; &#125; &#125; finally &#123; &#x2F;&#x2F; 如果等待过程中没有成功获取资源(如timeout，或者可中断的情况下被中断了)，取消结点在队列中的等待。 if (failed) cancelAcquire(node); &#125;&#125; shouldParkAfterFailedAcquire方法，检查自己是否真的可以被挂起了: 123456789101112131415161718192021private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; &#x2F;&#x2F; 拿到前驱节点的状态 int ws &#x3D; pred.waitStatus; &#x2F;&#x2F; 如果前驱节点的状态是SIGNAL，那么前驱节点执行完会自动唤醒自己，放心的将自身挂起就好了 if (ws &#x3D;&#x3D; Node.SIGNAL) return true; &#x2F;&#x2F; 如果前驱节点执行过程中放弃了(超时或者其他的)，一直往前找，直到找到正常等待的状态节点 if (ws &gt; 0) &#123; do &#123; node.prev &#x3D; pred &#x3D; pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next &#x3D; node; &#125; else &#123; &#x2F;&#x2F; 如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; parkAndCheckInterrupt方法，就是挂起: 12345678private final boolean parkAndCheckInterrupt() &#123; &#x2F;&#x2F;调用park()使线程进入waiting状态 LockSupport.park(this); &#x2F;&#x2F;如果执行到这里，说明被唤醒，查看自己是不是被中断的。 return Thread.interrupted();&#125; 内部方法主要方法 acquire(int arg):独占式获取同步状态，如果当前线程获取成功则返回，否则加入等待队列 acquireInterruptibly(int arg):独占式获取同步状态(同上)，如果被打断直接抛异常 tryAcquire(int arg):独占式获取同步状态(供开发者重写) tryAcquireNanos(int arg，long nanosTimeout):独占式获取同步状态，增加超时限制 release(int arg):独占式释放同步状态，释放后将同步队列中第一个节点包含的线程唤醒 tryRelease(int arg):独占式释放同步状态(供开发者重写) acquireShared(int arg):共享式获取同步状态，如果当前线程获取成功则返回，否则加入等待队列 acquireSharedInterruptibly(int arg):共享式获取同步状态(同上)，如果被打断直接抛异常 tryAcquireShared(int arg):共享式获取同步状态(供开发者重写) tryAcquireSharedNanos(int arg，long nanosTimeout):共享式获取同步状态，增加超时限制 releaseShared(int arg):共享式释放同步状态，释放后将同步队列中第一个节点包含的线程唤醒 tryReleaseShared(int arg):共享式释放同步状态(供开发者重写) isHeldExclusively():当前同步器是否在独占式模式下被线程占用，一般该方法表示是否被当前线程所独占 方法虽然很多，不过很容易进行区分 首先争夺锁的方式有独占和共享 每种方式又包含加锁、释放锁方法 加锁的方法又分为直接加锁、超时加锁、中断加锁 直接加锁与中断加锁内部调用对应try开头的加锁方法处理 try开头的加锁方法采用模板模式，具体实现由开发者自己重写实现 最后一个是否独占并占用的查询 共享资源获取释放在需要开发者重写的获取资源方法中，独占式获取资源方法tryAcquire(int arg)返回值为boolean类型，仅仅需要告诉调用者获取成功还是失败即可。 而共享式获取资源方法acquireShared(int arg)返回int类型，大于等于零表示成功，小于零则表示失败，因为是共享所以允许多个线程访问获取，但有些时候我们需要限制访问数量。这就可以设置一个阈值，每次有线程进来时阈值-1消耗，当消耗为零的时候，后续线程就不允许访问了，直接进入等待队列。 同样的，共享式资源的释放相比较独占式逻辑也有不同，除了唤醒后继节点，还需要将阈值+1。 独占式源码解析acquire(获取锁) 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 先尝试用重写的tryAcquire(arg)方法，由于独占锁同一时刻只允许一个线程持有，这就需要开发者在重写方法时要利用好state属性，确保拿到锁的线程返回true，在没有释放前其他线程访问返回false。如果返回false就将线程封装成一个独占式锁加入队列中，紧接着尝试挂起线程。 release(释放锁) 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h &#x3D; head; if (h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0) unparkSuccessor(h); return true; &#125; return false;&#125; 先尝试调用重写的tryRelease(int arg)释放锁，如果成功后判断自身状态，如果节点状态不等于0(也就是还没退出等待队列)，调用unparkSuccessor方法释放锁。 12345678910111213141516171819202122232425262728private void unparkSuccessor(Node node) &#123; &#x2F;&#x2F; 获取当前节点的状态 int ws &#x3D; node.waitStatus; &#x2F;&#x2F; 如果小于0，使用CAS设置为0，0代表退出等待队列 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); &#x2F;&#x2F; 获取后继节点 Node s &#x3D; node.next; &#x2F;&#x2F; 如果没有后继节点，或者后继节点状态大于0，也就是说已经退出队列了 if (s &#x3D;&#x3D; null || s.waitStatus &gt; 0) &#123; &#x2F;&#x2F; 方便GC回收 s &#x3D; null; &#x2F;&#x2F; 不停的往后面找，直到找到状态正常的为止 for (Node t &#x3D; tail; t !&#x3D; null &amp;&amp; t !&#x3D; node; t &#x3D; t.prev) if (t.waitStatus &lt;&#x3D; 0) s &#x3D; t; &#125; &#x2F;&#x2F; 如果找到了就唤醒 if (s !&#x3D; null) LockSupport.unpark(s.thread); &#125; 这个方法的逻辑也很简单，使用CAS方式将自身节点状态设置为0，紧接着根据自身的waitStatus判断后继节点是否需要被唤醒，如果后继节点因为响应中断等情况放弃了，就继续往后找，直到找到可以背唤醒的节点线程。 acquireInterruptibly(获取锁并支持中断) 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; 先判断是否中断状态，如果是直接抛异常。如果不是中断状态，进入doAcquireInterruptibly(arg)方法。 123456789101112131415161718192021222324252627private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node &#x3D; addWaiter(Node.EXCLUSIVE); boolean failed &#x3D; true; try &#123; for (;;) &#123; final Node p &#x3D; node.predecessor(); if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next &#x3D; null; &#x2F;&#x2F; help GC failed &#x3D; false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; 代码逻辑与acquire几乎一致，AQS阻塞等待逻辑的老套路就是，如果等待线程的前驱节点不是head则使用park()挂起，在parkAndCheckInterrupt()中实现，紧接着下一行返回中断状态。处于挂起状态的线程如果被中断，会立刻结束挂起状态，因此在上面的代码中会满足第二个if判断，抛出中断异常。这里有个疑问，如果前驱节点是head，中断没做任何处理？ doAcquireNanos(获取锁并支持中断、超时)进入方法前获取当前时间戳，每次循环再次获取当前时间戳用差值判断是否超时，就算是被挂起的，也是调用park(this,nanosTimeout)进行挂起，到达超时时间直接跳出自旋。其他逻辑和doAcquireInterruptibly()一致。 共享式源码解析acquireShared(获取锁) 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; 先尝试用重写的acquireShared(arg)方法，由于共享锁同一时刻时允许多个线程进行访问的，AQS将重写方法设计为支持同一时刻最大访问限制数，返回值的int类型，表示如果当前线程进入访问后还能剩余多少访问数，如果为负数证明已经没有访问名额了，只能阻塞等待。 releaseShared(释放锁) 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; 先尝试用重写的tryReleaseShared(arg)释放锁，加锁的时候是对state(访问限制数)-1，那么释放锁自然是加回来，这时有可能很多线程都在释放锁，因此在重写方法里加值要使用CAS方式。释放成功就代表有资源空闲出来，调用doReleaseShared方法唤醒后续节点。 123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h &#x3D; head; if (h !&#x3D; null &amp;&amp; h !&#x3D; tail) &#123; int ws &#x3D; h.waitStatus; if (ws &#x3D;&#x3D; Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; &#x2F;&#x2F; loop to recheck cases unparkSuccessor(h); &#125; else if (ws &#x3D;&#x3D; 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#x2F;&#x2F; loop on failed CAS &#125; if (h &#x3D;&#x3D; head) &#x2F;&#x2F; loop if head changed break; &#125;&#125; 在自旋的阶段，每一次循环的过程都是首先获得头结点，如果头结点不为空且不为尾结点(阻塞队列里面只有一个结点)，那么先获得该节点的状态，如果是SIGNAL的状态，则代表它需要有后继结点去唤醒，首先将其的状态变为0，因为是要释放资源了，它也不需要做什么了，所以转变为初始状态，然后去唤醒后继结点unparkSuccessor(h)，如果结点状态一开始就是0，那么就给他转换成PROPAGATE状态，保证在后续获取资源的时候，还能够向后面传播（这一块不明白）。 tryAcquireSharedNanos(获取锁并支持中断、超时)进入方法前获取当前时间戳，每次循环再次获取当前时间戳用差值判断是否超时，就算是被挂起的，也是调用park(this,nanosTimeout)进行挂起，到达超时时间直接跳出自旋。其他逻辑和tryAcquireShared()一致。 简单应用看懂AQS的原理机制后，我们可以尝试自己写一个不可重入锁，首先定义一下锁资源(AQS中的state)的含义，0表示未被加锁，1表示已经加锁。直接上代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class CustomLock &#123; private Sync sync; &#x2F;&#x2F; 自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; &#x2F;&#x2F; 判断是否锁定状态 @Override protected boolean isHeldExclusively() &#123; return getState() &#x3D;&#x3D; 1; &#125; &#x2F;&#x2F; 获取资源 @Override protected boolean tryAcquire(int arg) &#123; &#x2F;&#x2F; 使用CAS修改状态，如果成功设置当前资源为独占资源 if(compareAndSetState(0, 1))&#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; &#x2F;&#x2F; 释放资源 @Override protected boolean tryRelease(int arg) &#123; &#x2F;&#x2F;既然释放，肯定就是已占有状态了，为了代码健壮一点加层判断 if (getState() &#x3D;&#x3D; 0) throw new IllegalMonitorStateException(); &#x2F;&#x2F; 清空独占记录 setExclusiveOwnerThread(null); &#x2F;&#x2F; 释放共享资源，tryRelease还没执行完，线程仍然持有锁，因此不需要CAS修改 setState(0); return true; &#125; &#125; &#x2F;&#x2F; 在自定义加锁对象创建时，为其初始化一个同步器 public CustomLock()&#123; sync &#x3D; new Sync(); &#125; &#x2F;&#x2F; 加锁 public void lock() &#123; sync.acquire(1); &#125; &#x2F;&#x2F; 单次加锁尝试 public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; &#x2F;&#x2F; 释放锁 public void unlock()&#123; sync.release(1); &#125; &#x2F;&#x2F; 锁是否处于加锁状态 public boolean isLocked()&#123; return sync.isHeldExclusively(); &#125;&#125; 可重入锁在加锁、释放锁的时候需要对state进行加减操作，并且确保退出的时候state为零，再此期间其他线程访问时如果state大于等于零，则获取锁失败。由于这段代码设计的是不可重入锁，不需要记录次数，仅仅有加锁(1)和未加锁(0)俩中状态，因此lock()、tryLock()、unlock()方法传参随便写都可以，在内部类Sync重写AQS方法中已经写死。 利用AQS我们可以实现很多种同步机制，比如CountDownLatch、CyclicBarrier、Semaphore、Lock诸多实现类，都是利用AQS来实现。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(七) synchronized关键字","slug":"synchronized关键字","date":"2020-03-07T05:00:00.000Z","updated":"2020-10-19T07:47:11.609Z","comments":true,"path":"2020/03/07/synchronized关键字/","link":"","permalink":"http://yoursite.com/2020/03/07/synchronized%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"简介如果我们想要保证单个共享变量的原子操作，可以借助CAS来实现，当我们想要保证多个共享变量的原子操作时，那就要把对多个变量的操作代码整合在一起建立临界区，临界区同一时刻只能有一个线程访问。而synchronized关键字就是java老牌的互斥锁，保证操作的原子性、可见性、有序性，同时还保证锁的可重入性。 synchronized使用 修饰方法的时候，如果是普通方法，加锁目标是此实例对象(new出来的、存放在堆中的某个对象) 修饰方法的时候，如果是静态方法，加锁目标是当前类的class对象(存在方法区的类结构对象) 修饰代码块的时候，需要指定某个实例对象或class对象作为加锁目标 jvm对象头无论哪种方式实现线程同步，都必须指定一个对象并获得此对象的锁才有资格执行同步方法或代码块，synchronized的实现完全依赖于jvm，因此理解synchronized的底层实现，就必须理解对象在jvm是如何存储的，关于锁的那部分数据信息又是如何维护的。 在JVM虚拟机中，对象在内存中的存储布局，一般情况下分为三个区域： 对象头(包括标记字段、类型指针) 实例数据(存储对象自身定义的数据) 对齐填充(jvm要求对象的内存大小必须是8字节整倍数，对齐填充用于补全大小到整倍数) 如果对象是数组，还会有个区域记录数组的长度，用于判断数组对象的内存大小 有关对象锁的数据全部存储在对象头区域中，我们使用java提供的jol工具来看看对象的头部信息详细结构(测试为64位操作系统): 1.先添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jol-core&lt;&#x2F;artifactId&gt; &lt;version&gt;0.9&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 2.创建测试用对象 12345678910111213141516171819public class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name &#x3D; name; this.age &#x3D; age; &#125; public synchronized void doSomething()&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; ... &#125; &#125;&#125; 3.执行main方法 1234public static void main(String[] args) &#123; Person person &#x3D; new Person(&quot;李逍遥&quot;,18); System.out.println(ClassLayout.parseInstance(person).toPrintable());&#125; 4.打印结果 表头代表的含义： 列名 描述 OFFSET 偏移地址，单位字节 SIZE 占用的内存大小，单位字节 TYPE DESCRIPTION 类型描述，其中object header为对象头类型 VALUE 类型对应的值 颜色标记区域代表的含义： 区域 描述 红色 标记字段，内部结构比较复杂，而且会不断变化，下面单独讲 蓝色 类型指针，通常由64位组成，但是我们jvm会默认对其压缩到32位，因此占用4字节 绿色 实例数据，基本数据类型会直接打印值，引用数据类型显示(object) 黄色 对齐填充，图中对象占用总内存为20字节，因此对齐填充补了4字节确保是8字节倍数 与synchronized底层原理关联最为密切的就是红色区域了，这个区域也比其他区域更为复杂一点，标记字段拥有8字节的内存大小(也就是64位)，对象锁状态的不同，这64位存储的内容也不同： 标记字段中存储的信息： hash:存储对象哈希码，只有在调用hashCode()方法的时候才会生成，默认是没值的 age:jvm分代年龄，用于判断是否晋升老年代 biased_lock:偏向锁标识位 lock:锁状态标识位 JavaThread:保存持有偏向锁的线程ID epoch:保存偏向时间戳(并不是我们理解的long类型时间戳) Pointer to Lock Record:指向线程栈中锁记录的地址 Pointer to Monitor:指向jvm监控对象的地址 无锁状态所谓无锁状态，就是对象还没有被加过锁，也就是说内部的synchronized修饰的方法还没有任何线程调用过，上面打印的截图是没有调用hashCode()方法的，我们写个调用hashCode()方法的测试代码： 12345public static void main(String[] args)&#123; Object lockObject &#x3D; new Object(); System.out.println(&quot;哈希码 : &quot; + lockObject.hashCode()); System.out.print(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果： 我们把二进制数据拼接起来，拼接规则是从下至上、从右到左。 最终拼接结果为:00000000 00000000 00000000 01111011 00011101 01111111 11111111 00000001 取出哈希码:1111011 00011101 01111111 11111111 随便找个进制转换器就能算出来结果是:2065530879，与main方法打印的一致。 偏向锁偏向锁是jdk1.6引入的一项锁优化，意思是偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。 JVM启动时会进行一系列的复杂活动，比如装载配置，系统类初始化等等。在这个过程中会使用大量synchronized关键字对对象加锁，且这些锁大多数都不是偏向锁。为了减少初始化的时间，JVM默认采用延时加载偏向锁的机制(大概4秒左右)。在延迟时间内是没有偏向锁概念的，对象创建完毕后是无锁状态，即使需要进行锁升级也是直接升级到轻量级锁，当到达延迟时间之后创建出来的对象，锁状态都是偏向锁状态。 所以我们直接执行main方法是看不到偏向锁信息的，当然也可以在创建对象之前sleep五秒，不过这个方法太low逼了，JVM提供了取消偏向锁延迟加载命令:-XX:BiasedLockingStartupDelay=0 测试类走起: 1234public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); System.out.println(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果: 打印结果可以看出，对象还没有被作为加锁对象使用，偏向线程是空的。我们写个持有偏向线程的代码，并且手动调用一次gc看看age有没有增长: 1234567public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); System.gc(); synchronized (lockObject)&#123; System.out.print(ClassLayout.parseInstance(lockObject).toPrintable()); &#125;&#125; 打印结果: 打印结果中并不存在hashcode，这是因为在HotSpot虚拟机中，偏向锁与hashcode不可以并存(我估计是JavaThread占用的太多，没地方了…)，如果在无锁状态调用hashcode方法，直接升级到轻量级锁，如果是偏向锁状态下调用hashcode()，直接进入偏向锁撤销阶段。这种规则仅限于没有重写hashcode()方法的情况下。 偏向锁工作流程图: CAS获取偏向锁步骤整个流程图最大的疑问在于CAS获取偏向锁的这一步骤，如果线程A获取偏向锁并开始执行同步代码或方法块期间，线程B试图访问同步方法或代码块，按照我们的理解CAS成功是必然的，因为此刻线程A还在执行临界区代码，不会对标记字段进行修改干扰到线程B，这不就出现2个线程同时进入同步代码了吗？ 实时并非如此，无论是无锁状态(001)下的CAS，还是偏向锁状态下的CAS，期望值参数永远是null，也就意味着多个线程同时对无锁状态的同步代码争夺偏向锁，仅有一个线程会成功并成为偏向线程，之后任何线程在尝试CAS获取偏向锁永远是失败的(因为JavaThread已经非null)，直接进入偏向锁撤销阶段。 锁撤销偏向锁的撤销需要到达JVM的STW才会执行，这个时间点内所有字节码都不会执行，紧接着挂起偏向线程，根据isAlive()判断偏向线程状态再做后续处理: 如果处于未活动状态，说明偏向线程已经执行完毕并死亡，说明没有发生竞争，直接释放偏向锁。 如果处于活动状态并且已经退出同步代码块，说明没有发生竞争，释放偏向锁后需要唤醒线程继续执行。 如果处于活动状态并且未退出同步代码块，说明发生竞争,直接升级到轻量级锁。 锁重偏向通过对撤销步骤的了解不难发现，只有在到达安全点后，偏向线程已经死亡或者退出同步代码块，加锁对象的markword中JavaThread和epoch才会被清空，直到下一个线程获得偏向锁，加锁对象重新偏向另一个线程。 锁批量撤销JVM会以class为单位，为每个class分配一个偏向锁撤销计数器，每次class的实例被撤销偏向锁时计数器+1，当某个class的计数器达到阈值时(JVM参数控制)，JVM会将该class的所有实例批量撤销偏向锁，并且该class后续创建的所有实例都是不可偏向的(直接是轻量级锁)。 批量撤销阈值: -XX:BiasedLockingBulkRevokeThreshold = 40 锁批量重偏向重偏向操作需要等到安全点才可以触发，如果刚触发锁撤销操作的时候，偏向线程就执行完同步代码块，那么此时等待安全点是没有任何意义的，并且锁撤销也会占用一定的STW时间。由此可以看出频繁的锁撤销会对性能带来一定影响，为了解决这个问题，JVM引入了批量重偏向概念来减少锁撤销的频率。 与批量撤销的相似，批量重偏向也是在class的计数器达到一定阈值时触发，执行过程: 当到达安全点时发现偏向次数到达阈值触发批量重偏向，会对class中的epoch进行+1运算得出epoch_new jvm扫描所有该class的实例对象，并筛选出处于偏向锁状态的实例对象，把所有筛选对象的epoch改成epoch_new 退出安全点后，有线程需要尝试获取偏向锁，检查加锁对象的epoch与对应class的epoch是否一致 如果一致，根据JavaThread是否为自身ID决定撤销锁还是直接进入同步代码(还是原来的逻辑) 如果不一致说明偏向锁已经无效，不会因为加锁对象偏向其他线程而触发撤销操作，而是直接尝试CAS获取锁 注:我猜测此时期望值不在是null而是重新获取加锁对象的markword，获取到锁之后还会把class的epoch归零，因为epoch就2位不可能一直递增。 批量重偏向阈值: -XX:BiasedLockingBulkRebiasThreshold = 20 锁撤销计数器重置即使在竞争很少发生的应用中，随着时间的流逝，各class的锁撤销计数器总有到达阈值的时候。比如某个class的所有实例对象一小时才触发一次锁撤销，那么默认40小时后会触发批量锁撤销，后续所有对象的创建全都是轻量级锁。这种竞争程度简直毛毛雨，根本没必要使用轻量级锁增加无意义的性能消耗。对此JVM增加了两次批量锁撤销事件触发时差的阈值判断，如果距离上次批量撤销时差小于等于阈值时差就执行批量锁撤销，否则仅仅将锁撤销计数重置为零。 批量锁撤销时差阈值(毫秒): -XX:BiasedLockingBulkRebiasThreshold = 25000 启用禁用偏向锁撤销的作用很明显了，根据线程对此临界代码的访问是否发生竞争，来决定将锁恢复到无锁状态还是升级到轻量级。没有发生竞争的情况下，偏向锁的逻辑仍然能保证很好的性能，一旦发生竞争，就需要更高级的锁来最大化性能。偏向锁在竞争稍微激烈的情况下其实没什么卵用，如果你觉得你的应用对于大多数锁的竞争都是比较频繁的，偏向锁完全没有存在的必要，可以设置JVM启动参数来禁用偏向锁(默认延迟打开): 禁用偏向锁: -XX:-UseBiasedLocking 可重入性偏向锁是在没有发生竞争的情况下才存在，线程拿到偏向锁后成为偏向线程，在没有发生偏向锁撤销情况下，后续访问是没有资源消耗的，可以直接执行临界代码，这就代表偏向锁阶段完全支持可重入。 非公平性不存在竞争因此也不存在是否公平性可言。 轻量级锁轻量级锁也是jdk1.6引入的一项锁优化，是在锁发生竞争但竞争不是特别激烈情况下的折中解决方案，降低重量级锁使用过程中的性能消耗。 我们写个测试类(使用 -XX:-UseBiasedLocking命令，禁用偏向锁): 123456public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); synchronized (lockObject)&#123; System.out.println(ClassLayout.parseInstance(lockObject).toPrintable()); &#125;&#125; 打印结果: 轻量级锁的标记字段结构很简单，只存储锁标志、锁记录俩个信息，hashcode和age转移到Lock Record中进行存储。 轻量级锁工作流程图: 自旋次数在自旋竞争锁过程中，如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。这个自旋次数在jdk1.5是写死的参数无法更改，到了jdk1.6版本可以通过jvm参数控制自旋次数(默认10)，jdk1.7版本后又去掉了此参数，因为这个时候的jvm已经相当成熟，会根据内部收集的性能日志自己判定自旋次数。 轻量级锁自旋次数: -XX:PreBlockSpin=10 锁释放持锁线程执行完释放锁后，将拷贝的markword作为期望值，使用CAS修改加锁对象的markword，可以理解为将hashcode、age等信息还回去。有可能此时已经膨胀到重量级锁，加锁对象的markword已经变更，这种情况下CAS必然失败，这时候直接执行重量级锁的唤醒逻辑。 解锁操作为什么要用CAS来操作呢? 这是为了防止在解锁的时候，锁由于竞争的激烈程度再次提高，已经升级到重量级锁并且把其他线程阻塞，这种情况下如果不唤醒阻塞的线程，这些线程将永远阻塞在这里。 可重入性偏向线程执行过程中遇到锁升级信号(已经发出偏向锁撤销请求)，JVM会在该线程栈中分配一个Lock Record，并把加锁对象的markword拷贝进来，如果已经是轻量级锁情况下，线程访问临界代码前也会执行同样操作。这也就意味着持有轻量级锁过程中，加锁对象的hashcode、age等信息转移到了持锁线程的Lock Record中，持锁线程的Lock Record同样也会保存加锁对象markword的地址，两者是互相引用的关系，这样既能保证加锁对象的hashcode、GC年龄随时可以访问，也可以解决可重入的问题。 非公平性顶多俩线程在竞争，一个在执行，一个在自旋等待，因此也没有是否公平性可言。 重量级锁轻量级锁膨胀之后，就升级为重量级锁了。重量级锁是依赖对象关联的monitor锁来实现的，每个java对象都有一个与之对应的monitor对象，随着java对象一起创建一起销毁。而monitor又依赖操作系统的MutexLock(互斥锁)来实现的，所以重量级锁也被成为互斥锁。 在HotSpot虚拟机中，Monitor是基于C++实现的，封装成ObjectMonitor对象，具体成员变量: 属性名 默认值 属性描述 _header NULL 锁对象的原始对象头 _count 0 用来记录该线程获取锁的次数 _waiters 0 进入wait状态的线程数 _recursions 0 锁的重入次数 _object NULL 关联的锁对象 _owner NULL 指向持有ObjectMonitor对象的线程，锁释放后设置为null _WaitSet NULL 调用wait()方法后进入的wait集合 _WaitSetLock 0 操作WaitSet链表的锁 _Responsible NULL 防止搁浅情况 _succ NULL 假定继承线程 _cxq NULL 被挂起线程等待重新竞争锁的单向链表，为了避免插入和取出元素的竞争，所以Owner会从列表尾部取元素 FreeNext NULL Free list linkage _EntryList NULL 处于block状态的线程集合，被notify唤醒后重新加入竞争也是进入此队列 _SpinFreq NULL 自旋成功率 _SpinClock 0 自旋时钟 OwnerlsThread 0 表明当前owner原来持有轻量级锁 _previous_owner_tid 0 上一个获取锁的线程id 写个重量级锁mode: 1234567891011121314151617181920212223242526272829public static void main(String[] args)&#123; Object lockObject &#x3D; new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lockObject) &#123; while (true) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lockObject) &#123; while (true) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#125;).start(); System.out.println(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果: 阻塞过程monitor对象在轻量级锁膨胀后初始化，并且将状态设置为膨胀中(INFLATING)，在膨胀期间有线程访问直接进入忙等状态。当一个线程尝试获取锁并且获取失败，则将线程封装为ObjectWaiter插入到cxq的队列的队首，进入cxq队列的线程还会再次尝试自旋获取锁，如果还是失败则调用park函数挂起线程。park函数涉及到内核态的切换，因此比较耗时，也是被称为'重'锁的原因。 自旋目的争夺锁失败插入cxq队列后仍然会进行自旋的目的在于，防止同步块中代代码较少、执行比较快的情况下，频繁的park函数调用导致频繁的内核态的切换影响性能。关于自旋次数在JDK1.6之前默认10次，之后版本改成了适应性自旋由JVM自己控制。 防止搁浅当线程获得锁后，会去查询当前是否还有其他线程等待获取锁，如果没有则将_Responsible设置为自身，在进入cxq后自旋仍然没获取锁会再次判断_Responsible是否为自身，如果是则调用有时间限制的park方法，估计是考虑到特殊场景下所有线程都处于阻塞导致没有线程进行释放锁操作，出现搁浅情况。 线程释放当锁被释放后，会从_cxq或_EntryList中挑选一个线程唤醒，被选中的线程为假定继承人赋值给_succ，即使_succ重新加入竞争也不能保证会获取到锁，所以_succ也只能称为假定继承人。 重量级锁工作流程图: 可重入性monitor通过_owner属性判断线程有无权限进入同步代码块，再根据_recursions属性用来记录重入次数，进入临界代码时+1、退出时-1，由此可以保证重入性。 非公平性jvm在唤醒线程时会根据内部参数QMode的值决定使用哪种唤醒策略，可能从_cxq中选取一个，也可能从_EntryList中选取一个，_cxq队列的线程也会因为策略被转移到_EntryList队列的首部或尾部。被选中的线程也不保证能拿到锁，因此synchronized是非公平的。 GC标记如果设置finalize()或许还有一线生机，没设置就等死吧…. 锁降级synchronized是由JVM来实现的，因此锁是否支持降级完全取决于JVM设计者，本文所有技术点均来自HotSpot虚拟机。HotSpot虚拟机在进入安全点的时候，会去检查是否有空闲的monitor，如果有就试图进行降级。在轻量级锁释放锁的时候会将拷贝的markwordCAS修改回去，如果成功，是不是也代表降级为偏向锁了呢？这个问题没有找到答案，以后搞懂了再改。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"多线程(六) 锁分类","slug":"锁分类","date":"2020-03-06T05:00:00.000Z","updated":"2020-10-19T08:17:40.042Z","comments":true,"path":"2020/03/06/锁分类/","link":"","permalink":"http://yoursite.com/2020/03/06/%E9%94%81%E5%88%86%E7%B1%BB/","excerpt":"","text":"前言java中的锁可谓是五花八门，各种锁功能相似又不同，有的是概念、有的是java接口、有的是实现类，让你很难找到明显的分界线去区分并记住他们。所以学习锁首先要打消一种想法，就是一个锁只属于一个分类，比如一个锁可以同时是乐观锁、可重入锁，公平锁，就像一个人可以是男人、程序员、健身爱好者。 synchronized与Lockjava代码中两种加锁方式 一种是用synchronized关键字，另一种是用Lock接口的实现类。形象地说，synchronized关键字是自动档，可以满足一切日常驾驶需求。但是如果你想要玩漂移或者各种骚操作，就需要手动档了——各种Lock的实现类，因为Lock的实现类可以通过设置不同的参数改变锁的作用达到灵活适应场景的作用，而synchronized是关键字，底层有jvm实现，很多参数都是写死的。 悲观锁与乐观锁锁的一种宏观分类方式是悲观锁和乐观锁。悲观锁与乐观锁并不是特指某个锁(Java中没有哪个Lock实现类就叫PessimisticLock或OptimisticLock)，而是在并发情况下的两种不同策略。 悲观锁(Pessimistic Lock)，就是很悲观，每次去拿数据的时候都认为别人会修改。所以每次在拿数据的时候都会上锁，这样别人想拿数据就被挡住，直到悲观锁被释放。比如上面说的synchronized与Lock。 乐观锁(Optimistic Lock), 就是很乐观，每次去拿数据的时候都认为别人不会修改。所以不会上锁，这里的上锁是指互斥性质的上锁，在说明白点就是我加锁了谁也别想碰，除非我释放锁，乐观锁采用的是类似CAS的方式，保证操作数据不会干扰到其他线程。 悲观锁阻塞事务，乐观锁回滚重试，它们各有优缺点，不要认为一种一定好于另一种。像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行重试，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 自旋锁有一种锁叫自旋锁。所谓自旋，说白了就是一个** while(true) ** 无限循环。这个自旋锁与Atomic类的while实现的自旋代码不是一回事，下一章AQS会详细讲 synchronized锁升级前面提到synchronized关键字就像是汽车的自动档。一脚油门踩下去，synchronized会从无锁升级为偏向锁，再升级为轻量级锁，最后升级为重量级锁，就像自动换挡一样。那么自旋锁在哪里呢？这里的轻量级锁就是一种自旋锁。 初次执行到synchronized代码块的时候，锁对象变成偏向锁(通过CAS修改对象头里的锁标志位，说明白点就是锁记住了第一次和他发生关系的线程)，字面意思是“偏向于第一个获得它的线程”的锁，执行完同步代码块后，线程并不会主动释放偏向锁。第二次访问如果还是此线程，那么就没有加锁释放锁这一说，正常执行。 一旦有第二个线程加入锁竞争并发现锁是偏向锁，会去断线程A是否仍然存活。如果线程A仍然存活，将线程A暂停，此时偏向锁升级为轻量级锁，之后线程A继续执行，线程B自旋。但是如果判断结果是线程A不存在了，则线程B持有此偏向锁，锁不升级。 在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。 自旋锁避免不了的问题就是竞争特别激烈的情况下，其他线程只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做**忙等(busy-waiting)**。显然，此忙等是有限度的(有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改)。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁(依然是CAS修改锁标志位，但不修改持有锁的线程ID)。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起(而不是忙等)，等待将来被唤醒。在JDK1.6之前，synchronized直接加重量级锁，很明显现在得到了很好的优化。 可重入锁(递归锁)可重入锁的字面意思是“可以重新进入的锁”，即允许同一个线程多次获取同一把锁。比如一个递归函数里有加锁操作，递归过程中这个锁会阻塞自己吗？如果不会，那么这个锁就是可重入锁(因为这个原因可重入锁也叫做递归锁)。 公平锁、非公平锁如果多个线程申请一把公平锁，那么当锁释放的时候，先申请的先得到，非常公平。显然如果是非公平锁，后申请的线程可能先获取到锁，是随机或者按照其他优先级排序的。 对ReentrantLock类而言，通过构造函数传参可以指定该锁是否是公平锁，默认是非公平锁。一般情况下，非公平锁的吞吐量比公平锁大，如果没有特殊要求，优先使用非公平锁。对于synchronized而言，它也是一种非公平锁，但是并没有任何办法使其变成公平锁。 可中断锁这里的关键是理解什么是中断。Java并没有提供任何直接中断某线程的方法，只提供了中断机制。何谓“中断机制”？线程A向线程B发出“请你停止运行”的请求(线程B也可以自己给自己发送此请求)，但线程B并不会立刻停止运行，而是自行选择合适的时机以自己的方式响应中断，也可以直接忽略此中断。也就是说，Java的中断不能直接终止线程，而是需要被中断的线程自己决定怎么处理。这好比是父母叮嘱在外的子女要注意身体，但子女是否注意身体，怎么注意身体则完全取决于自己。 读写锁、共享锁、互斥锁读写锁其实是一对锁，一个读锁(共享锁)和一个写锁(互斥锁、排他锁)，Java提供了ReadWriteLock接口和实现类ReentrantReadWriteLock来实现读写锁。 读锁：防止读的时候其他线程写，允许读的时候其他线程读 写锁：防止写的时候其他线程读或写 使用锁带来的问题死锁、活锁、饥饿","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(五) CAS","slug":"CAS","date":"2020-03-05T05:00:00.000Z","updated":"2020-10-19T07:53:53.632Z","comments":true,"path":"2020/03/05/CAS/","link":"","permalink":"http://yoursite.com/2020/03/05/CAS/","excerpt":"","text":"什么是CASCAS的全称是Compare and Swap(比较和交换)，是一种特殊的修改数据的方式，线程通过CAS修改数据时整个过程涉及到三个数据：要修改的内存数据V、执行CAS操作前读取V并将V的值复制到工作空间计作A(预期值)、修改后的数据B，执行CAS操作中当且仅当预期值A和内存值V相同时，将内存值V修改为B并返回true，否则视为修改失败返回false。 Atomic对CAS的应用Atomic包是Java.util.concurrent下的另一个专门为线程安全设计的Java包，包含多个原子操作类，我们以AtomicInteger为例看看java如何通过CAS实现原子性。 incrementAndGet方法，以原子方式将当前值增加1并返回增加后的值： 1234public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 我们发现incrementAndGet方法把这个操作委托给unsafe类的getAndAddInt方法处理，我们继续看getAndAddInt方法源码： 123456789101112public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; &#x2F;&#x2F; 读取AtomicInteger在内存中对应的值，并复制一份赋值给var5，作为期望值 var5 &#x3D; this.getIntVolatile(var1, var2); &#x2F;&#x2F; 将AtomicInteger对象引用、偏移量、预期值、修改后的值交给compareAndSwapInt也就是CAS方法循环执行，直到true &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 代码中我们可以看到，真正的CAS修改操作是compareAndSwapInt方法，我们继续往下看： 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 到这里的时候我们发现compareAndSwapInt方法是被native修饰的，说明接下来的代码是使用C++实现的了。源码就不贴了，这个方法实际上是利用处理器提供的汇编指令CMPXCHG。当CPU执行此修改指令时发现带有CMPXCHG前缀，那么会采用CAS方式(比较并交换操作数)修改数据，并且保证比较、交换俩个步骤不会被上下文切换打断。当且仅当预期值var4与要修改的内存值相等时，将内存值修改为var5。 如果你细心的话会发现，在多核CPU的操作系统中仅仅保证CAS的俩个步骤不被上下文切换打断没什么卵用，如果俩个线程并行同时对某个AtomicInteger(0)执行incrementAndGet方法，怎么保证高速缓存中取出的期望值不是脏数据？怎么保证多个处理器不会同时执行到CAS的比较操作并且都返回true，继而同时修改内存值为1，最终导致结果应该是2却因为线程安全问题变为1？ 我们回头看看AtomicInteger的其他源码： 12345678910111213141516... private volatile int value; public AtomicInteger(int initialValue) &#123; value &#x3D; initialValue; &#125; public AtomicInteger() &#123; &#125; public final int get() &#123; return value; &#125; ... AtomicInteger内部有个int类型的value属性，代表着自身的值，并且AtomicInteger读写操作都是围绕这个值进行的，并且这个类被volatile修饰的。到这里思路就清晰了，volatile修饰符保证了value值的可见性，线程不会出现读到脏数据的情况。 对于第二种情况百度的资料很少提及，所以也无法确定CPU到底如何解决这个问题。但是我在知乎上看到了俩个感觉还算靠谱的答案。首先被volatile修饰的变量会使用MESI协议确保同一时刻只有一个处理器修改值，并且把其他处理器此值的缓存设为无效，当第二个处理器想要修改值时发现无效，CAS操作失败，返回false，另一个答案则表示当多个处理器同时使用cmpxchg指令(也就是CAS)操作同一个数据时，总线会进行仲裁只有一个处理器执行CAS，其他处理器连比较操作都不会执行，直到上一个处理器执行完毕后总线再次仲裁并选中自己。 第一种答案强调使用MESI的失效机制解决问题，第二种答案则强调将CAS视为一个整体，在执行比较操作的时候就会利用MESI协议将数据修改为M状态。不同的CPU架构可能解决问题的方式也不同，总之CPU保证多处理器并行执行CAS不会出错，Java保证volatile+自旋CAS修改数据的原子性，以后搞懂了再更新。 ABA问题我实在是不想写这个问题，我也想不到ABA会带来什么后果，通过CAS修改数据也想不到啥业务场景需要记录修改了多少次，百度一堆人云亦云此A非彼A瞎鸡吧复制，就是讲不明白此A和彼A到底有啥区别。但是Java在1.5版本引进了AtomicStampedReference类，采用版本号的机制解决这个操蛋的问题。 总结 CAS是典型的乐观派操作，每次都迷之自信认为操作一定成功，但是在高并发比较严重的情况下会导致大量线程不断的循环，增大CPU的消耗。 CAS只能保证单个共享变量的原子操作，如果操作涉及多个共享变量，必须要排他锁解决 仅仅依靠CAS无法保证原子性，必须配合CPU缓存锁一起保证。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(四) volatile关键字","slug":"volatile关键字","date":"2020-03-04T05:00:00.000Z","updated":"2020-10-19T07:53:31.881Z","comments":true,"path":"2020/03/04/volatile关键字/","link":"","permalink":"http://yoursite.com/2020/03/04/volatile%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"概述volatile是Java的一个修饰符，它在多线程编程开发中保证了共享变量的可见性和有序性。相对于各种排他锁，volatile在使用和执行成本上占用资源较少。 实现原理那么volatile如何保证可见性和有序性呢？我们写一段单例模式的java代码： 123456789101112131415161718192021package com.test;public class SingletonObject &#123; &#x2F;&#x2F; 单例对象 private static volatile SingletonObject instance; &#x2F;&#x2F; 获取单例对象方法 public static SingletonObject get()&#123; if(instance &#x3D;&#x3D; null)&#123; instance &#x3D; new SingletonObject(); &#125; return instance; &#125; public static void main(String[] args) &#123; SingletonObject.get(); &#125;&#125; 然后用idea运行main方法并打印汇编代码，jvm参数：-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly-XX:CompileCommand=compileonly,*SingletonObject.get (只打印SingletonObject的get方法) 运行打印结果： 1234567891011121314# &#123;method&#125; &#123;0x0000000128e022b0&#125; &#39;get&#39; &#39;()Lcom&#x2F;test&#x2F;SingletonObject;&#39; in &#39;com&#x2F;test&#x2F;SingletonObject&#39;# [sp+0x40] (sp of caller) 省略代码..... 0x000000010af1fb54: movb $0x0,(%rax,%rsi,1) 0x000000011b6f4e58: lock addl $0x0,(%rsp) ;*putstatic instance ; - com.test.SingletonObject::get@13 (line 12) 省略代码..... 0x000000010af1f701: mov %r12b,(%r11,%r10,1) 0x000000011b6f4a05: lock addl $0x0,(%rsp) ;*putstatic instance ; - com.test.SingletonObject::get@13 (line 12) 省略代码..... 我们可以看到被volatile修饰的共享变量进行写操作的时候，会比普通公共变量的读写操作多一行lock addl $0x0,(%rsp)前缀的代码，lock前缀指令有俩个作用： 使用总线锁或缓存一致性协议来保证数据的可见性。 不是内存屏障却能完成类似内存屏障的功能，阻止屏障两遍的指令重排序保证有序性。 总结volatile的使用场景不是很多，常用在多线程下的状态标记量和双重检查等，也有很多地方配合CAS来实现无锁编程。因为volatile只能保证线程每次拿到的数据是最新的，对于数据的单纯查询没有任何问题(jvm自动保证基本数据类型和引用的取值赋值为原子操作)，但是对于i++、懒汉式单例模式等对变量操作依赖当前值的情况，就显得无能为力。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(三) 生命周期和常用方法","slug":"多线程生命周期和常用方法","date":"2020-03-03T05:00:00.000Z","updated":"2020-11-03T01:42:03.748Z","comments":true,"path":"2020/03/03/多线程生命周期和常用方法/","link":"","permalink":"http://yoursite.com/2020/03/03/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%92%8C%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"线程状态以及转化NEW(新建) 使用new创建出线程后，进入新建状态 此时jvm为其分配内存以及其成员变量 除此之外没有任何特征，方法也不会被执行 RUNNABLE(就绪) 调用对象的start()方法，进入就绪状态 此时jvm会为其创建方法调用栈和程序计数器 线程拥有被CPU调度资格，开始疯狂争夺使用权 RUNNING(运行) 抢到CPU使用权时，开始执行run()方法，进入运行状态 线程只有通过start()后争夺到CPU时间片的方式运行run()方法，才可以实现异步执行 如果直接调用run()方法运行，系统会当作普通方法，不会异步执行 BLOCKED(阻塞) 处于运行状态的线程在进入synchronized关键字修饰的方法或代码块时，进入阻塞状态 阻塞的过程就是线程在抢夺锁的过程，因此阻塞是被动的 阻塞在某个锁上的线程，在锁被释放后会主动去争取，争取到锁后回到运行状态，因此脱离阻塞状态是主动的 WAITING(等待) 调用wait()、join()方法时，进入等待状态 因此进入等待状态是主动的，需要有事件主动唤醒 TIMED_WAITING(等待) 调用sleep(long)、wait(long)、join(long)方法时，进入超时等待状态 同等待状态，到达参数指定时间自动唤醒 TERMINATED(终止) run()方法或call()方法运行完毕，线程正常结束 线程执行代码过程中抛出未捕获异常或直接ERROR 调用stop()方法，也是个奇葩的方法，不推荐使用 附加状态转化图： 类型转化。 isAlive()1public final native boolean isAlive(); 判断当前线程是否活着，只有当线程进入RUNNABLE(就绪)或RUNNING(运行)状态才返回true。 sleep(long millis)1public static native void sleep(long millis) throws InterruptedException; Thread的静态方法，使当前线程放弃CPU时间片，在指定时间内不参与CPU竞争，在到达指定时间后变为runnable状态并重新加入CPU竞争。如果当前线程持有锁，在睡眠过程中不会放弃锁的占有权 join(long millis)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#x2F;&#x2F; 无参方法，调用重载方法传入固定参数0public final void join() throws InterruptedException &#123; join(0);&#125;&#x2F;&#x2F; 支持超时的join方法public final synchronized void join(long millis) throws InterruptedException &#123; &#x2F;&#x2F; 获取当前时间戳 long base &#x3D; System.currentTimeMillis(); &#x2F;&#x2F; 记录已经延迟多久 long now &#x3D; 0; &#x2F;&#x2F; 参数校验，不能小于0 if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; &#x2F;&#x2F; 没有超时限制情况下 if (millis &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 线程只有处于活着状态才进行处理 while (isAlive()) &#123; &#x2F;&#x2F; 这里意味着调用此方法的线程直接被wait方法挂起，没有提供任何notify方法唤醒，只能被动的等待线程运行完毕后死亡 wait(0); &#125; &#125; else &#123; &#x2F;&#x2F; 线程只有处于活着状态才进行处理 while (isAlive()) &#123; &#x2F;&#x2F; 还需要延迟多久 long delay &#x3D; millis - now; &#x2F;&#x2F; 如果已达到延迟时间限制，跳出循环 if (delay &lt;&#x3D; 0) &#123; break; &#125; &#x2F;&#x2F; 挂起进入等待状态 wait(delay); &#x2F;&#x2F; 执行到这里说明等待时间已到，重新计算已经延迟多久了，等待下一次进入while循环调用break now &#x3D; System.currentTimeMillis() - base; &#125; &#125;&#125; 源码可以看出来join是用的wait()实现的，wait方法是object的方法，作用是让调用这个Object.wait()的线程处于等待状态，除非其他线程调用这个Object.notify()唤醒，或者这个Object死亡阻塞状态才会变成可运行状态，如果join方法带参数，那就等到参数时间结束自动唤醒自己。 如果在一个线程执行中创建另外一个线程并使用join()，那么主线程会被挂起，等待子线程执行完在继续往下执行。说白了和执行过程中调用另一个方法没什么区别，无非就是有个超时时间限制，超过时间限制主线程就取消等待继续执行。使用isAlive()进行判断，也就意味着线程如果没有进入RUNNABLE(就绪)或RUNNING(运行)状态，join方法不会起任何作用。 join其实合理理解成是线程合并，当在一个线程调用另一个线程的join方法时，当前线程阻塞等待被调用join方法的线程执行完毕才能继续执行，所以join的好处能够保证线程的执行顺序，但是如果调用线程的join方法其实已经失去了并行的意义，虽然存在多个线程，但是本质上还是串行的，最后join的实现其实是基于等待通知机制(wait+notify)的。 yield()1public static native void yield(); Thread的静态方法，暂停当前正在执行的线程对象，并执行其他线程。被暂停的线程会让出CPU的使用权给其他线程获得运行机会，自身转化为RUNNABLE(就绪)状态，但是这么做并不一定能达到让出CPU资源的目的，因为让出CPU使用权的时候，自身回到可运行状态与其他同优先级线程一起再去竞争CPU时间片，如果这个线程是个欧皇还会被再次选中，出现这种情况也就意味着此次yield()方法并没有任何效果。 目前想不到什么应用场景，如果一个线程的优先级特别低，执行内容也不是很重要，又怕他被CPU调度的次数多，可以适当的调用此方法减少执行的次数，把CPU资源给其他重要的线程工作。 interrupt()1234567891011121314151617public void interrupt() &#123; &#x2F;&#x2F;如果调用中断的是线程自身，则不需要进行安全性判断 if (this !&#x3D; Thread.currentThread()) checkAccess(); &#x2F;&#x2F; synchronized (blockerLock) &#123; Interruptible b &#x3D; blocker; if (b !&#x3D; null) &#123; interrupt0(); &#x2F;&#x2F; 只是设置中断标志 b.interrupt(this); return; &#125; &#125; interrupt0();&#125; 每个线程内部都维护了一个中断标志(默认false)，调用线程的interrupt()方法时会根据当前线程的中断标志和阻塞情况，判断是否需要抛出异常： 如果中断标志为false，且没有被阻塞，修改中断标志为true。 如果中断标志为true，此时调用wait、sleep、join方法时会抛出InterruptedException异常，恢复中断标志为false。 如果已经被wait、sleep、join方法阻塞，调用interrupt()会抛出InterruptedException异常，恢复中断标志为false。 这里提到的阻塞，只是因为wait、sleep、join方法导致线程被堵住无法继续执行，并不是线程七大状态的BLOCKED(阻塞)状态。BLOCKED(阻塞)状态只由synchronized导致，而且不能被打断，相同的，IO阻塞也不能被打断。 由此可以看出来interrupt()方法中断的不是线程的运行，而是中断线程的阻塞状态，并且采用抛异常的方式引起线程的注意，被中断线程可以通过try catch方式自己决定如何应对中断信号。 比如使用kafka采用while(true)的方式消费数据时，又希望在某个时刻终止这个线程，并且终止过程中要保证此刻正在处理的那条消息处理完毕后才能终止，可以采用interrupt()方法+wait、sleep、join的一种来实现： 1234567891011121314151617181920212223242526272829303132public void run()&#123; &#x2F;&#x2F; 创建消费者 Properties props &#x3D; createProperties(&quot;localhost:9092&quot;, &quot;groups&quot;); props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;); KafkaConsumer&lt;String, String&gt; consumer &#x3D; new KafkaConsumer&lt;&gt;(props); &#x2F;&#x2F; 设置消费topic consumer.subscribe(Arrays.asList(&quot;topic-name&quot;)); while (true) &#123; &#x2F;&#x2F; 每次拉取消息 ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(100); &#x2F;&#x2F; 循环处理 for (ConsumerRecord&lt;String, String&gt; record : records) &#123; &#x2F;&#x2F; 消费逻辑.. &#x2F;&#x2F; wait或sleep或join阻塞1毫秒，试探线程有没有被中断 try &#123; Thread.wait(1); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; 关闭消费者对象 consumer.close(); return; &#125; &#125; &#125;&#125; stop()强制终止线程的运行，并立即释放掉此线程持有的锁，这些锁可能用来维护数据一致性的，所以此方法被废弃。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(二) 并发编程三大特性","slug":"并发编程三大特性","date":"2020-03-02T05:00:00.000Z","updated":"2020-11-28T09:12:35.949Z","comments":true,"path":"2020/03/02/并发编程三大特性/","link":"","permalink":"http://yoursite.com/2020/03/02/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7/","excerpt":"","text":"可见性可见性是指一个线程对共享变量的修改，其他线程可以立即感知到这个变化 计算机中程序的执行，本质上是线程指令在CPU处理器上的执行，并且在执行必然牵涉到数据的读和写，程序运行过程的临时数据都是存放在主内存(RAM)中，因此CPU在处理数据的时候也必然牵涉到和主内存的交互。处理器访问内存时，需要先获取内存总线的控制权，任何时刻只能有一个处理器获得内存总线的控制权，可以理解为同一时刻某个内存地址只可能被一个处理器访问。 随着硬件技术的不断发展，现在的CPU处理速度已经远远超过主内存的访问速度，如果任何时候对数据的操作都要和内存进行交互，会大大降低指令的执行速度，因此就有了CPU高速缓存： 高速缓存的产生大大减少了CPU直接访问主内存的频率，也减少了内存访问速度对CPU的拖累，提高了CPU的执行效率。如果是单核CPU的操作系统中，只有一个高速缓存，没有任何问题。但是多核CPU的诞生打破了这个规则，处理器对数据的修改在没有做任何措施的情况下，不会及时通知到其他处理器的缓存，这就导致其他处理器的数据是脏数据。 比如i++操作，编译成指令后大概有三步骤： 将i=0从主内存复制到 对i进行加1运算 将运算后的值刷回主内存 假设俩个线程对公共变量i=0执行i++操作，我们期望俩个线程都执行完毕后i的值变为2，由于操作系统配置是多核CPU，俩个线程分别在不同的CPU上并行执行，用时间线流程图模拟执行效果: 图中可以看出CPU-1计算完毕后还没来得及将数据i刷回主内存，另一个CPU就去主内存获取i值并且到的是脏数据，这导致i最终值并不是我们期望的结果。对此问题，早期的解决方案是总线加锁，一个处理器在总线上输出LOCK#信号，使得其他处理器对内存的操作请求都会被阻塞，该处理器独占共享内存。方法简单粗暴，就是锁定范围太大(整个共享内存)，导致CPU利用率急剧下降。 CPU如何保证可见性？为了解决总线锁开销过大问题，CPU提出了缓存一致性解决方案，主要有Directory协议、Snoopy协议、MESI协议。这个说下MESI协议，这个协议只会对高速缓存中的某个数据加锁(如果数据不在缓存中，还是会总线加锁)，不会影响到内存中其他数据的读写。MESI协议将数据划分为四种状态，通过总线嗅探机制让所有处理器监听数据状态的变化，达到缓存一致的目的: 我们重点关注一下修改缓存数据的情况，对于E状态的数据，只有自己在读，可以直接把数据设置为M状态，对于S状态的数据，说明有多个处理器在读，必须将其他处理器对此数据的缓存作废，然后才能把数据的状态设置为M。当其他处理器发现自己的缓存是I状态时，就去主内存再次读取，而MESI协议保证其他处理器去主内存读取此数据前，将修改后的数据从高速缓存刷回主内存，并把数据状态改为E。 高并发情况下可能出现俩个处理器同时修改变量，并同时向总线发出将各自的缓存行更改为M状态的情况，此时总线会采取裁决机制进行裁决，将其中一个置为M状态，另一个置为I状态，且I状态的缓存行修改无效。 Java自带的可见性操作： volatile关键字(采用MESI协议保证，如果数据不在缓存中就用总线锁) synchronized关键字(同一时刻就一个线程操作，还有啥不可见的) Lock相关类(跟synchronized一个套路) 原子性原子性操作是指一个或多个操作，要么全部执行且在执行过程中不被任何因素打断，要么全部不执行。并且针对某个值的原子操作在被执行的过程中，CPU绝不会再去进行其他的针对该值的操作 java作为一门高级语言，一个可执行线程会被编译成多条指令序列交由CPU执行，既然是多条指令，在执行过程中就存在被上下文切换打断的可能。在多线程编程中如果有的操作不具有原子性，同样会导致运行结果与预期的不一致，比如i++操作： 同样的i++操作，可见性与原子性对线程安全强调的角度却不一样，可见性强调线程在修改完数据后未及时从缓存刷新到主内存，导致另一个线程获取脏数据，继而影响到最终计算结果，而原子性强调非原子操作在执行过程中被上下文打断，在未切回期间另一个线程对数据i进行了递增操作，导致数据最终出现错误。 CPU如何保证原子性？首先，处理器自动保证单条指令、基本内存操作的原子性，因此中断只会发生在指令之间。在单核CPU中保证操作原子性非常简单，只要禁止CPU在原子操作过程中发生上下文切换，那么就可以保证多线程对某个公共变量的多步骤操作都是串行的。嗯，有点线程安全的味道了。到了多核CPU时代，仅仅保证原子操作的执行不被CPU打断已经没什么卵用了，因为多个线程可以并行执行修改一个公共变量，线程之间又出现了干扰。对此，CPU又提出了CAS来解决这个问题(CAS下一章会讲)。 Java自带的原子性操作： 基本数据类型的赋值(long、double无法保证) 所有引用类型的赋值 synchronized关键字(采用jvm的monitor，monitor底层采用CPU的CAS) Lock相关类(采用aqs，aqs底层采用CPU的CAS) java.concurrent.Atomic包下所有类(采用CPU的CAS) 注:CPU和Java(内存读写)的原子性与数据库的原子性还是有区别的，CPU和Java(内存读写)执行原子操作过程中发生中断的唯一可能就是断电，这时候所有内存数据全部消失，也就没讨论的意义了。而数据库的增删改操作涉及的都是持久化的磁盘数据，就算执行过程发生断电，持久化的数据仍然存在，因此数据库的原子操作增加了事务回滚概念，只要事务没提交，就相当于没执行。无论CPU还是Java还是数据库，都是强调整体的成败，不允许仅执行部分操作的存在。 有序性有序性是指程序按照写代码的顺序执行 处理器和编译器为了提高程序运行效率，可能会对输入代码进行优化，并且不保证程序中各个语句的执行先后顺序同代码中的顺序一致。当然，CPU和编译器是在遵循as-if-serial语意的前提下对指令重排，而不是随意重排。首先CPU保证调度线程过程中，单线程的执行结果不会受指令重排影响导致结果不一致，编译器保证编译过程中不会对有依赖关系的数据进行指令重排。由此看出多线程情况下还是会有问题： CPU如何保证有序性？处理器主要通过内存屏障机制来解决有序性问题，如果不想让它重排，在两条指令中间加一道屏障。拿X86平台来说，有几种主要的内存屏障： lfence，是一种Load Barrier(读屏障)，在lfence指令前的所有读操作当必须在lfence指令后的所有读操作前完成 sfence, 是一种Store Barrier(写屏障)，在sfence指令前的所有写操作当必须在sfence指令后的所有写操作前完成 mfence, 是一种General Barrier(通用屏障)，在mfence指令前的所有读写操作当必须在mfence指令后的所有读写操作前完成 除了内存屏障，也可以使用原子指令，如x86上的”lock…”前缀 Java自带的有序性操作： volatile关键字(内存屏障) synchronized关键字(单线程操作，as-if-serial语意自动保证) Lock相关类(单线程操作，as-if-serial语意自动保证) 总结原子性、可见性、有序性问题是一切线程安全问题的根源，单纯的保证操作具有某一种特性只能解决某一部分场景问题。Java提供了很多类以及修饰符，提供了不同维度的保证，底层也都是封装CPU提供的措施来实现。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(一) 基本概念","slug":"多线程基本概念","date":"2020-03-01T05:00:00.000Z","updated":"2020-11-28T09:15:11.902Z","comments":true,"path":"2020/03/01/多线程基本概念/","link":"","permalink":"http://yoursite.com/2020/03/01/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","excerpt":"","text":"进程操作系统进行资源分配和调度的基本单位，每一个进程都是一个应用程序的执行实例，比如我们启动的一个java项目就是一个jvm进程，操作系统为jvm分配运行内存等资源，进程中包含一个或多个线程，线程之间共享进程的资源(比如堆、栈、方法区等)。 线程CPU运行的最小单位，线程之间共享进程的资源，也有自己的私有空间，比如虚拟机栈、本地方法栈、程序计数器。 进程上下文切换线程上下文切换CPU通过分配时间片来执行任务，当一个任务的时间片用完，就会切换到另一个任务。在切换之前会保存上一个任务的状态，当下次再切换到该任务，就会加载这个状态，任务从保存到再加载的过程就是一次上下文切换。 切出：一个线程被剥夺处理器的使用权而被暂停运行 切入：一个线程被系统选中占用处理器开始或继续运行 线程的上下文是什么？对于CPU来说一个线程就是多条指令集合，线程的运行实质上是多条指令在CPU上的运行，而上下文是指线程私有空间的内容。比如虚拟机栈、本地方法栈保存了某一时刻线程局部变量的值，程序计数器保存了线程此刻执行到哪一条指令的位置。 导致上下文切换的原因？ CPU分配的时间片用完了 有个优先级更高的线程需要被执行 手动操作比如java线程的sleep、yield、wait、join、synchronized、lock等 读取数据库操作由于数据量较大引起IO阻塞,线程会被挂起直到读取完毕再次回归等待被CPU调度 上下文切换的过程？放发生切换的时候，CPU会把被挂起线程的上下文保存在程序计数器和寄存器中，程序计数器存储正在执行的指令序列的位置、寄存器存储工作变量，然后从高速缓存中清除掉被挂起线程的上下文，去加载新线程的上下文到高速缓存中。因此线程上下文的切换需要消耗CPU的资源。 并发与并行单CPU操作系统中多个线程同时运行，实质上是交替占有CPU使用权的过程，同时运行只是CPU处理过快造成的错觉，这种现象可以称作为线程并发运行。 到了多CPU时代才实现真正意义上的多线程同时运行，比如4颗CPU的操作系统可以做到4个线程的同时运行，但是操作系统中可能有很多线程需要被执行，比如有16个线程在运行，那么平均4个线程仍然要争夺一个CPU的使用权，只是同一时刻必然有4个争夺到使用权，这种现象称作为线程并行运行。 由此可以看出，操作系统中CPU的数量对多线程编程非常重要。因此项目开发中要尽量参考所在服务器的CPU配置，作出适当的线程池参数以避免频繁的上下文切换带来的性能损耗。同样在选取机器配置上尽量考虑放置服务的线程特点，比如存放redis服务选用多处理器的CPU没有任何意义，redis永远只在一个处理器上面运行。 线程安全在开发中使用过线程都知道，多线程编程需要面对线程安全问题，而线程安全问题归根结底就三个方面:可见性、原子性、有序性，下一章节会详细讲解这些问题。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"IO流(一) 字节流","slug":"字节流","date":"2020-02-01T05:00:00.000Z","updated":"2020-10-19T08:22:23.656Z","comments":true,"path":"2020/02/01/字节流/","link":"","permalink":"http://yoursite.com/2020/02/01/%E5%AD%97%E8%8A%82%E6%B5%81/","excerpt":"","text":"啊锁啊锁大","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"IO流","slug":"java基础/IO流","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/IO%E6%B5%81/"}],"tags":[]},{"title":"集合(一) HashMap","slug":"HashMap","date":"2020-01-01T05:00:00.000Z","updated":"2020-11-10T09:21:41.628Z","comments":true,"path":"2020/01/01/HashMap/","link":"","permalink":"http://yoursite.com/2020/01/01/HashMap/","excerpt":"","text":"啊锁啊锁大","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"数据结构","slug":"java基础/数据结构","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[]}],"categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"},{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"IO流","slug":"java基础/IO流","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/IO%E6%B5%81/"},{"name":"数据结构","slug":"java基础/数据结构","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]}