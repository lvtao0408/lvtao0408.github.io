{"meta":{"title":"来杯冰镇可乐","subtitle":"","description":"","author":"lvtao","url":"http://yoursite.com","root":"/"},"pages":[{"title":"所有分类","date":"2020-09-29T01:49:01.545Z","updated":"2020-04-12T05:48:42.451Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis(十二) lua脚本","slug":"Redis-lua脚本","date":"2021-03-04T08:00:00.000Z","updated":"2021-07-22T01:42:17.333Z","comments":true,"path":"2021/03/04/Redis-lua脚本/","link":"","permalink":"http://yoursite.com/2021/03/04/Redis-lua%E8%84%9A%E6%9C%AC/","excerpt":"","text":"","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(十一) 布隆过滤器","slug":"Redis-布隆过滤器","date":"2021-02-20T08:00:00.000Z","updated":"2021-07-26T08:44:21.260Z","comments":true,"path":"2021/02/20/Redis-布隆过滤器/","link":"","permalink":"http://yoursite.com/2021/02/20/Redis-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","excerpt":"","text":"1.概述布隆过滤器由二进制向量(位数组)和一系列随机映射函数组成，用于快速定位某个元素是否存在。如果你需要判断的元素都是数字，那么Redis提供的BitMap结构完全可以胜任，但很多场景我们需要对字符串进行判断，这就必须运用随机映射(哈希)函数将字符串转化为数字放入BitMap中，考虑到哈希值碰撞的情况，就需要多个随机映射函数来减少误判率。 2.二进制向量BitMap也称为位图，实质上是一个二进制形式的字节数组，由0和1俩个数组构成，如图所示: 现在往创建的BitMap中添加7、15、24三个数字，看看bit结构的变化: BitMap添加、查询元素的本质是对二进制数组的位与运算，并且这种结构并不直接存储元素本身，而是以偏移量的形式记录，每个元素在BitMap中仅占有一个bit空间(1亿个bit也仅占有12MB内存空间)。 3.基本原理如果存储的元素为字符串或者复杂对象，那么BitMap是无法通过一个bit表示的，这时候需要随机散列函数转化为数字，假设某个布隆过滤器有三个哈希函数，然后往该布隆过滤器中添加张三、李四俩个字符串: 图中可以看出布隆过滤器并没有存储元素本身，只是记录对应的多个随机映射函数值，这样大大节省了存储空间。在判断某个元素是否存在时，会将计算出该元素的所有随机映射函数值，如果返回不存在，那么元素必定是不存在的。 另外图中也能看出随机映射函数的数量、BitMap的容量，直接影响到随机散列函数值碰撞的几率，也就是我们最关心的误判几率。在判断某个元素是否存在时，如果返回存在，有可能真的存在，也可能只是随机散列函数值发生碰撞造成的假象，实际元素是不存在的。 4.Redisson实现RedisTemplate客户端实现布隆过滤器比较麻烦，需要借助google的guava框架提供的功能，然后实现对BitMap的操作达到布隆过滤器的效果。而Redisson客户端对布隆过滤器进行了封装，可以直接调用API。 创建一个普通的布隆过滤器: 1234567891011// 创建对象RBloomFilter&lt;SomeObject&gt; bloomFilter = redisson.getBloomFilter(&quot;sample&quot;);// 初始化布隆过滤器，预计统计元素数量为55000000，期望误差率为0.03(误差率必须小于1大于0，否则报错)bloomFilter.tryInit(55000000L,0.03);bloomFilter.add(newSomeObject(&quot;field1Value&quot;,&quot;field2Value&quot;));bloomFilter.add(newSomeObject(&quot;field5Value&quot;,&quot;field8Value&quot;));// 判断元素是否存在bloomFilter.contains(newSomeObject(&quot;field1Value&quot;,&quot;field8Value&quot;)); 创建一个分布式布隆过滤器: 1234567891011// 创建分布式对象RClusteredBloomFilter&lt;SomeObject&gt; bloomFilter = redisson.getClusteredBloomFilter(&quot;sample&quot;);// 初始化布隆过滤器，预计统计元素数量为255000000，期望误差率为0.03bloomFilter.tryInit(255000000L,0.03);bloomFilter.add(newSomeObject(&quot;field1Value&quot;,&quot;field2Value&quot;));bloomFilter.add(newSomeObject(&quot;field5Value&quot;,&quot;field8Value&quot;));// 判断元素是否存在bloomFilter.contains(newSomeObject(&quot;field1Value&quot;,&quot;field8Value&quot;)); 注: Redisson客户端创建的布隆过滤器，不支持删除元素操作。 5.删除元素布隆过滤器在初始化时，期望误差率是无法设置为0的，也就是说无论怎么设置都会出现哈希碰撞，这就导致了元素无法删除，因为你不能确定某个bit位到底被几个元素映射，也就无法删除某个元素映射的bit值。 第一个解决方案是定时重构BitMap结构，首先无论怎么设置都会出现哈希碰撞，因此必然会考虑到误判的处理逻辑，元素在删除后重构前这段时间被查询时，可以直接按误判处理。这种方案适合数据量不高、修改频率小的场景。 第二种方案是参考guava的设计，为BitMap结构中的每个bit设置一个计数器，添加元素后映射的位置计数+1，删除元素时计数-1，计数减少到0时将bit位的值设置为0，达到删除元素的效果。这种方案相对定时重构要灵活很多，并且在大数据量的情况下同步数据也不会占用多少CPU，缺点是占用空间过多，并且Redisson客户端没有支持这种功能，需要手动去实现(用到这种场景在更新)。","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(九) 事务机制","slug":"Redis-事务机制","date":"2021-02-10T08:00:00.000Z","updated":"2021-07-01T00:31:49.228Z","comments":true,"path":"2021/02/10/Redis-事务机制/","link":"","permalink":"http://yoursite.com/2021/02/10/Redis-%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6/","excerpt":"","text":"1.概述Redis的事务的本质是将一组命令进行打包，然后按照顺序执行命令，并且执行过程不会被其他客户端发送的命令打断插入，执行过程中若出现失败的命令也不会导致事务终止，而是跳过并执行下一条命令。 2.执行过程事务相关命令: MULTI: 开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。 EXEC: 执行事务中的所有操作命令。 DISCARD: 取消事务，放弃执行事务块中的所有命令。 WATCH: 监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。 UNWATCH: 取消WATCH对所有key的监视。 Redis事务提供的watch监控，必须在事务开启前执行。这个很容易理解，因为事务一旦开始执行就不会被上下文切换打断，那么执行期间也不可能执行其他命令，也就没有监控的意义。另外考虑到并发问题，事务在执行命令队列前会通过CAS进行检查，一旦发现修改记录，会阻止命令队列的执行。最后watch的监控是一次性的，无论执行是否成功，都会释放监控。 3.客户端命令RedisTemplate默认不支持事务操作，并且每次执行命令都会从连接池获取资源，使用完毕后归还。如果开启事务需要将enableTransactionSupport属性设置为true，这种情况下会将连接池获取的资源绑定到当前线程，直到事务提交后归还，以减少频繁的获取资源带来的消耗。 1template.setEnableTransactionSupport(true); // 开启事务支持 如果在@Transactional修饰的方法中使用Redis事务，Spring会自动帮我们开启、提交/回滚事务，在没有被@Transactional修饰的方法中，就需要手动调用API控制事务。 1234567891011121314151617181920// 监控，一定要在事务开启前执行，不然会报错！redisTemplate.watch(&quot;testKey3&quot;);// 开启事务template..multi();// 执行命令redisTemplate.opsForValue().set(&quot;testKey1&quot;, &quot;abc&quot;);redisTemplate.opsForValue().increment(&quot;testKey2&quot;);// 提交事务List&lt;Object&gt; execResultList = template.exec();// 如果集合为空，说明watch监控的key被修改过if(execResultList.isEmpty())&#123; // 逻辑处理...&#125;else&#123; // 逻辑处理...&#125; 4.与关系型数据库事务的区别4.1 原子性原子性是指一个事务内的SQL或命令集是不可分割的，要么都执行要么都不执行。关系型数据库以Mysql为例，事务内的多条SQL执行会先写入redolog中，直到事务提交才会执行磁盘IO进行持久化，如果执行过程中断电、异常、手动回滚事务则不会将SQL的执行效果刷回磁盘，达到要么都执行要么都不执行的效果。 Redis的事务原子性属于弱原子性，我们都知道Redis执行命令是单线程执行，Redis仅仅保证某个事务的命令集执行过程中不会被CPU的上下文切换打断，并且不支持异常回滚，出现异常的命令会跳过继续往下执行。所以说Redis事务不是严格意义上的原子性，因为达不到要么都执行，要么都不执行的效果。 在原子性这方面Redis也增加一些机制减少命令执行错误带来的影响，比如命令总是发送到服务端的命令池里，这样服务端就可以对命令进行一些名称、格式之类的校验，以减少事务执行过程中的异常几率，如果在测试环境前做了充足的测试，出现命令异常的可能性很小，在这种理论前提下，Redis的原子性与关系型数据库也不会有太大差距，但是断电的情况就无法做任何保证。 4.2 一致性关系型数据库的一致性是事务执行成功后，涉及到的数据从一个一致状态转移到另一个一致状态，但完整性约束没有被破坏，比如经典的转账，先扣钱A账户的钱，在添加B账号的钱，在事务执行完毕后两者的钱总合不应该发生变化(不考虑扣手续费情况)，这就是完整性约束，关系型数据的一致性是由其他三大特性和应用程序来保证的，而Redis并不满足原子性和持久性，所以一致性也无法保证。 4.3 隔离性这个没啥好说的，Redis以单线程模式处理所有命令，并且执行过程中不会被上下文切换打断，因此Redis的事务总是串行化执行，不存在隔离性这种问题。 4.4 持久性关系型数据库每次事务提交后就会进行持久化，Redis的持久化并不与事务的提交挂钩，因此Redis的事务是没有持久化这个特性的。 5.为什么不支持异常回滚?通常我们应用程序都是通过各种客户端连接Redis服务，执行命令也都是调用API，最终客户端帮我们生成命令并发送，不会出现语法错误，其次客户端在真正执行事务前也会对命令进行校验，比如对某个HashMap类型的key使用了add，或者对value非数字的String类型key，使用了increment命令，这些服务端都会检测出来并拒绝执行，另外还有watch来提高事务的原子性。再加上开发过程中的测试，几乎不会存在命令执行异常的情况。 对于事务执行过程中出现宕机、断电情况，也不是没法保证，只是这种保证会让整个Redis的设计更加复杂，命令的处理效率变低，而Redis设计的首要目的是让程序快速运行，事务操作会让整个服务阻塞点增多，降低命令处理的吞吐量，为了这种小概率发生的场景提高设计复杂度和性能，似乎不划算。","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(八) 管道机制","slug":"Redis-管道机制","date":"2021-02-07T08:00:00.000Z","updated":"2021-06-17T03:41:57.987Z","comments":true,"path":"2021/02/07/Redis-管道机制/","link":"","permalink":"http://yoursite.com/2021/02/07/Redis-%E7%AE%A1%E9%81%93%E6%9C%BA%E5%88%B6/","excerpt":"","text":"1.工作原理在使用Redis客户端发送请求命令时，每条命令都会与Redis服务端进行一次socket通信，那么每次请求的耗时等于服务端处理时间+网络传输时间(三次握手、四次挥手)。服务端的操作都是在内存中进行，不会耗费太多的时间，因此一个请求的耗时很大程度取决于网络开销。管道技术就是为了批量操作场景下，通过减少服务端与客户端的通信次数，减少请求耗时的一种优化。 图中可以看出pipeline就是为了批量操作而设计的，三条命令使用管道没什么直观效果，但随着命令数量的增加或网络延迟变高，管道操作的优势会越来越明显。 2.客户端命令对于服务端来说就没有pipeline相关概念，这完全属于客户端支持的功能，服务端无法区分请求是否为pipeline请求，只是支持一次通信多条命令的的接收，最终还是单条执行完后汇总返回。另外pipeline请求会独占链接，期间不能进行非pipeline请求，因此使用pipeline需要单独分配连接对象。 客户端代码: 123456789101112List&lt;Long&gt; List = redisTemplate.executePipelined(new RedisCallback&lt;Long&gt;() &#123; @Nullable @Override public Long doInRedis(RedisConnection connection) throws DataAccessException &#123; connection.openPipeline(); for (int i = 0; i &lt; 1000000; i++) &#123; String key = &quot;PIPLINE_KEY_&quot; + i; connection.zCount(key.getBytes(), 0,Integer.MAX_VALUE); &#125; return null; &#125;&#125;); 3.命令行限制虽然pipeline是为批量操作而设计的，明面上没有任何数量限制，但这并不代表你可以在请求中无限制添加命令，每个socket在操作系统内核中都有一个发送缓冲区和一个接收缓冲区，pipeline命令处理完毕后将数据发送到接收缓冲区一直保存，直到应用程序(客户端)读走为止。如果pipeline命令返回的数据过多导致接收缓冲区存满，根据TCP socket原理会发送信息给服务端告知接收窗口关闭，保证TCP套接口接收缓冲区不会溢出，从而保证了TCP是可靠传输。那么剩余未发送的结果数据会直接丢弃。 注: 官方建议每次pipeline请求不要超过1W条命令 4.适用场景 pipeline请求发送后客户端需同步阻塞等待结果，适用对响应实时性要求不高的场景 pipeline请求不可能保证所有的命令都执行成功，适用那些允许一定比例失败的场景 pipeline请求不能保证多条命令的原子性，适用没有执行关系的命令集场景","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(七) 发布订阅","slug":"Redis-发布订阅","date":"2021-02-06T08:00:00.000Z","updated":"2021-06-16T02:15:56.894Z","comments":true,"path":"2021/02/06/Redis-发布订阅/","link":"","permalink":"http://yoursite.com/2021/02/06/Redis-%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85/","excerpt":"","text":"1.工作原理Redis的发布订阅(pub/sub)是一种消息通信模式，客户端指定某个频道(channel)进行消息的发布和订阅，向channel发送消息的客户端称为发布者(pub)，订阅并接收消息的客户端称为订阅者(sub)。 2.存储结构 图中可看出结构与Java的HashMap类似，并且关系结构中并没有涉及到发布者，可以断定客户端可以通过命令随意向channel发送消息。当消息发送到channel后，会遍历所有订阅此channel的客户端，逐个进行消息的推送。 3.终端命令12345publish [channel] [message] &#x2F;&#x2F; 向某个频道发布消息subscribe [channel-0] [channel-1] &#x2F;&#x2F; 订阅一个或多个频道消息unsubscribe [channel] &#x2F;&#x2F; 退订某频道消息 4.客户端命令4.1 发布消息RedisTemplate客户端提供了发布消息的API: 1redisTemplate.convertAndSend(&quot;频道名称&quot;, &quot;消息Object&quot;); 4.2 接受消息关于订阅的配置类: 1234567891011121314151617181920212223242526272829303132333435@Configurationpublic class RedisConfig&#123; /** * Redis消息监听器容器 * 这个容器加载了RedisConnectionFactory和消息监听器 * 可以添加多个监听不同话题的redis监听器，只需要把消息监听器和相应的消息订阅处理器绑定，该消息监听器 * 通过反射技术调用消息订阅处理器的相关方法进行一些业务处理 * @param connectionFactory 链接工厂 * @param adapter 适配器 * @return redis消息监听容器 */ @Bean public RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory, MessageListenerAdapter adapter) &#123; RedisMessageListenerContainer container = new RedisMessageListenerContainer(); container.setConnectionFactory(connectionFactory); //可以添加多个 messageListener container.addMessageListener(adapter, new PatternTopic(&quot;频道名称1&quot;)); container.addMessageListener(adapter, new PatternTopic(&quot;频道名称2&quot;)); return container; &#125; /** * 消息监听器适配器，绑定消息处理器，利用反射技术调用消息处理器的业务方法 * 将MessageReceiver注册为一个消息监听器，可以自定义消息接收的方法（handleMessage） * 如果不指定消息接收的方法，消息监听器会默认的寻找MessageReceiver中的onMessage这个方法作为消息接收的方法 * @param messageReceiver 消息接受 * @return 适配器 */ @Bean public MessageListenerAdapter adapter(MessageReceiverSupport messageReceiver) &#123; return new MessageListenerAdapter(messageReceiver, &quot;onMessage&quot;); &#125;&#125; 监听类: 123456789101112131415@Component@Slf4jpublic class MessageReceiverSupport implements MessageListener &#123; @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; @Override public void onMessage(Message message, byte[] pattern) &#123; RedisSerializer&lt;String&gt; redisSerializer = redisTemplate.getStringSerializer(); String msg= redisSerializer.deserialize(message.getBody()); System.out.println(&quot;接收到的消息是：&quot;+ msg); log.info(&quot;Received &lt;&quot; + msg + &quot;&gt;&quot;); &#125;&#125; 5.与MQ的区别Redis仅仅提供了最基础的发布订阅功能，无法做到消息的持久化、重试等可靠机制，消息丢失概率较大，不适用消息密集或者可靠性要求很高的场景，甚至说有些鸡肋。另外各种MQ提供的负载均衡、消费模式、消息延迟、消息过滤、事务等可以满足各种复杂的业务场景，也是Redis无法实现的。 最后Redis的发布订阅完全基于内存操作，不过目前流行的MQ都会尽可能的将磁盘IO进行顺序读写，性能不会拉开太多差距，另外还可以通过增加队列来均摊压力，不考虑运维成本的情况下，性能也是优于Redis的。总体上说Redis发布订阅可以满足的场景，各种MQ都可以满足，因此在已经有MQ中间件的前提下，尽量不要考虑Redis的发布订阅。 6.应用场景Redis内部的哨兵集群模式在相互监控的时候使用了此功能进行通信。","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(六) RedisTemplate客户端","slug":"Redis-RedisTemplate客户端","date":"2021-02-05T10:00:00.000Z","updated":"2021-07-01T06:35:28.356Z","comments":true,"path":"2021/02/05/Redis-RedisTemplate客户端/","link":"","permalink":"http://yoursite.com/2021/02/05/Redis-RedisTemplate%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"前言RedisTemplate客户端是spring对底层依赖Jedis、Lettuce的高度封装，在Springboot1.X版本默认使用Jedis进行自动装配，在Springboot2.X版本默认使用Lettuce进行自动装配。 1.依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 2.序列化2.1 序列化对象RedisTemplate客户端在存取数据时，并不需要像Jedis、Lettuce那样通过硬代码手动序列化(比如json、java serialization等)，spring提供了多种序列化对象，然后通过代码配置的方式制定序列化器: GenericToStringSerializer(可以将任何对象泛化为字符串并序列化) JacksonJsonRedisSerializer(序列化object对象为json字符串) Jackson2JsonRedisSerializer(和JacksonJsonRedisSerializer一样) JdkSerializationRedisSerializer(序列化java对象，需要实现Serializable接口) StringRedisSerializer(简单的字符串序列化) 2.2 性能对比JdkSerializationRedisSerializer属于JDK原生序列化对象，效率自然是最快的，缺点是序列化后的结果字符串最长，也就意味着占用内存相对多点。Jackson2JsonRedisSerializer是将数据转化为json字符串，需要解析结构因此最慢，但生成的字符串结果较为紧凑。 3.配置文件由于Redis依赖基于springboot的自动装配，所以只需要配置文件参数即可。 3.1 单机版12345678910111213141516171819202122# redis数据库索引spring.redis.database&#x3D;0# redis服务器IPspring.redis.host&#x3D;127.0.0.1# redis服务器端口spring.redis.port&#x3D;6379# redis服务器密码spring.redis.password&#x3D;abcdef#连接池最大连接数（使用负值表示没有限制）jedis.pool.max-active&#x3D;8# 连接池最大阻塞等待时间（使用负值表示没有限制）jedis.pool.max-wait&#x3D;-1# 连接池中的最大空闲连接jedis.pool.max-idle&#x3D;8# 连接池中的最小空闲连接jedis.pool.min-idle&#x3D;8# 连接超时时间（毫秒）jedis.pool.timeout&#x3D;10000 3.2 主从版12345678910111213141516171819202122# redis数据库索引spring.redis.database&#x3D;0# redis服务器IPspring.redis.host&#x3D;127.0.0.1# redis服务器端口spring.redis.port&#x3D;6379# redis服务器密码spring.redis.password&#x3D;abcdef#连接池最大连接数（使用负值表示没有限制）jedis.pool.max-active&#x3D;8# 连接池最大阻塞等待时间（使用负值表示没有限制）jedis.pool.max-wait&#x3D;-1# 连接池中的最大空闲连接jedis.pool.max-idle&#x3D;8# 连接池中的最小空闲连接jedis.pool.min-idle&#x3D;8# 连接超时时间（毫秒）jedis.pool.timeout&#x3D;10000 3.3 哨兵版12345678910111213141516171819202122# redis数据库索引spring.redis.database&#x3D;0# redis服务器IPspring.redis.host&#x3D;127.0.0.1# redis服务器端口spring.redis.port&#x3D;6379# redis服务器密码spring.redis.password&#x3D;abcdef#连接池最大连接数（使用负值表示没有限制）jedis.pool.max-active&#x3D;8# 连接池最大阻塞等待时间（使用负值表示没有限制）jedis.pool.max-wait&#x3D;-1# 连接池中的最大空闲连接jedis.pool.max-idle&#x3D;8# 连接池中的最小空闲连接jedis.pool.min-idle&#x3D;8# 连接超时时间（毫秒）jedis.pool.timeout&#x3D;10000 3.4 集群版12345678910111213141516171819202122# redis数据库索引spring.redis.database&#x3D;0# redis服务器IPspring.redis.host&#x3D;127.0.0.1# redis服务器端口spring.redis.port&#x3D;6379# redis服务器密码spring.redis.password&#x3D;abcdef#连接池最大连接数（使用负值表示没有限制）jedis.pool.max-active&#x3D;8# 连接池最大阻塞等待时间（使用负值表示没有限制）jedis.pool.max-wait&#x3D;-1# 连接池中的最大空闲连接jedis.pool.max-idle&#x3D;8# 连接池中的最小空闲连接jedis.pool.min-idle&#x3D;8# 连接超时时间（毫秒）jedis.pool.timeout&#x3D;10000 4.客户端对象4.1 StringRedisTemplate如果你对redis的操作仅涉及到字符串类型，那么直接使用Spring提供的StringRedisTemplate类即可，此类内部使用StringRedisSerializer序列化，代码方面直接注入: 12@Autowiredpublic StringRedisTemplate stringRedisTemplate; 4.2 自定义RedisTemplate通常的项目中不可能只用Redis来存储字符串，也不可能把所有对象一股脑转成Json字符串存储，因此需要额外注入一个RedisTemplate用于对象的存储，并且可以针对不同的数据结构设置不同的序列化规则，配置如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788@Configurationpublic class RedisConfig &#123; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate(); template.setConnectionFactory(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // key采用String的序列化方式 template.setKeySerializer(stringRedisSerializer); // hash的key也采用String的序列化方式 template.setHashKeySerializer(stringRedisSerializer); // value序列化方式采用jackson template.setValueSerializer(jackson2JsonRedisSerializer); // hash的value序列化方式采用jackson template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; &#125; /** * 对hash类型的数据操作 * * @param redisTemplate * @return hash操作对象 */ @Bean public HashOperations&lt;String, String, Object&gt; hashOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForHash(); &#125; /** * 对redis字符串类型数据操作 * * @param redisTemplate * @return 字符串操作对象 */ @Bean public ValueOperations&lt;String, Object&gt; valueOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForValue(); &#125; /** * 对链表类型的数据操作 * * @param redisTemplate * @return list操作对象 */ @Bean public ListOperations&lt;String, Object&gt; listOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForList(); &#125; /** * 对无序集合类型的数据操作 * * @param redisTemplate * @return set操作对象 */ @Bean public SetOperations&lt;String, Object&gt; setOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForSet(); &#125; /** * 对有序集合类型的数据操作 * * @param redisTemplate * @return zset操作对象 */ @Bean public ZSetOperations&lt;String, Object&gt; zSetOperations(RedisTemplate&lt;String, Object&gt; redisTemplate) &#123; return redisTemplate.opsForZSet(); &#125;&#125; 5.Springboot自动装配5.1 自动装配类 从RedisTemplate的自动装配类可以看出来，Springboot会自动向IOC注入RedisTemplate、StringRedisTemplate俩个类，但都是有前提条件且注入的操作都比较粗糙，很多属性都没有设置，所以这俩个类的注入只会在你没有手动注入的情况下生效。 另外RedisTemplate底层依赖Lettuce或Jedis，至于使用哪个完全依赖配置方法中的参数RedisConnectionFactory，这个类有LettuceConnectionConfiguration、JedisConnectionConfiguration俩个实现类，分别对应Lettuce和Jedis俩个客户端。 5.2 默认底层依赖123456789101112131415161718/** * Lettuce客户端 连接配置类 */@Configuration( proxyBeanMethods = false)@ConditionalOnClass(&#123;RedisClient.class&#125;)class LettuceConnectionConfiguration extends RedisConnectionConfiguration &#123; @Bean @ConditionalOnMissingBean(&#123;RedisConnectionFactory.class&#125;) LettuceConnectionFactory redisConnectionFactory(ObjectProvider&lt;LettuceClientConfigurationBuilderCustomizer&gt; builderCustomizers, ClientResources clientResources) throws UnknownHostException &#123; LettuceClientConfiguration clientConfig = this.getLettuceClientConfiguration(builderCustomizers, clientResources, this.getProperties().getLettuce().getPool()); return this.createLettuceConnectionFactory(clientConfig); &#125; // 其他省略...&#125; 1234567891011121314151617/** * Jedis客户端 连接配置类 */@Configuration( proxyBeanMethods = false)@ConditionalOnClass(&#123;GenericObjectPool.class, JedisConnection.class, Jedis.class&#125;)class JedisConnectionConfiguration extends RedisConnectionConfiguration &#123; @Bean @ConditionalOnMissingBean(&#123;RedisConnectionFactory.class&#125;) JedisConnectionFactory redisConnectionFactory(ObjectProvider&lt;JedisClientConfigurationBuilderCustomizer&gt; builderCustomizers) throws UnknownHostException &#123; return this.createJedisConnectionFactory(builderCustomizers); &#125; // 其他省略...&#125; 从代码可以看出，Springboot会将这俩个客户端的配置类都尝试注册IOC(包括包含的RedisConnectionFactory)，但是在Springboot2.X版本里默认只包含Lettuce的依赖，所以在@ConditionalOnClass的注入限制条件下，默认使用的是Lettuce客户端。 5.3 Springboot2.X使用Jedis如果想要在Springboot2.X的RedisTemplate使用Jedis客户端实现，就需要对依赖进行处理，排除包含的Lettuce依赖，再添加Jedis依赖。这样Lettuce注入时，就无法满足@ConditionalOnClass的条件，而Jedis正好满足。 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除lettuce依赖 --&gt; &lt;exclusion&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; 注:Springboot1.X版本仅支持Jedis底层依赖，有兴趣可以自己看源码。","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(五) Lettuce客户端","slug":"Redis-Lettuce客户端","date":"2021-02-05T09:00:00.000Z","updated":"2021-06-09T03:49:42.666Z","comments":true,"path":"2021/02/05/Redis-Lettuce客户端/","link":"","permalink":"http://yoursite.com/2021/02/05/Redis-Lettuce%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"前言Lettuce客户端是一个线程安全的客户端，通信方式上基于netty，保证多个线程共享一个连接对象也不会存在线程安全问题，并且连接实例数量上支持可伸缩设计，一个连接达到上限后会按需增加连接实例。另外Lettuce客户端还支持异步请求方式、全局命令超时设置等特性。 注意: 使用Lettuce客户端，Redis的版本至少2.6 1.依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;&#x2F;groupId&gt; &lt;artifactId&gt;lettuce-core&lt;&#x2F;artifactId&gt; &lt;version&gt;5.1.8.RELEASE&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;&#x2F;groupId&gt; &lt;artifactId&gt;commons-pool2&lt;&#x2F;artifactId&gt; &lt;version&gt;2.4.3&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; Lettuce客户端因为不存在单个连接对象的线程安全问题，因此在连接池使用方面没有强制要求。如果请求频率不是很高，完全可以创建单个连接对象，毕竟Redis服务端处理命令是单线程执行，创建多个物理连接也是无意义的消耗资源。 2.单机版配置2.1 配置文件1234567891011121314151617181920# IP地址spring.lettuce.host&#x3D;127.0.0.1# 端口spring.lettuce.port&#x3D;6379# 连接密码spring.lettuce.password&#x3D;123456# 连接超时时间spring.lettuce.timeout&#x3D;2000# 连接池最大连接数(使用负值表示没有限制)spring.lettuce.pool.max-total&#x3D;200# 连接池最大空闲连接spring.lettuce.pool.max-idle&#x3D;10# 连接池最小空闲连接spring.lettuce.max-idle&#x3D;5 2.2 Java配置类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Configurationpublic class LettuceConfig&#123; @Value(&quot;$&#123;spring.lettuce.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.lettuce.port&#125;&quot;) private int port; @Value(&quot;$&#123;spring.lettuce.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.lettuce.timeout&#125;&quot;) private int timeout; @Value(&quot;$&#123;spring.lettuce.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.lettuce.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.lettuce.pool.max-total&#125;&quot;) private int maxTotal; /** * 普通连接 */ @Bean public StatefulRedisConnection&lt;String, String&gt; statefulRedisConnection()&#123; // 需要连接的服务器信息 RedisURI redisUri = RedisURI.builder() .withHost(host) .withPort(port) .withPassword(password) .withTimeout(Duration.of(timeout, ChronoUnit.SECONDS)) .build(); // 创建客户端对象 RedisClient redisClient = RedisClient.create(redisUri); // 创建连接池对象 return client.connect(); &#125; /** * 连接池 */ @Bean public GenericObjectPool&lt;StatefulRedisConnection&lt;String, String&gt;&gt; genericObjectPool()&#123; // 需要连接的服务器信息 RedisURI redisUri = RedisURI.builder() .withHost(host) .withPort(port) .withPassword(password) .withTimeout(Duration.of(timeout, ChronoUnit.SECONDS)) .build(); // 创建连接池配置信息 GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig(); genericObjectPoolConfig.setMinIdle(minIdle); genericObjectPoolConfig.setMaxIdle(maxIdle); genericObjectPoolConfig.setMaxTotal(maxTotal); // 创建客户端 RedisClient redisClient = RedisClient.create(redisUri); // 创建连接对象pool return ConnectionPoolSupport.createGenericObjectPool(() -&gt; client.connect(), poolConfig); &#125;&#125; 3.主从版配置3.1 配置文件1234567891011121314151617181920# IP地址spring.lettuce.host&#x3D;127.0.0.1# 端口spring.lettuce.port&#x3D;6379# 连接密码spring.lettuce.password&#x3D;123456# 连接超时时间spring.lettuce.timeout&#x3D;2000# 连接池最大连接数(使用负值表示没有限制)spring.lettuce.pool.max-total&#x3D;200# 连接池最大空闲连接spring.lettuce.pool.max-idle&#x3D;10# 连接池最小空闲连接spring.lettuce.max-idle&#x3D;5 3.2 Java配置类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Configurationpublic class LettuceConfig&#123; @Value(&quot;$&#123;spring.lettuce.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.lettuce.port&#125;&quot;) private int port; @Value(&quot;$&#123;spring.lettuce.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.lettuce.timeout&#125;&quot;) private int timeout; @Value(&quot;$&#123;spring.lettuce.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.lettuce.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.lettuce.pool.max-total&#125;&quot;) private int maxTotal; /** * 普通连接 */ @Bean public StatefulRedisMasterSlaveConnection&lt;String, String&gt; statefulRedisConnection()&#123; // 需要连接的服务器信息, 主节点、从节点都可以 RedisURI redisUri = RedisURI.builder() .withHost(host) .withPort(port) .withPassword(password) .withTimeout(Duration.of(timeout, ChronoUnit.SECONDS)) .build(); // 创建客户端 RedisClient redisClient = RedisClient.create(redisUri); // 任意节点最终都能获取到，涉及的所有相关节点信息 StatefulRedisMasterSlaveConnection&lt;String, String&gt; connection = MasterSlave.connect(redisClient, new Utf8StringCodec(), redisUri); // 只从主节点读取数据(读写分离设置成ReadFrom.SLAVE即可) connection.setReadFrom(ReadFrom.MASTER); return connection; &#125; /** * 连接池 */ @Bean public GenericObjectPool&lt;StatefulRedisMasterSlaveConnection&lt;String, String&gt;&gt; genericObjectPool()&#123; // 参考单机模式连接池配置... &#125;&#125; 如果不想通过任意节点获取所有主从节点信息，可以通过代码固定设置要连接的节点集合: 1234567891011121314151617181920public StatefulRedisMasterSlaveConnection&lt;String, String&gt; statefulRedisConnection()&#123; // 固定节点集合 List&lt;RedisURI&gt; uris = new ArrayList&lt;&gt;(); uris.add(RedisURI.builder().withHost(host1).withPort(port1).build()); uris.add(RedisURI.builder().withHost(host2).withPort(port2).build()); uris.add(RedisURI.builder().withHost(host3).withPort(port3).build()); // 创建客户端 RedisClient redisClient = RedisClient.create(); // 创建连接对象 StatefulRedisMasterSlaveConnection&lt;String, String&gt; connection = MasterSlave.connect(redisClient, new Utf8StringCodec(), uris); // 设置读写分离 connection.setReadFrom(ReadFrom.MASTER); return connection;&#125; 4.哨兵版配置4.1 配置文件1234567891011121314151617181920212223# 哨兵IP地址spring.lettuce.sentinel.host&#x3D;127.0.0.1# 哨兵端口spring.lettuce.sentinel.port&#x3D;26379# masterIdspring.lettuce.sentinel.master.id&#x3D;master# 连接密码spring.lettuce.password&#x3D;123456# 连接超时时间spring.lettuce.timeout&#x3D;2000# 连接池最大连接数(使用负值表示没有限制)spring.lettuce.pool.max-total&#x3D;200# 连接池最大空闲连接spring.lettuce.pool.max-idle&#x3D;10# 连接池最小空闲连接spring.lettuce.max-idle&#x3D;5 4.2 Java配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Configurationpublic class LettuceConfig&#123; @Value(&quot;$&#123;spring.lettuce.sentinel.host&#125;&quot;) private String sentinelHost; @Value(&quot;$&#123;spring.lettuce.sentinel.port&#125;&quot;) private int sentinelPort; @Value(&quot;$&#123;spring.lettuce.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.lettuce.timeout&#125;&quot;) private int timeout; @Value(&quot;$&#123;spring.lettuce.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.lettuce.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.lettuce.pool.max-total&#125;&quot;) private int maxTotal; /** * 普通连接 */ @Bean public StatefulRedisMasterSlaveConnection&lt;String, String&gt; statefulRedisConnection()&#123; // Lettuce提供了哨兵的拓扑发现机制，仅需要配置一个哨兵节点即可得到所有相关节点信息 RedisURI redisUri = RedisURI.builder() .withPassword(password) .withSentinel(sentinelHost, sentinelPort); .withSentinelMasterId(masterId); .build(); RedisClient redisClient = RedisClient.create(); StatefulRedisMasterSlaveConnection&lt;String, String&gt; connection = MasterSlave.connect(redisClient, new Utf8StringCodec(), redisUri); // 读写分离设置 connection.setReadFrom(ReadFrom.SLAVE); return connection; &#125; /** * 连接池 */ @Bean public GenericObjectPool&lt;StatefulRedisMasterSlaveConnection&lt;String, String&gt;&gt; genericObjectPool()&#123; // 参考单机模式连接池配置... &#125;&#125; 5.集群版配置5.1 配置文件1234567891011121314151617# 集群节点spring.lettuce.cluster.nodes&#x3D;127.0.0.1:7001,127.0.0.2:7001,127.0.0.3:7001# 连接密码spring.lettuce.password&#x3D;123456# 连接超时时间spring.lettuce.timeout&#x3D;2000# 连接池最大连接数(使用负值表示没有限制)spring.lettuce.pool.max-total&#x3D;200# 连接池最大空闲连接spring.lettuce.pool.max-idle&#x3D;10# 连接池最小空闲连接spring.lettuce.max-idle&#x3D;5 5.2 Java配置类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Configurationpublic class LettuceConfig&#123; @Value(&quot;#&#123;&#x27;$&#123;spring.lettuce.cluster.nodes&#125;&#x27;.split(&#x27;,&#x27;)&#125;&quot;) private List&lt;String&gt; clusterList; @Value(&quot;$&#123;spring.lettuce.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.lettuce.timeout&#125;&quot;) private int timeout; @Value(&quot;$&#123;spring.lettuce.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.lettuce.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.lettuce.pool.max-total&#125;&quot;) private int maxTotal; /** * 普通连接 */ @Bean public StatefulRedisClusterConnection&lt;String, String&gt; statefulRedisConnection()&#123; // 指定所有主节点，也可以随便指定一个节点，lettuce会通过拓扑机制发现所有节点 ArrayList&lt;RedisURI&gt; redisUriList = new ArrayList&lt;&gt;(); for(String cluster : clusterList)&#123; String[] hostPort = cluster.split(&quot;:&quot;); String host = hostPort[0]; Integer port = Integer.valueOf(hostPort[1]); redisUriList.add(RedisURI.builder().withHost(host).withPort(port).withPassword(password).build()); &#125; // 建立客户端 RedisClusterClient redisClusterClient = RedisClusterClient.create(redisUriList); // 定时更新集群的拓扑信息，这里设置10分钟更新一次 ClusterTopologyRefreshOptions options = ClusterTopologyRefreshOptions .builder() .enablePeriodicRefresh(Duration.of(10, ChronoUnit.MINUTES)) .build(); // 将更新规则设置到客户端对象 redisClusterClient.setOptions(ClusterClientOptions.builder().topologyRefreshOptions(options).build()); // 建立连接 StatefulRedisClusterConnection&lt;String, String&gt; connection = redisClusterClient.connect(); // 读写分离设置 connection.setReadFrom(ReadFrom.SLAVE); // 返回 return connection; &#125; /** * 连接池 */ @Bean public GenericObjectPool&lt;StatefulRedisClusterConnection&lt;String, String&gt;&gt; genericObjectPool()&#123; // 参考单机模式连接池配置... &#125;&#125; 6.基本使用6.1 同步使用同步的使用方式就和普通的方法调用一样: 123456789101112131415161718192021222324252627@Componentpublic class LettuceCommands&#123; @Autowired private StatefulRedisClusterConnection clusterConnection; private static RedisAdvancedClusterCommands&lt;String, String&gt; commands; @PostConstruct public void initRedisCommands()&#123; commands = clusterConnection.sync(); &#125; public static void set(String key, String value)&#123; commands.set(key, value); &#125; public static void set(String key, String value)&#123; // nx()代表键不存在才会设置，xx()代表键存在才会设置；ex()代表过期时间单位为秒，px代表毫秒 SetArgs setArgs = SetArgs.Builder.nx().ex(5); commands.set(key, value, setArgs); &#125; public static String get(String key)&#123; return commands.get(key); &#125;&#125; 6.2 异步使用异步调用就像使用Java自带的线程FutureTask一样，调用后立即返回RedisFuture对象，并通过调用get()方法阻塞获取返回值: 12345678910111213141516171819202122232425@Componentpublic class LettuceCommands&#123; @Autowired private StatefulRedisClusterConnection clusterConnection; private static RedisAdvancedClusterAsyncCommands&lt;String, String&gt; commands; @PostConstruct public void initRedisCommands()&#123; commands = clusterConnection.async(); &#125; public static RedisFuture&lt;String&gt; set(String key, String value)&#123; return commands.set(key, value); &#125; public static RedisFuture&lt;String&gt; set(String key, String value)&#123; return commands.set(key, value); &#125; public static RedisFuture&lt;String&gt; get(String key)&#123; return commands.get(key); &#125;&#125; 6.3 反应式使用Lettuce的反应式基于编程框架Project Reactor，暂时没看懂。","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(四) Jedis客户端","slug":"Redis-Jedis客户端","date":"2021-02-05T08:00:00.000Z","updated":"2021-05-31T00:48:48.338Z","comments":true,"path":"2021/02/05/Redis-Jedis客户端/","link":"","permalink":"http://yoursite.com/2021/02/05/Redis-Jedis%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"前言Jedis客户端提供的API比较全面，方法名与redis的命令名非常相似，了解redis的命令也就能熟练使用Jedis客户端。由于提供的功能偏低层，springboot不支持依赖自动装配，且存取对象需要自己手动组装或转化，因此很少有直接使用jedis。 1.依赖1234&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt;&lt;/dependency&gt; 2.单机版配置1.1 配置文件1234567891011121314151617181920212223# IP地址spring.jedis.host&#x3D;127.0.0.1# 端口spring.jedis.port&#x3D;6379# 连接密码spring.jedis.password&#x3D;123456# 连接超时时间spring.jedis.timeout&#x3D;2000# 连接池最大连接数(使用负值表示没有限制)spring.jedis.pool.max-total&#x3D;200# 连接池最大空闲连接spring.jedis.pool.max-idle&#x3D;10# 连接池最小空闲连接spring.jedis.max-idle&#x3D;5# 获取连接最大等待时间spring.jedis.max-wait-millis&#x3D;10000 1.2 Java配置类12345678910111213141516171819202122232425262728293031323334353637@Configurationpublic class JedisConfig&#123; @Value(&quot;$&#123;spring.jedis.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.jedis.port&#125;&quot;) private int port; @Value(&quot;$&#123;spring.jedis.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.jedis.timeout&#125;&quot;) private int timeout; @Value(&quot;$&#123;spring.jedis.pool.max-total&#125;&quot;) private int maxTotal; @Value(&quot;$&#123;spring.jedis.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.jedis.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.jedis.max-wait-millis&#125;&quot;) private long maxWaitMillis; @Bean public JedisPool jedisPool()&#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(maxTotal); jedisPoolConfig.setMaxIdle(maxIdle); jedisPoolConfig.setMinIdle(minIdle); jedisPoolConfig.setMaxWaitMillis(maxWaitMillis); return new JedisPool(jedisPoolConfig,host,port,timeout,password); &#125;&#125; 1.3 读写分离单机、主从运行模式都是连接固定服务器地址，因此实现读写分只需要创建两个JedisPool即可。 2.哨兵版配置2.1 配置文件1234567891011121314151617181920212223# 哨兵节点spring.jedis.sentinel.nodes&#x3D;127.0.0.1:26379,127.0.0.2:26379,127.0.0.3:26379# 哨兵主节点名称，用于指定连接的某个主从组合spring.jedis.sentinel.master.name&#x3D;abc# 连接密码spring.jedis.password&#x3D;123456# 连接超时时间spring.jedis.timeout&#x3D;2000# 连接池最大连接数(使用负值表示没有限制)spring.jedis.pool.max-total&#x3D;200# 连接池最大空闲连接spring.jedis.pool.max-idle&#x3D;10# 连接池最小空闲连接spring.jedis.max-idle&#x3D;5# 获取连接最大等待时间spring.jedis.max-wait-millis&#x3D;10000 2.1 Java配置类1234567891011121314151617181920212223242526272829303132333435363738394041424344@Configurationpublic class JedisConfig&#123; @Value(&quot;#&#123;&#x27;$&#123;spring.jedis.sentinel.nodes&#125;&#x27;.split(&#x27;,&#x27;)&#125;&quot;) private List&lt;String&gt; nodeList; @Value(&quot;$&#123;spring.jedis.sentinel.master.name&#125;&quot;) private String masterName; @Value(&quot;$&#123;spring.jedis.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.jedis.timeout&#125;&quot;) private int timeout; @Value(&quot;$&#123;spring.jedis.pool.max-total&#125;&quot;) private int maxTotal; @Value(&quot;$&#123;spring.jedis.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.jedis.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.jedis.max-wait-millis&#125;&quot;) private long maxWaitMillis; @Bean public JedisSentinelPool jedisPoolConfig()&#123; // 连接池参数 JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(maxTotal); jedisPoolConfig.setMaxIdle(maxIdle); jedisPoolConfig.setMinIdle(minIdle); jedisPoolConfig.setMaxWaitMillis(maxWaitMillis); // 哨兵节点 Set&lt;String&gt; sentinels = new HashSet&lt;&gt;(nodeList); // 哨兵连接池 return new JedisSentinelPool(masterName, sentinels, jedisPoolConfig, password); &#125;&#125; 2.3 感知节点变化哨兵模式的配置中，JedisSentinelPool对象的构造器会为每个masterName下的每个sentinel节点开启一个线程，通过pub/sub模式订阅master节点的变化，接收到变化信息后重置jedis连接池信息。 监听器为JedisSentinelPool的内部类MasterListener，线程的run()源码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public void run() &#123; // 1.设置线程正常运行 this.running.set(true); // 2.正常运行情况下，进入循环 while(this.running.get()) &#123; // 3.通过哨兵IP、端口与服务器建立连接 this.j = new Jedis(this.host, this.port); try &#123; // 4.再次判断是否满足运行条件 if (!this.running.get()) &#123; break; &#125; // 5.订阅master节点变化频道 this.j.subscribe(new JedisPubSub() &#123; // 订阅到消息后的处理逻辑 public void onMessage(String channel, String message) &#123; // 打印日志 JedisSentinelPool.this.log.fine(&quot;Sentinel &quot; + MasterListener.this.host + &quot;:&quot; + MasterListener.this.port + &quot; published: &quot; + message + &quot;.&quot;); // 5.1 解析订阅返回的消息字符串，格式: String[] switchMasterMsg = message.split(&quot; &quot;); // 5.2 分割后的数据长度小于3代表正常格式，大于等于3代表无效返回结果 if (switchMasterMsg.length &gt; 3) &#123; // 5.3 再次判断masterName是否为自己监听的，估计是怕乱传数据 if (MasterListener.this.masterName.equals(switchMasterMsg[0])) &#123; // 5.4 提取新master节点的IP、端口，作为参数调用initPool()方法重置连接 JedisSentinelPool.this.initPool(JedisSentinelPool.this.toHostAndPort(Arrays.asList(switchMasterMsg[3], switchMasterMsg[4]))); &#125; else &#123; JedisSentinelPool.this.log.fine(&quot;Ignoring message on +switch-master for master name &quot; + switchMasterMsg[0] + &quot;, our master name is &quot; + MasterListener.this.masterName); &#125; &#125; else &#123; JedisSentinelPool.this.log.severe(&quot;Invalid message received on Sentinel &quot; + MasterListener.this.host + &quot;:&quot; + MasterListener.this.port + &quot; on channel +switch-master: &quot; + message); &#125; &#125; // &quot;+switch-master&quot;，就是订阅的channel名称 &#125;, new String[]&#123;&quot;+switch-master&quot;&#125;); &#125; catch (JedisConnectionException var8) &#123; // 6.如果发生连接异常，且监听逻辑仍然允许运行 if (this.running.get()) &#123; // 打印日志 JedisSentinelPool.this.log.log(Level.SEVERE, &quot;Lost connection to Sentinel at &quot; + this.host + &quot;:&quot; + this.port + &quot;. Sleeping 5000ms and retrying.&quot;, var8); // 7.暂停固定时间后，进入下次while循环继续监听 try &#123; Thread.sleep(this.subscribeRetryWaitTimeMillis); &#125; catch (InterruptedException var7) &#123; JedisSentinelPool.this.log.log(Level.SEVERE, &quot;Sleep interrupted: &quot;, var7); &#125; &#125; else &#123; JedisSentinelPool.this.log.fine(&quot;Unsubscribing from Sentinel at &quot; + this.host + &quot;:&quot; + this.port); &#125; &#125; finally &#123; // 8.关闭连接 this.j.close(); &#125; &#125;&#125; 再来看看initPool()方法源码: 12345678910111213141516171819202122private void initPool(HostAndPort master) &#123; // 只有订阅返回的master信息，与当前的不一致，才会进行重置 if (!master.equals(this.currentHostMaster)) &#123; // 重新赋值当前master节点指向实例 this.currentHostMaster = master; // 重置Jedis工厂信息 if (this.factory == null) &#123; this.factory = new JedisFactory(master.getHost(), master.getPort(), this.connectionTimeout, this.soTimeout, this.password, this.database, this.clientName, false, (SSLSocketFactory)null, (SSLParameters)null, (HostnameVerifier)null); this.initPool(this.poolConfig, this.factory); &#125; else &#123; this.factory.setHostAndPort(this.currentHostMaster); this.internalPool.clear(); &#125; // 打印变化日志 this.log.info(&quot;Created JedisPool to master at &quot; + master); &#125;&#125; 2.4 读写分离之前在写Redis运行模式的时候有讲过，Redis服务端不支持读写分离功能，需要客户端自己去实现。然而Jedis客户端也不会自动对请求进行读写分离，具体情况还得看源码: 12345678910111213141516171819202122// 获取一个Jedis连接对象public Jedis getResource() &#123; while(true) &#123; // 从池子里获取一个Jedis连接(连接池全都是master连接) Jedis jedis = (Jedis)super.getResource(); jedis.setDataSource(this); // 获取当前master信息 HostAndPort master = this.currentHostMaster; // 如果连接池取出的Jedis连接信息，与当前master的连接一致时，才返回 HostAndPort connection = new HostAndPort(jedis.getClient().getHost(), jedis.getClient().getPort()); if (master.equals(connection)) &#123; return jedis; &#125; // 到这里说明不一致，肯定是master挂掉了，选举出了新master，连接池的数据还没来得及更新， // 特殊处理后进入下次循环，确保返回的一定是master的Jedis连接 this.returnBrokenResource(jedis); &#125;&#125; 源码可以看出，实现读写分离只能手动配置。实现方案也很简单，Jedis提供了sentinelSlaves()方法，可以通过哨兵节点获取到所有Slave节点信息，然后为每个Slave节点创建JedisPool对象，多个Slave就自己写代码实现负载均衡，另外照抄一份MasterListener类的订阅代码，及时更新从节点信息即可。 由于Jedis客户端很少直接使用，再加上Redis读写分离的应用不是很普遍，这里就不自己写代码实现了。 3.集群版配置3.1 配置文件1234567891011121314151617181920# 集群节点spring.jedis.nodes&#x3D;127.0.0.1:6379,127.0.0.2:6379,127.0.0.3:6379# 连接密码spring.jedis.password&#x3D;123456# 连接超时时间spring.jedis.timeout&#x3D;2000# 连接池最大连接数(使用负值表示没有限制)spring.jedis.pool.max-total&#x3D;200# 连接池最大空闲连接spring.jedis.pool.max-idle&#x3D;10# 连接池最小空闲连接spring.jedis.max-idle&#x3D;5# 获取连接最大等待时间spring.jedis.max-wait-millis&#x3D;10000 3.2 Java配置类123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configurationpublic class JedisConfig&#123; @Value(&quot;$&#123;spring.jedis.nodes&#125;&quot;) private String nodes; @Value(&quot;$&#123;spring.jedis.password&#125;&quot;) private String password; @Value(&quot;$&#123;spring.jedis.timeout&#125;&quot;) private int timeout; @Value(&quot;$&#123;spring.jedis.pool.max-total&#125;&quot;) private int maxTotal; @Value(&quot;$&#123;spring.jedis.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.jedis.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.jedis.max-wait-millis&#125;&quot;) private long maxWaitMillis; @Bean public JedisCluster jedisCluster()&#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(maxTotal); jedisPoolConfig.setMaxIdle(maxIdle); jedisPoolConfig.setMinIdle(minIdle); jedisPoolConfig.setMaxWaitMillis(maxWaitMillis); String[] nodesArray = nodes.split(&quot;,&quot;); Set&lt;HostAndPort&gt; nodeSet = new HashSet&lt;&gt;(); for(int i = 0; i &lt; nodesArray.length; i++)&#123; String[] nodeInfo = nodesArray[i].split(&quot;:&quot;); String host = nodeInfo[0]; Integer port = Integer.valueOf(nodeInfo[1]); nodeSet.add(new HostAndPort(host, port)); &#125; return new JedisPool(nodeSet,timeout,jedisPoolConfig); &#125;&#125; 3.3 读写分离集群模式的读写分离，除了要考虑主节点的变化外，还需要考虑到卡槽的路由，总之实现起来较为复杂，以后有空再写吧。 4.线程安全使用Jedis对象直连服务端，多线程调用情况下会造成线程安全问题。Jedis发送请求命令是通过Connection的connect()方法实现，具体源码: 4.1 传输流安全源码中可以看出方法内的outputStream、inputStream均为Jedis对象的成员变量，并且俩成员变量的赋值没有任何加锁措施，这意味着多个线程同时调用一个Jedis对象发送命令时，输入输出流的值会被不停覆盖引起数据错乱，也就是出现了线程安全问题。 4.2 网络连接安全在较低版本的Jedis依赖中，Socket的创建并没有单独抽成一个方法，而是写在connect()方法内部，具体源码: 源码中可以看出Socket对象是先创建并赋值给socket成员变量，然后再建立长连接，最后处理连接的输入输出流。假设线程A创建完Socket对象并成功建立长连接，但是还没有调用getXXStream()方法，此时线程B也执行connect方法创建Socket对象并重新赋值socket，由于线程B还没来得及建立长连接，线程A就开始调用getXXStream()方法，因此会抛出java.net.SocketException: Socket is not connected异常。 4.3 解决方案解决线程安全的方案是通过JedisPool连接池去管理Jedis实例，线程向服务器发送redis命令时，先通过连接池获取一个Jedis实例，使用完毕后归还连接池，这样就保证了一个Jedis实例同一时刻只会被一个线程调用。","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(三) 运行模式","slug":"Redis-运行模式","date":"2021-01-28T02:00:00.000Z","updated":"2021-06-08T09:39:47.651Z","comments":true,"path":"2021/01/28/Redis-运行模式/","link":"","permalink":"http://yoursite.com/2021/01/28/Redis-%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"1.单机模式关于Redis单节点服务的并发性能，官方提供的数据表示读的速度为110000次/每秒,写的速度是81000次/每秒。当然，官方数据只能代表大概情况，毕竟机器内存大小、网络带宽等因素都会影响到Redis的性能，不过支撑万级并发还是没啥问题的。 1.1 单机性能Redis自带redis-benchmark工具，可以指定参数对Redis单个服务进行并发压测，得出真实的性能数据，工具参数如下: 序号 参数项 描述 默认值 1 -h 指定服务器IP或域名 127.0.0.1 1 -p 指定服务器端口 6379 1 -s 指定服务器socket 无 1 -c 指定并发连接数 50 1 -n 指定请求数 10000 1 -d 以字节形式指定set、get值的数据大小 2 1 -k keep alive=1 reconncet=0 无 1 -r set、get使用随机key，SADD使用随机值 无 1 -P 通过管道传输请求 1 1 -q 强制退出redis，没懂表达什么的 无 1 –csv 以csv格式输出 无 1 -l 生成循环，永久性执行测试 无 1 -t 仅运行以逗号分隔的测试命令列表 无 1 -I Idle模式，仅打开N个idle连接并等待 无 先看看官网是什么姿势: 用我阿里云服务器来一波: 没使用管道传输请求时，和Redis官网数据差不多，加上管道参数我这小霸王服务器简直渣渣... 1.2 优缺点没啥优点，缺点一大堆。首先不具备自动容错和恢复功能，服务器宕机或者Redis服务崩掉后只能手动干预，在恢复期间完全不可用。其次数据没有备份，如果将单机Redis服务作为数据库存储数据，机器磁盘发生损坏或被删库跑路，数据就真的丢失了。 2.主从模式主从模式是将某一台Redis服务作为主机，其余的一或多个作为备份机，主机每次收到写命令执行成功后会发送给所有备份机进行数据同步。这种模式主要解决单机模式的数据备份问题，并且主从结点的数据几乎一致，可以对集群进行读写分离，提高请求的处理能力。 2.1 集群架构 2.2 主从复制Redis在2.8版本前主从节点的数据同步是用SYNC实现，主节点需要执行BGSAVE命令生成RDB文件，并且RDB文件的传输也由主线程完成，这意味着整个同步流程中主线程是完全阻塞的，无法处理读写请求，如果RBD文件过大会导致数据同步耗时太久，大量的请求被阻塞。 Redis2.8版本开始采用PSYNC，通过异步+缓冲区的方式同步数据，整个过程如下: 从节点启动连接主节点，发送PSYNC命令进行同步数据 主节点收到命令后执行BGSAVE向从节点发送快照文件(异步) 从节点拿到新的rdb文件替换旧的，载入收到的rdb文件到内存 主节点完成自己的rdb加载后开始向从节点发送缓冲区的命令 从节点开始同步主节点的缓冲区的命令(此时从节点初始化完成，正常工作) 每次主节点收到命令都会发送给从节点同步数据 2.3 读写分离Redis的读写分离机制是主节点处理所有的写命令，从节点处理所有的读命令，从而减轻主节点的请求压力。然而引用这种机制是要付出一定代价的，首先是数据一致性问题，毕竟主节点的数据同步到从节点需要时间，比如秒杀业务的库存数据，就需要强一致性。其次Redis服务端并不支持这个功能，服务端接收到命令后并不会根据命令类型转发到主节点或从节点，需要客户端自己区分哪些IP的服务是拥有写权限，哪些是只读权限。 单纯的主从模式，从java客户端的角度来实现读写分离，需要创建两个连接bean，一个连接主节点，另一个连接从节点，并根据命令类型分别调用不同bean的API。哨兵模式配置相对较为简单，客户端只需要连接哨兵节点，就可以定位主节点与从节点，然后进行读写分离操作。 读写分离机制更多的是针对mysql这种需要磁盘IO的数据库，因为磁盘IO是比较耗时的操作，对于Redis这种内存IO的数据库很少能达到这种瓶颈。如果你项目中对于Redis仅仅作为缓存使用，换句话说就是读请求数量远大于写请求数量，并且可以接受一定程度的数据一致性问题，可以考虑使用读写分离。 由于Redis的内存管理机制并不能保证某个Key过期后立马被清除，导致在3.2版本以前会把过期数据同步到从节点，在读写分离的场景下会读取到脏数据，这个问题在3.2版本后修复，使用读写分离的一定要注意Redis的版本号! 2.4 优缺点优点: 数据可以保持多个备份，不会出现由于磁盘损坏导致的数据丢失。 主节点向从节点同步数据的过程是异步执行，在此期间正常处理读写请求。 读写分离机制有效缓解了主节点的读请求压力。 缺点: 仍然不支持自动容错和恢复功能，宕机后需要手动干预。 主节点宕机如果没来得及同步到从服务器会引起数据不一致。 数据全部存储在一个节点中，无法在线扩容。 3.哨兵模式哨兵模式是启动一个或多个哨兵节点对多个Redis主从节点进行发现并监控，如果主节点宕机将所属的某个从节点升级为主节点，另外哨兵节点之间也会互相监控。哨兵模式的出现是为了解决Redis集群模式下的自动容错和恢复功能。 3.1 集群架构 3.2 哨兵监控原理哨兵节点启动后，会根据配置文件确认要监控的master节点，并且与每个主节点建立两条连接: 在连接②中，哨兵节点每10秒向主节点、从节点发送INFO命令。由于配置哨兵监控对象时只需要填写主节点信息，因此通过INFO命令可以获取到主节点的所有从节点，达到自动发现新加入的从节点的目的。对于链式主从模式来说，从节点可能还会配置从节点，因此涉及到的所有从节点也会发送INFO命令。 在连接②中，哨兵节点每2秒向主节点、从节点的sentinel:hello频道发布自己的信息。信息内容包括自身的IP、端口、运行ID等，以此来向其他哨兵宣告自己的存在。 在连接②中，哨兵节点每1秒向主节点、从节点以及其他哨兵节点发送ping命令。接收方必须在指定时间内(down-after-milliseconds)作出正确响应，如果down-after-milliseconds值小于1秒时，那么发送频率会提升到每down-after-milliseconds秒发送一次。 在连接①中，哨兵节点订阅监控目标的sentinel:hello频道，从而得知其他哨兵节点的存在。在订阅到消息后会判断消息中的哨兵节点是否为新加入的节点，如果是则与其建立连接②，然后发送ping命令，并通过这种形式实现哨兵集群的相互监控。 3.2 主观/客观下线哨兵节点会通过ping命令的形式判断节点是否正常运行，当命令在down-after-milliseconds内未做出正确响应，那么哨兵节点会认为其主观下线。主观下线仅表示哨兵自己认为出故障了，但并不一定是节点出现故障，也有可能是哨兵自己网络出现问题导致与被监控节点无法ping通，因此需要借助其他哨兵进一步判断。 哨兵发送命令给其他哨兵节点，询问此故障节点是否主观下线，如果超过指定数量(参数配置)的哨兵都觉得此故障节点主观下线，那么会被整个哨兵集群认为客观下线。如果故障节点的角色是从节点或其他哨兵节点，需要将其踢掉，如果是主节点挂掉了，那么还要进行故障恢复，考虑到故障恢复只能由一个哨兵去完成，因此需要选举出领头哨兵，处理这个事情。 3.3 故障恢复领头哨兵获取故障主节点的所有从节点，选出优先级最高的从节点，优先级通过replica-priority参数设置。如果出现优先级相同的情况，则选出复制的偏移量最大的节点，因为偏移量越大代表同步的数据越完整，如果到此还存在优先级相同的从节点，那么选择运行ID(启动时自动生成)最小的那个节点。 领头哨兵向选中的从节点发送SLAVEOF no one命令，将其升级为主节点 故障的原主节点重新启动后，领头哨兵发送SLAVEOF命令，将其变为新master的slave 3.4 优缺点优点: 哨兵模式是主从模式的升级版，主从模式拥有的优点，哨兵模式都有 支持自动容错和恢复功能 哨兵支持集群相互监控，稳定性高 缺点: 所有数据仍然存储在单节点中，很难在线扩容 配置太繁琐 4.分片模式分片模式是将数据集分成几个小部分，存储在不同的服务节点中，在处理读写请求时，通过对key的hash取余定位到具体的节点，然后转发命令到该节点进行处理。分片模式的出现是为了解决主从模式、哨兵模式下，单节点存储瓶颈以及在线扩容的问题。 早期为了应对哨兵模式单节点存储的弱点，需要借助代理中间件在客户端实现分区存储以及对key的定位查询功能，常见的中间件有codis、twemproxy等。直到Redis发布3.0版本后，才开始在服务端支持分片模式，下面只讲述redis自己提供的分片模式。 4.1 集群架构 图中为3个master节点的分片集群，每个master节点拥有一个slave节点，每个节点(包括slave节点)都会实时同步其他所有节点的信息。服务端只有master节点处理请求(如果需要实现读写分离，需要在客户端进行改造)，当请求命令涉及的key不属于本节点负责时，会根据实时同步的节点信息进行转发。 4.2 槽位分配Redis分片模式在存储数据时采用虚拟哈希槽的方式存储，预先分配16384(2^14)个卡槽，集群内各master节点均摊所有卡槽，并对外提供服务: 服务端接收读到写命令后，通过key定位出所在的节点: Redis在分片设计上，并没有直接使用一致性哈希算法(hash值%节点数，定位节点)，而是在中间添加了一层哈希槽的定位计算。这样节点新增或删除后进行数据转移，只需要操作卡槽到对应节点即可，如果采用一致性哈希算法，还需要遍历节点内所有数据并逐个计算，得出哪些数据需要转移的。 另外卡槽的存储概念仅针对master节点，slave节点仅根据master节点同步的数据正常存储。 4.3 节点伸缩当对集群进行缩容或扩容后，整个集群的master节点数量发生变化，为了保证所有正常节点对哈希槽的分配是均匀的，需要对所有哈希槽进行重新分配并迁移。 例如三个master节点的集群中，新增一个master节点后的哈希槽分配变化: 图中可以看出哈希槽迁移的范围: master-0节点的4097～5461哈希槽转移到master-1节点中 master-1节点的8193～10922哈希槽转移到master-2节点中 master-2节点的12289～16384哈希槽转移到master-3节点中 4.4 客户端路由客户端向服务端发送读写命令时，并不知道此次操作涉及的key到底在哪个分片节点上，因此只能请求集群中的任意一个节点(包括从节点)，如果响应的是moved重定向异常，则从异常中获取正确的节点信息并再次请求: 在集群正常运行期间，moved重定向机制完全可以解决key的路由访问，当节点正常退出或者有新节点加入集群后，部分卡槽数据进行迁移。此时moved重定向节点的数据已经迁移到别的节点中，仍然会出现查询不到数据的情况，此时节点会返回ask重定向给客户端，再次请求服务端: 上述的路由转发机制可以看出，数据量过多或者集群节点过多时，客户端的请求会产生大量的重定向，对redis的性能造成影响，因此客户端都会对分片节点负责的哈希槽信息进行缓存，从而减少无用的网络请求，当节点伸缩导致负责的哈希槽变化时，客户端也会做出相应的更新。 比如java提供的Jedis客户端，内部JedisCluster类久实现了类似机制。JedisCluster在创建后会从集群中选择一个正常运行的节点，查询哈希槽的分布情况并将映射关系保存到本地，然后为集群的每个节点建立连接池，所有的请求命令都会先去映射缓存查询，然后再调用指定的连接池发送请求命令。 4.5 故障恢复分片模式并没有哨兵模式那种单独监控节点实现故障恢复，当某个master节点挂掉后，需要借助集群内其他master节点，从故障master的众多slave节点中选举出一个继续工作。 首先有两种情况会导致redis-cluster不可用，也就是集群无法提供服务: 超过半数master节点挂掉(无视对应的slave) 某个节点的master、slave全挂 在集群可用的情况下，master挂掉后会触发选举，选出新的master节点: slave节点发现自己的master变为FAIL slave节点先给自己epoch+1，然后请求集群内其他master节点给自己投票，并将事件广播给其他所有节点 slave节点发起投票后，会等待至少NODE_TIMEOUT*2时间接受投票结果(最少也会2秒) master节点接收到投票后响应FAILOVER_AUTH_ACK，并且在NODE_TIMEOUT*2时间内不给同一master的其他slave投票 slave接收FAILOVER_AUTH_ACK的epoch如果小于自身，直接丢失 如果slave接收到半数以上符合条件的FAILOVER_AUTH_ACK，则声明自己选举成功 如果在等待的NODE_TIMEOUT2时间内没有赢得选举，放弃本次选举，然后在NODE_TIMEOUT4时间后重新发起选举 选举成功后，广播通知集群内其他节点 节点中的epoch全称为currentEpoch，集群中新加入或重启的节点(无论master或slave)currentEpoch值都为0，某节点需要请求其他节点提供协助时(目前只有选举)currentEpoch+1。当节点接收到其他节点的包时(比如slave发起的选举)，如果包中的currentEpoch大于自身的currentEpoch，那么会更新为发送者的currentEpoch。这种规则下集群中所有节点的currentEpoch最终会达成一致，也是代表自身在集群中的通信是健康的。 另外slave节点发现master挂掉后，不会立即发起投票，而是通过延迟公式计算出一定延迟时间后在发起:延迟公式: 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms 延迟发送选举是为了确保master挂掉的信息在整个集群内传开(让子弹飞一会)，如果没有延迟的情况下可能部分master接收到选举请求时还没有感知到master挂了，造成误判。在0.5秒的基础上增加随机时间，是为了防止多个slave同时发起选举。公式最后的SLAVE_RANK代表slave节点已经从master节点复制的总量的rank，越小代表复制的越新，这个参数理论上可以保证持有最新数据的slave会先发起选举。 4.6 slave自动迁移Redis为了保证整个集群的高可用，让每个分片都正常提供服务，某些情况下会对slave节点迁移到别的分片下面。假设某个集群拥有3主3从共6个节点，万一某个master对应的slave发生宕机，这时候就不存在高可用这一说，因为master在发生宕机就没有任何节点可以代替它工作，会导致整个集群不可用。 针对这种情况，集群在发现某个master节点没有任何slave节点时，会将其他master节点多余的slave节点迁移过来，继续保证集群的高可用。因此在搭建集群模式时，一定要多部署几台slave节点备用，提高集群的高可用状态。","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(二) 内存管理与持久化","slug":"Redis-内存管理与持久化","date":"2021-01-24T08:00:00.000Z","updated":"2021-02-28T07:15:52.400Z","comments":true,"path":"2021/01/24/Redis-内存管理与持久化/","link":"","permalink":"http://yoursite.com/2021/01/24/Redis-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B8%8E%E6%8C%81%E4%B9%85%E5%8C%96/","excerpt":"","text":"1.过期策略1.1 定期删除Redis中所有设置过期时间的KEY都会被记录到一个字典中，通过定时任务每隔一段时间(默认100ms)对字典中的KEY进行扫描删除过期数据，当然这种定时扫描只会发生在master节点上，slave节点会通过主节点同步的DEL命令进行同步达到删除过期键的目的。 扫描过程中如果过期KEY在总数中占的比例少于25%，则终止循环，这么做的目的是为了节省CPU资源，为了防止过期KEY数量过多导致循环一直执行下去，Redis增加了超时限制，消耗一定时间循环也会被打破。 1.2 惰性删除Redis在执行任何读写命令时都会先找到这个KEY，惰性删除就作为一个切入点在命令执行前判断KEY是否过期，如果过期则进行删除。这种机制主要为了弥补定期删除策略扫描无法覆盖全部KEY的情况。 2.淘汰策略2.1 淘汰规则Redis的内存淘汰机制是针对内存不足的情况下，采用某种策略淘汰掉内存中的部分数据，保证服务可以继续写入数据，Redis提供了六种淘汰规则: noeviction: 禁止淘汰，当内存达到阈值时，后续所有需要申请内存的命令都会报错 allkeys-random: 从数据集中任意选择数据淘汰 allkeys-lru: 从数据集中挑选最近最少使用的数据淘汰 volatile-lru: 从设置了过期时间的数据集中挑选最近最少使用的数据淘汰 volatile-ttl: 从已设置了过期时间的数据集中挑选即将要过期的数据淘汰 volatile-random: 从已设置了过期时间的数据集中任意选择数据淘汰 如果内存中不存在设置过期时间的key，会导致前缀为volatile的三种策略找不到任何可以清理的key，结果和noeviction一样报错。 2.2 文件配置redis.conf# 策略启动阈值(单位字节，64位系统中0表示不限制，32位系统中隐式不能超过3GB)maxmemory 0# 淘汰策略类型maxmemory-policy noeviction# 样本池数量maxmemory-samples 5 2.3 淘汰过程当Redis服务内存达到maxmemory后，对于所有的读写请求，都会触发freeMemoryIfNeeded函数以清理内存，并且这个清理过程是阻塞的，直到腾出足够的内存空间。整个清理过程并不是针对所有key，而是随机抽取maxmemory-samples个样本key，根据设置好的淘汰策略从样本范围中进行淘汰。 maxmemory-samples的大小对于noeviction和random策略没有任何影响，对于lru和ttl策略来说，值的大小直接影响到淘汰的精准度。值越大则样本范围越大，精准度越高，缺点是CPU耗时也会越高，在清理函数阻塞情况下甚至造成请求卡顿，反之亦然。 2.4 lru算法实现lru算法是淘汰掉最近最少使用的数据，由于Redis采用样本随机抽取的机制清理数据，因此并不是严格意义上的lru算法。Redis给每个key额外添加了一个25bit的字段，存储最后一次的访问时间，并以此字段作为参考值实现lru算法。 在3.0版本进行优化，维护一个大小为16的候选池，池中的数据根据访问时间排序，第一次抽取的样本都会放入池中，后续随机抽取的样本数据只有在访问时间小于池中最小时间的情况下，才会放入池中，直到候选池放满数据。再往后抽取的样本中，如果仍然存在访问时间小于池中的数据，将池中访问时间最大的移除并添加到池中。当需要淘汰数据时，直接从池中选取最久没被访问的key淘汰掉。 3.RDB持久化RDB即快照，是Redis默认的持久化方式，对某个特定时间点的数据进行一次全量备份，并将备份结果写入一个紧凑的二进制文件中，除此之外Redis还支持命令的方式手动触发一次RDB持久化。 3.1手动触发SAVE: 同步持久化，由于Redis所有命令仅用一个线程进行处理，因此整个持久化过程会阻塞所有读写请求，如果数据量大的话会造成长时间的阻塞，生产环境一般禁止使用。 BGSAVE: 异步持久化，Redis接收到此命令后会fork出一个子进程处理持久化工作，由于Redis所有命令仅用一个线程进行处理，因此fork期间所有读写请求仍然是阻塞的，直到fork完毕后继续处理请求，与此同时，子进程异步执行持久化工作。 3.2 自动触发在配置文件redis.conf中，默认设置了三种自动触发的规则，用户可以根据自身业务场景修改触发规则。如果同时配置多个save选项，那么只要其中任一条满足，Redis都会触发一次BGSAVE操作: 123456789# 自动触发的规则格式:# save &lt;seconds&gt; &lt;changes&gt;# 900秒(15分钟)内至少发生一次写操作，触发RDB持久化save 900 1# 300秒(5分钟)内至少发生10次写操作，触发RDB持久化save 300 10# 60秒(1分钟)内至少发生10000次写操作，触发RDB持久化save 60 10000 当手动执行shutdown命令关闭服务器时，如果没有开启AOF持久化功能，也会自动触发一次bgsave命令进行RDB持久化。 3.3 执行流程 执行bgsave命令的时候，Redis主进程会检查是否有子进程在执行RDB/AOF持久化任务，如果有的话，直接返回 Redis主进程会fork一个子进程来执行执行RDB操作，fork操作会对主进程的读写请求造成阻塞，fork操作完成后会发消息给主进程，从而不再阻塞主进程。 RDB子进程会根据Redis主进程的内存生成临时的快照文件，持久化完成后会使用临时快照文件替换掉原来的RDB文件。该过程中主进程的读写不受影响，但Redis的写操作不会同步到主进程的主内存中，而是会写到一个临时的内存区域作为一个副本。 子进程完成RDB持久化后会发消息给主进程，通知RDB持久化完成，并将上阶段内存副本中的增量写数据同步到主内存。 3.4 优缺点优点是主进程在整个持久化过程中唯一要做的就是fork出子进程，剩下的持久化工作全部由子进程完成，父进程无需执行任何磁盘IO操作。RDB文件是紧凑的二进制数据构成，占用磁盘相对AOF较小，在服务重启加载数据时速度会快很多。 缺点是无法做到实时持久化，一旦服务器异常退出或宕机，会导致最后一次快照后面的所有数据丢失，因此需要根据自身场景配置触发规则，尽量减少这种意外带来的损失。另外主进程fork子进程属于重量级操作，过程中会阻塞主进程的读写请求，因此配置触发规则除了考虑到减少意外带来的损失以外，还要考虑到频繁RDB对读写请求响应时间带来的影响。 4.AOF持久化AOF采用命令日志的方式进行内存数据的持久化，每条写命令都会记录到AOF日志中，当Redis需要重启时会逐条执行命令日志，将持久化数据恢复到内存中。 4.1 开启方式AOF持久化方式默认是关闭的，可以通过配置文件redis.conf进行开启，如果RDB和AOF同时开启，Redis在启动时默认加载AOF文件恢复数据，并且后续采用AOF方式进行持久化。 redis.conf中，关于AOF的相关配置: 1234567891011121314151617# 此选项为aof功能的开关，默认为no，可以通过修改为yes来开启aof功能appendonly yes# 指定aof文件名称appendfilename appendonly.aof# 指定aof操作中文件同步策略，分为always、everysec(默认)、no三种appendfsync everysec# 在aof-rewrite期间，appendfsync是否暂缓文件同步no-appendfsync-on-rewrite no# aof文件rewrite触发的最小文件尺寸(mb,gb),只有大于此aof文件大于此尺寸是才会触发rewrite，默认64mbauto-aof-rewrite-min-size 64mb# 相对于“上一次”rewrite，本次rewrite触发时aof文件应该增长的百分比auto-aof-rewrite-percentage 100 4.2 appendfsyncAOF对于每条写命令都会追加到文件中，当写命令过于频繁会导致磁盘IO的负荷加重，另外Linux系统提供了pageCache机制将部分磁盘IO请求转化为内存IO，并通过异步方式刷回磁盘文件，这种机制在一定程度上缓解了AOF文件写入的压力，同时也增加了数据丢失的可能，比如数据写入内核缓存后还没来得及刷回磁盘发生断电，那么这部分数据就会丢失。 Redis提供了三种刷盘的策略: always: 每条写命令都会调用操作系统的fsync函数，强制从内核缓存刷回磁盘，较为安全，代价是性能很低。 everysec: 每秒调用一次操作系统的fsync函数，是一种折中的处理方式，最多丢失一秒的数据。 no: Redis永远不主动调用fsync函数，让操作系统自身选择何时同步磁盘，性能较好，缺点是断电情况下会造成更多的丢失可能。 4.3 rewrite(重写机制)AOF采用记录命令的方式持久化，这会导致随着时间的推移AOF文件会越来越大，因此需要定期对AOF日志进行压缩，压缩的过程就是rewrite。例如对key1初始值是0，共调用incr命100次，key1的值变为100，那么一条set key1 100 就可以合并之前的100条命令。 rewrite目的是对AOF文件的压缩，但是执行过程中并不是对现有AOF文件进行编辑删减，而是采取类似RDB快照的方式，遍历内存中所有数据，逐个将数据对应的命令添加到新的AOF文件中。在rewrite过程中对于新的变更操作仍然写入到旧的AOF文件中，不过这些命令Redis会单独在保存一份，当内存中的数据全部写入到新的AOF文件后，之前单独存储的新命令也会一并写入到新AOF文件，最后替换掉旧的AOF文件。 4.4 no-appendfsync-on-rewrite在对AOF文件压缩期间，新的写命令仍然会记录到旧的AOF文件中，在假设新的AOF文件必定生成成功的前提下，这部分命令是否成功写入旧的AOF文件已经不重要了，这段时间调用操作系统的fsync函数强制刷盘完全是资源浪费，可以暂缓。但是这个参数Redis给的默认值是no，也就是说Redis不推荐暂缓强制刷盘，可能是出于安全考虑吧。 4.5 自动触发rewriteauto-aof-rewrite-min-size是自动触发rewrite的最小文件尺寸，默认64mb。当某条写命令追加到AOF文件后文件大于64mb，会自动触发rewrite。 auto-aof-rewrite-percentage是自动触发rewrite的最小增长比例，默认100%。每次rewrite后都会记录此刻AOF文件的大小，后续每次追加命令都会获取当前AOF文件大小，和最初的大小比较并计算增长百分比，当增长比例超过100%触发rewrite。 注:只有俩个条件都满足的情况下才会触发rewrite。 4.6 手动触发rewrite如果你的Redis一直使用RDB持久化方式，并且想更换为AOF，那么可以使用config命令动态修改redis.conf配置，然后发送此命令将扫描当前内存数据，生成一份AOF文件。 触发命令:redis-cli -h ip -p port bgrewriteaof 4.7 优缺点优点是大部分情况下仅仅是对AOF文件追加写日志，对服务器性能影响较小，并且在默认配置下最多丢失一秒的数据。AOF文件的内容都是命令，可以兼容任何Redis版本。 缺点是在数据量较大的情况下，会不断触发rewrite，对AOF文件进行压缩。即使经过压缩，由于自身是文本文件，体积相对RDB(二进制文件)要大得多。并且在服务重启过程中需要重演命令式的恢复数据，相对于RDB要慢上许多。 4.8 AOF文件修复在将命令写入AOF文件过程中，可能因为宕机造成文件有错误，导致Redis服务重启时拒绝加载此AOF文件，可以通过redis-check-aof工具修正AOF文件。 5.混合持久化5.1 开启方式12# yes开启 no关闭aof-use-rdb-preamble yes 5.2 执行过程RDB与AOF俩种持久化方式的优缺点都很明显，因此Redis4.0推出了混合持久化方式，将原AOF文件内容变成了前部分存储RDB格式数据、后部分存储AOF格式数据，既保证了服务运行期间数据不丢失，又避免了服务重启数据恢复慢的问题:","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"Redis(一) 常用数据类型","slug":"Redis-常用数据结构","date":"2021-01-22T08:00:00.000Z","updated":"2021-02-27T05:23:34.952Z","comments":true,"path":"2021/01/22/Redis-常用数据结构/","link":"","permalink":"http://yoursite.com/2021/01/22/Redis-%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"1.字符串(string)string是Redis最基础的数据类型，底层通过int或SDS(动态字符串:Simple Dynamic String)实现。在设置一个字符串键值对后，Redis会根据value的类型、长度来决定使用哪种编码，通过不同的编码方式映射到不同的数据结构。 1.1 内部结构 int类型数据结构支持incr、incrby、decr、decrby等命令对value值进行增减操作。 embstr编码的SDS结构是专门用于保存短字符串的优化编码方式，与raw编码不同，embstr编码通过一次内存分配函数将字符串KV对象和value值分配在连续的内存块中，提高CPU取数据的效率问题。 raw编码的SDS结构用于存储较长的字符串，通过俩次内存分配函数得到俩块内存，给字符串KV对象和value分别存储。 1.2 常用命令123456789101112131415161718192021get [key] [value] &#x2F;&#x2F; 获取指定key对应valueset [key] [value] &#x2F;&#x2F; 给指定key设置value，该命令会覆盖旧的KVset [key] [value] [ex 秒数]&#x2F;[px 毫秒]&#x2F;[nx 纳秒] &#x2F;&#x2F; 给指定key设置value和过期时间，该命令会覆盖旧的KV和过期时间append [key] [value] &#x2F;&#x2F; 把value追加到key的原值上expire [key] [time] &#x2F;&#x2F; 等价于set + expire命令setex [key] [time] [value] &#x2F;&#x2F; 给指定key设置过期时间，单位秒setnx [key] [value] &#x2F;&#x2F; 如果key不存在则set，否则返回0incr [key] &#x2F;&#x2F; 如果key为整数则使值增加1incrby [key] [number] &#x2F;&#x2F; 如果key为整数则使值增加numberdecr [key] &#x2F;&#x2F; 如果key为整数则使值减少1decrby [key] [number] &#x2F;&#x2F; 如果key为整数则使值减少number 1.3 应用场景 分布式缓存: 字典常量数据、JSON字符串、图片视频等序列化数组、Session等 分布式锁: 根据业务对接口或代码块加分布式锁 常规计数: 网站浏览量、点击量、收藏量等 接口监控: 通过AOP和Redis计数器对指定接口限流或屏蔽 2 哈希(hash)hash类型在Redis类型中是指键值中的值本身又是一个键值对，底层通过ziplist(压缩列表)或hashtable(哈希表)实现，Redis会根据哈希表中的KV元素数量、每个元素值大小来决定使用哪种数据。 2.1 内部结构 ziplist是Redis自己设计的数据结构，使用更加紧凑的结构实现多个元素的连续存储，相比较hashtable更加节约内存，但是在大量元素的情况下读写效率不如hashtable，大块连续的存储空间的要求也比较苛刻。 hashtable的结构与Java JDK1.7版本的HashMap类似，采用数组加链表的形式进行存储，相比较ziplist在大量元素情况下读写效率更好，因为读写时间复杂度为O(1)。 2.2 常用命令123456789101112131415161718192021222324hset [object-key] [hash-key] [hash-value] &#x2F;&#x2F; 对某个hash对象设置单个键值对hsetnx [object-key] [hash-key] [hash-value] &#x2F;&#x2F; 对某个hash对象设置单个键值对(如果hash-key已存在则什么都不做)hset [object-key] [hash-key-1] [hash-value-1] [hash-key-2] [hash-value-2] &#x2F;&#x2F; 对某个hash对象设置多个键值对hexists [object-key] [hash-key] &#x2F;&#x2F; 判断hash对象某个key是否存在(0否 1是)hget [object-key] [hash-key-1] &#x2F;&#x2F; 获取hash对象单个key的值hmget [object-key] [hash-key-1] [hash-key-2] &#x2F;&#x2F; 获取hash对象多个key的值hlen [object-key] &#x2F;&#x2F; 获取hash对象某个键值对hgetall [object-key] &#x2F;&#x2F; 获取hash对象所有键值对hkeys [object-key] &#x2F;&#x2F; 获取某个hash对象的key列表hdel [object-key] &#x2F;&#x2F; 删除hash的某个keyhincrby [object-key] [hash-key] num &#x2F;&#x2F; hash对象某个数字类型value递增num(num为整数)hincrbyfloat [object-key] [hash-key] num &#x2F;&#x2F; hash对象某个数字类型value递增num(num为浮点) 2.3 应用场景哈希一般用于存储结构简单、属性较多、修改频率较高的对象信息，比如购物车、商品信息、配置信息等。哈希存储对象相对于字符串存储对象的优势在于，整个修改操作可以只针对某个属性。 比如购物车的商品数量发生改变，字符串存储需要将内容提取出来转为对象，修改完属性后在转化为字符串存储，在购物车数据比较大的情况下会增加很多无意义的资源浪费。哈希类型存储购物车信息一般将每个商品的ID和数量作为元素的键值对，每次发生改变也仅仅是修改某个键值对的value，涉及到的资源消耗相对较少。 3.列表(list)list类型是用来存储多个有序的字符串，3.2之前的版本底层通过ziplist(压缩列表)或linkedlist(链表)实现，Redis会根据列表中的KV元素数量、每个元素值大小来决定使用哪种数据结构，3.2包括以后版本采用quicklist代替。 3.1 内部结构 ziplist的优缺点上面已经提到了。 linkedlist和ziplist都是线性数据结构，当元素较多或者某元素内存占用较大时，连续存储不太现实，还得采用linkedlist方式进行存储。 3.2 应用场景123456789101112131415161718lpush [key] [value] [value]... &#x2F;&#x2F; 在list的头部插入单个或多个value，如果可以不存在则先创建(返回插入个数)rpush [key] [value] [value]... &#x2F;&#x2F; 在list的尾部插入单个或多个value，如果可以不存在则先创建(返回插入个数)lpushx [key] [value] &#x2F;&#x2F; 在list的头部插入单个value，如果key不存在则什么都不做rpushx [key] [value] &#x2F;&#x2F; 在list的尾部插入单个value，如果key不存在则什么都不做lrange [key] [start] [end] &#x2F;&#x2F; 获取list从start到end之间的元素，start和end可为负数，-1代表尾部元素，-2代表倒数第二个llen [key] &#x2F;&#x2F; 获取list的长度lpop [key] &#x2F;&#x2F; 返回并删除list中的第一个元素rpop [key] &#x2F;&#x2F; 返回并删除list中的最后一个元素lrem [key] [count] [value] &#x2F;&#x2F; 从头遍历并删除count个值为value的元素，如果count&#x3D;0，则删除全部 3.3 应用场景Redis关于此类型结构的操作比较丰富，支持两端插入和弹出、还可以获取指定范围的元素列表、获取指定索引下标的元素等，是一个比较灵活的数据结构，因此应用场景也比较灵活。可以利用list实现消息队列、列表的分页数据缓存等。 4.去重集合(set)set类型是一个无序并唯一的键值集合，底层通过inset(整数集合)或hashtable(哈希表)实现，根据集合内部的元素类型、个数来决定使用哪种数据结构。 4.1 内部结构 intset集合存在的意义就是尽量减少内存的使用，当intset的条件无法满足时，使用hashtable进行存储，set集合对hashtable的使用和Java一样，仅仅使用key而已。 4.2 常用命令1234567891011121314151617181920212223242526sadd [key] [value-1] [value-2]... &#x2F;&#x2F; 添加单个或多个元素scard [key] &#x2F;&#x2F; 获取集合中元素个数sismember [key] [value] &#x2F;&#x2F; 判断某个元素是否存在(返回 0否 1是)spop [key] &#x2F;&#x2F; 随机弹出一个元素，如果set没有元素则返回(nil)srandmember [key] [num] &#x2F;&#x2F; 随机获取集合中num个元素，num为大于总数则获取全量，为负数则随机获取num的绝对值个(可能有重复)smove [key-A] [key-B] [value] &#x2F;&#x2F; 将key-A的某个元素移动到key-B中srem [key] [value] &#x2F;&#x2F; 删除某个元素(返回 0没找到 1删除成功)sdiff [key] [key-A] [key-B] &#x2F;&#x2F; 差集，返回key有、key-A和key-B没有的所有元素(也可以一对一比较)sdiffstore [key] [key-A] [key-B] &#x2F;&#x2F; 差集，计算后将结果重置到key中sinter [key] [key-A] [key-B] &#x2F;&#x2F; 交集，返回多个key中共有的元素sdiffstore [key] [key-A] [key-B] &#x2F;&#x2F; 交集，计算后将结果重置到key中sunion [key] [key-A] [key-B] &#x2F;&#x2F; 并集，返回多个key中包含的所有元素sunionstore [key] [key-A] [key-B] &#x2F;&#x2F; 并集，计算后将结果重置到key中 4.3 应用场景set类型具有无序、不可重复、支持并交差等特性，在电商、社交、视频网站等平台有着广泛的应用，通过将用户的标签信息存储在set结构中，可以向用户推荐相同兴趣爱好的好友，或者存储好友信息来展示相同好友功能等。 通过set集合提供的SADD、SRANDMEMBER命令可以实现抽奖功能。需要注意的是Redis在2.6版本才支持SADD命令的count参数，在3.2版本支持SRANDMEMBER命令的count参数，2.6版本以下仅支持单次获取一个随机元素。 5.有序去重集合(zset)zset类型相对于set类型，每个元素多了一个score值，保证元素内容不重复的前提下，通过score值对元素自动排序，底层通过ziplist(压缩列表)或skiplist(跳跃表)实现，根据集合内部的元素个数、大小来决定使用哪种数据结构。 5.1 数据结构 ziplist的优缺点上面已经提到了。 skiplist也是一个有序的数据结构，为了避免链表结构这种查找元素需要从头到尾遍历的弊端，采用在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 zset还会维护一个字典结构(hashtable)，用于新增元素时判断是否已存在 5.2 常用命令1234567891011121314151617181920zadd [key] [score-1] [value-1] [score-2] [value-2]... &#x2F;&#x2F; 添加单个或多个元素zrange [key] [start] [end] [withscores] &#x2F;&#x2F; 根据范围列出zset的所有元素和对应score，如果end为-1则代表尾部，-2为倒数第二个元素zrangebyscore [key] [start-score] [end-score] &#x2F;&#x2F; 根据score范围取元素(闭区间)zrangebyscore [key] [start-score] [end-score] [withscores] &#x2F;&#x2F; 根据score范围取元素和对应score(闭区间)zrangebyscore [key] [start-score] [end-score] [withscores] limit [start-index] [size] &#x2F;&#x2F; 根据score范围取元素和对应score(闭区间)，并分页zcard [key] &#x2F;&#x2F; 获取元素个数zcard [key] [start-score] [end-score] &#x2F;&#x2F; 获取指定socre范围的元素个数zrank [key] [value] &#x2F;&#x2F; 获取某个元素的下标值zscore [key] [value] &#x2F;&#x2F; 获取某个元素的score值zrem [key] [value-1] [value-2] &#x2F;&#x2F; 删除指定元素 5.3 应用场景既然数据结构的亮点是排序，那么应用场景自然也是和排序相关。应用最为广泛的就是排行榜系统，例如某个网站的文章访问量、视频播放量/点赞量、电商系统商品的销售量等等。 Redis的ZRANGEBYLEX命令支持对相同的score元素进行排序，实现方式是将元素字符串转化为二进制数组的字节数进行比较，因此可以用来实现手机号、姓名等排序场景。 6.SDS(动态字符串)SDS的实现原理和Java的ArrayList差不多，都是采用动态扩容的方式来减少内存的频繁分配。当字符串长度小于1M时，扩容后为原来的两倍，当字符串超过1M时，每次固定扩容1M。Redis对SDS的扩容限制为最高512M，也就是说Redis的字符串最多可以存储512M的字符串，超过此容量会报错。 6.1 内部结构 7.ziplist(压缩列表)ziplist存在的意义就是压缩、节约内存，当然这种节约内存是相对于数组而言进行的优化，在Redis中存在的意义是为了弥补链表和哈希表在内存分配上的不足。 7.1 数组存储的弊端我们都知道数组中每个元素的大小相同，在我们存储字符串的时候，不能保证存储的每个元素大小都相同，这就需要以占用内存最大的元素作为数组元素大小的标准。假设某个数组中最大的元素占用30KB，数组中小于30KB的元素存储就会出现部分下标的内存浪费: 7.2 数组压缩存储数组的优势在于分配一片连续的空间，提升CPU的内存访问效率，压缩列表保留了这个优势，同时在结构上将每个下标的进行压缩，压缩后的占用保持和对应元素大小一致，达到节约内存的目的: 这就有个问题了，每个元素占用的内存块不固定，无法向数组那样通过下标内存大小计算出下个元素的位置。因此压缩列表为每个元素添加了一个length属性，通过这个属性就很容易计算出下个元素的位置并提取数据了: 7.2 优缺点ziplist的特点是数据在内存中连续存储，不会像linkedlist、hashtable那样分散存储，不需要额外的存储指针来管理分散内存块之间的关联，再加上ziplist内存块中绝大多数空间都用来存储元素数据，且元素数据不会浪费内存空间，因此ziplist的优势在于节约内存。 当元素数量上升，或某个元素占用内存过大，会导致当前内存块大小无法满足而必须要扩展，内存块越大扩展的消耗就越大。对于list类型来说，提供的常用命令都是对列表的增删操作，大量元素下的情况下linkedlist更能胜任。对于hash类型来说，无论元素数量多大查询某个元素的时间复杂度永远是O(1)，也比ziplist的更合适。 8.quicklist(压缩列表+链表混合)列表类型在Redis3.2版本以前采用ziplist和linkedlist进行存储，前者的思想是时间换空间，后者的思想是空间换时间，无论哪种都有很明显的优缺点为此Redis3.2版本开始对列表数据结构进行了改造，创建了quicklist代替ziplist和linkedlist。 8.1 内存结构quicklist是ziplist和linkedlist的混合体，从宏观上讲仍然是一个linkedlist，而其中的每个元素都是一个zipList，zipList内部紧凑且连续的存储着真实的元素数据: 8.1 新增节点过程quicklist仍然是将元素存储在zipList中，上面也讲过zipList不适合存储大型字符串和大量元素，扩容是他的硬伤。当新插入的元素无法放入zipList中时，quicklist会直接创建一个新的zipList并将数据存入，然后将新创建的zipList作为一个元素添到linkedlist中，删除也是同样的道理。 9.skiplist(跳表)对于链表来说，即使结构中的数据是有序存储，如果想要查询某个数据也只能从头到尾遍历，查询效率较低。skiplist也是一种有序链表，为了提高查询效率，skiplist在每个节点上建立索引，避免从头到尾遍历，是一种空间换时间的优化思想。 9.1 内部结构传统链表获取第9个元素，需要通过指针地址查询9次: 跳表获取第9个元素，通过元素存储的索引，只需要通过指针地址查询5次: 如果获取的是第8个元素，则通过索引遍历到索引9(大于8)，然后退回索引7向后遍历: 当元素数量增多，可以建立多层索引提高效率: Redis跳表结构: Redis跳表的元素索引存储的是链表下坐标，由于整个列表根据score排序存储，因此score的范围查询同样可以走索引。","categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}],"tags":[]},{"title":"RocketMQ(十一)高可靠","slug":"RocketMQ高可靠","date":"2021-01-20T04:00:00.000Z","updated":"2021-01-20T14:19:05.791Z","comments":true,"path":"2021/01/20/RocketMQ高可靠/","link":"","permalink":"http://yoursite.com/2021/01/20/RocketMQ%E9%AB%98%E5%8F%AF%E9%9D%A0/","excerpt":"","text":"重复消费Rebalance集群模式下，由于各种原因导致触发rebalance，可能出现某个Consumer已经消费完一条消息，但是并没有向Broker提交offset，导致rebalance结束后，Consumer再次拉取此条数据进行消费。 TIMEOUTConsumer没有及时向Broker反馈消息的处理状态，或者网络原因导致Broker没有收到反馈，Broker判定为TIMEOUT并触发重试机制，导致消息重复消费。 instanceName重复RocketMQ会通过ClientConfig类的buildMQClientId方法为每个Consumer生成唯一标示cid: 1234567891011121314151617public String buildMQClientId() &#123; StringBuilder sb = new StringBuilder(); // 本地IP地址 sb.append(this.getClientIP()); sb.append(&quot;@&quot;); // jvm进程ID sb.append(this.getInstanceName()); // unitName可以在启动时指定，默认null if (!UtilAll.isBlank(this.unitName)) &#123; sb.append(&quot;@&quot;); sb.append(this.unitName); &#125; return sb.toString(); &#125; 如果某个消费组的Consumer完全在部署在一个服务器的不同Docker容器中，会出现instanceName相同的情况，默认情况下会导致不同Consumer的唯一标示cid相同。前面再均衡章节有讲述过重新分配是对cid集合、队列集合提取并排序，然后根据策略重新给Consumer分配队列。 如果Consumer的cid相同，会被分配到同一个队列进行消息拉取消费，也就是说一个队列会被同一消费组内多个Consumer订阅，那么投递到此队列的所有消息都会出现重复消费，甚至退化为广播模式。 分配策略不同这个场景只是个人猜测，rebalance过程中，Consumer各自通过分配策略计算出自身需要拉取的队列，如果同一消费组内不同的Consumer设置的策略不同，会出现计算结果有重叠的队列，也就意味着一条消息被会被多个Consumer消费，造成消息重复。 解决方案根据业务逻辑做幂等处理，或者使用redis等中间件对相关数据进行加锁，如果Consumer部署在同一个服务器的不同Docker容器中，则需要在Consumer手动设置随机instanceName(比如UUID)。 消息丢失Producer单向发送Producer如果采用单向发送消息的方式，无法知晓消息是否发送成功，如果因为网络等原因Broker没有收到消息并落盘，会导致消息丢失。 异步刷盘RocketMQ的异步刷盘机制，采用pageCache减少磁盘IO次数，并由操作系统定时将pageCache中的数据IO到磁盘中，如果消息存储在pageCache中还未落盘就发生宕机，会导致这部分消息丢失。 Broker无备份即使Broker采用同步刷盘方式保存消息数据，由于特殊情况导致磁盘损坏，没有任何备份的情况下该Broker保存的所有消息全部丢失。 解决方案 Producer端使用同步发送机制，如果有必要采用事务消息机制，确保消息投递到Broker进行存储。 Broker端开启主从模式并且复制方式设置为同步复制。 Consumer端确保消息处理完毕后提交offset，而不是接收消息后交给线程异步处理直接提交offset。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(十)HA机制","slug":"RocketMQHA机制","date":"2021-01-17T04:00:00.000Z","updated":"2021-01-20T04:46:20.357Z","comments":true,"path":"2021/01/17/RocketMQHA机制/","link":"","permalink":"http://yoursite.com/2021/01/17/RocketMQHA%E6%9C%BA%E5%88%B6/","excerpt":"","text":"主从模式RocketMQ通过Broker的主从模式实现服务的高可用，Slave节点定时向Master节点发送请求同步最新数据，并且在4.5版本后支持主从节点的自动切换，当主节点出现故障后，根据RAFT算法从Slave节点中选择一个作为Master，保证Broker服务的正常生产消费。 主从模式优点: 数据备份 : 数据冗余多份，一定程度上保证了Master出现不可恢复的故障后，数据不丢失。 高可用性 : 即使Master宕机，Consumer会自动重连到对应的Slave节点，不会出现消费停滞的情况。 读写分离 : Slave节点可以一定程度上缓解Master节点的读压力。 元数据复制BrokerController类有个handleSlaveSynchronize方法，当role为BrokerRole.SLAVE时，会注册一个定时任务，每隔10秒钟执行一次SlaveSynchronize类的syncAll()方法，进行元数据的复制: 12345678910public void syncAll() &#123; // 同步topic信息 this.syncTopicConfig(); // 同步消费者偏移量信息 this.syncConsumerOffset(); // 同步延迟消费的偏移量信息 this.syncDelayOffset(); //同步订阅的消息组信息 this.syncSubscriptionGroupConfig(); &#125; 没有什么复杂的逻辑，就是通过NameServer可以得到Master节点的服务地址，然后直接调用接口就能拿到所有数据信息。Consumer在拉取完消息并消费完毕后，仍然是向Master节点提交消费进度，Slave定时进行拉取刷新。当Master节点宕机后，Consumer无法向Master提交offset信息，对此RocketMQ提供了俩种机制确保不丢失offset信息。 第一种是Consumer端将消费进度存储在自身内存中并标记hasCommitOffsetFlag属性为true，仍然定时向Broker反馈offset信息，当Broker恢复后会收到并更新offset，从节点也会定时同步Master最新offset，如果再恢复期间Consumer宕机或关闭服务，仍然会丢失部分消费进度，造成数据重复消费。 第二种是消费者在向Broker节点拉取消息时，如果为Master节点，拉取消息后会顺带更新Master的offset。 CommitLog复制复制流程: AcceptSocketService: Master启动后会运行此线程，监听并接受Slave的连接请求。 HAConnection: 每接受一个Slave的连接请求，都会创建一个对应的HAConnection，本质是对SocketChannel的read/write的封装。 SocketReadService: 由HAConnection创建，是对SocketChannel中read的封装，作用是读取slave发送的已同步offset。 SocketWriteService: 由HAConnection创建，是对SocketChannel中write的封装，作用是将消息发送给Slave。 GroupTransferService: 同步复制模式下，将Master挂起直到Slave发出同步成功信号后唤醒。 异步复制异步复制的好处是将消息写入commitlog后直接返回，无需关心与Slave的数据同步问题，消息同步给Slave的逻辑处理由HAConnection异步处理。消息持久化后无需等待Slave确认是否存储成功，从效率上高于同步复制，缺点是如果Master宕机，由于数据同步有延迟导致Slave和Master存在一定程度的数据不一致问题，适用于数据可靠性要求不高的业务场景。 同步复制同步复制与异步复制的唯一区别是持久化消息后，需等待Slave节点返回此消息的同步结果，期间被GroupTransferService线程使用CountDownLatch阻塞挂起，直到Slave返回成功结果或超时再进行唤醒。这种模式不会造成消息丢失，但是工作效率相对降低，适用于数据可靠性要求很高的业务场景。 判断主从同步是否完成的依据是Slave中已成功复制的最大消息偏移量是否大于等于消息生产者发送消息后消息服务端返回的下一条消息的起始偏移量。如果大于等于说明主从同步完成，否则等待1秒后继续检查，每一批任务中循环5次加上初始的一次一共6次，6次还没确认就关闭连接。 这里只需要有一个Slave复制成功并成功应答即算成功。 读写分离传统的读写分离是完全按照Master节点写入、Slave节点读取的规则进行，而RocketMQ有属于自己的一套读写分离逻辑。在默认情况下RocketMQ会优先选择从Master进行拉取消息，并且计算堆积量是否超过物理内存40%，表示主服务繁忙，当超过时则建议Consumer下次从Slave拉取消息。 开启读写分离需要Master与Slave添加配置slaveReadEnable=true，默认为false。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(九)事务消息","slug":"RocketMQ事务消息","date":"2020-05-18T10:00:00.000Z","updated":"2021-01-16T14:55:17.417Z","comments":true,"path":"2020/05/18/RocketMQ事务消息/","link":"","permalink":"http://yoursite.com/2020/05/18/RocketMQ%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF/","excerpt":"","text":"概述RocketMQ事务消息本质是将发送消息和本地数据库操作融合为一个事务，要么一起成功，要么一起失败，不会存在一个操作成功另一操作失败的情况，说明白点就是Broker端与数据库端持久化数据的分布式事务问题。 例如电商系统中，用户下单成功后会得到一定数量的积分奖励，但是订单系统与积分系统是俩个独立的微服务，无法放在一个事务里执行。这种业务场景可以在订单系统中执行数据库insert订单的操作，然后将增加积分以RocketMQ形式异步发送处理。 事务原理阿里官方的RocketMQ事务消息发送流程图: RocketMQ参考2PC的分布式事务解决方案，将RocketMQ事务消息的发送分解为俩个阶段: 第一阶段：发送消息，Producer把消息发送到Broker，但是此时该消息还不能被投递给消费者，此时消息的状态被称为半消息。 第二阶段：请求Broker进行消息的二次确认，根据本地数据库事务执行的成功或失败，对半消息进行提交或者回滚，成功提交的消息才可以被投递给消费者，回滚的消息会被删除。 事务状态回查:整个流程在执行过程中，可能由于网络或者服务器宕机等原因导致Broker没有收到二次确认请求，那么数据库操作和消息推送就会出现数据一致性问题。因此Broker端会启动一个线程定时扫描本地存储的半消息，并向Producer发起事务状态回查，根据回查结果决定消息的去留。 由事务状态回查机制可以断定，RocketMQ并不能保证分布式事务的强一致性，仅仅保证分布式事务的最终一致性，还不是100%保证。因为Broker存储的半消息同样会被删除策略扫描，如果因为各种原因没能及时处理二次确认，或者消息转移到队列但是Consumer一直消费失败，都会导致Conusmer错过此消息的逻辑处理。 对于Producer端要保证回查接口能正常调用，对于Consumer端要保证一定次数的消费失败后，将消息写入数据库并开启定时器扫描继续处理，然后采用发短信或钉钉、企业微信等办公APP的内部通知方式告知管理员，对消息进行人工排查处理。 代码示例订单新增业务层: 1234567891011121314151617181920212223@Slf4j@Servicepublic class OrderServiceImpl implements OrderService &#123; @Autowired private OrderMapper orderMapper; @Transactional @Override public void insert(OrderInfo orderInfo)&#123; orderMapper.insert(orderInfo); // 其他逻辑... &#125; @Override public boolean existById(String id)&#123; return id == null ? false : orderMapper.existById(id); &#125; &#125; RocketMQ本地事务监听对象: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Slf4j@Component@RocketMQTransactionListener(txProducerGroup = &quot;order_integral_tx_producer_group&quot;)public class OrderIntegralTransactionListener implements RocketMQLocalTransactionListener &#123; @Autowired private OrderService orderService; /** * 半消息发送成功后需要执行的本地事务 */ @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; try &#123; String jsonStr = new String(msg.getBody()); OrderInfo orderInfo = JSONObject.parseObject(jsonStr, OrderInfo.class); orderService.insert(orderInfo); &#125;catch (Exception e)&#123; log.error(&quot;本地事务执行异常, 回滚消息&quot;, e.getErrorMessage()); return LocalTransactionState.ROLLBACK_MESSAGE; &#125; return LocalTransactionState.COMMIT_MESSAGE; &#125; /** * Broker进行事务状态回查调用的方法 */ @Override public LocalTransactionState checkLocalTransaction(MessageExt messageExt) &#123; // 解析半消息 String halfMessage = new String(messageExt.getBody(), RemotingHelper.DEFAULT_CHARSET); OrderInfo orderInfo = JSONObject.parseObject(halfMessage, OrderInfo.class); // 查询数据库是否存在 boolean exist = orderService.existById(orderInfo.getId()); // 根据订单查询结果决定返回状态 RocketMQLocalTransactionState localTransactionState = exist ? LocalTransactionState.COMMIT_MESSAGE : LocalTransactionState.ROLLBACK_MESSAGE; log.info(&quot;本地事务状态回查执行完毕, halfMessage:&#123;&#125;, localTransactionState:&#123;&#125;&quot;, halfMessage, localTransactionState); // 失败的最好记录下来，方便数据异常排查 if(!exist)&#123; // 记录到数据库或NoSQL &#125; return localTransactionState; &#125;&#125; 订单新增控制层: 12345678910111213@RestController@RequestMapping(&quot;order&quot;)public class OrderController &#123; @RequestMapping(value = &quot;/insert&quot;, method = RequestMethod.POST) public String addUser(@RequestBody OrderInfo orderInfo)&#123; String message = JSONObject.toJSONString(orderInfo); Message sendMsg = new Message(&quot;ORDER_INTEGRAL&quot;, &quot;*&quot;, message.getBytes()); producer.sendMessageInTransaction(sendMsg, null); return Result.success(&quot;新增成功&quot;); &#125;&#125;","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(八)再均衡","slug":"RocketMQ再均衡","date":"2020-05-18T04:00:00.000Z","updated":"2021-01-20T09:08:15.053Z","comments":true,"path":"2020/05/18/RocketMQ再均衡/","link":"","permalink":"http://yoursite.com/2020/05/18/RocketMQ%E5%86%8D%E5%9D%87%E8%A1%A1/","excerpt":"","text":"简单介绍在集群消费模式下，消费组内各Consumer均摊订阅的队列信息，也就是消费端的负载均衡机制。在消费过程中如果队列、消费组信息发生变化，则需要根据分配策略对组内所有Consumer重新分配队列，这个过程就是再均衡(rebalance)。 队列变化1.当Broker节点因为宕机、停止等原因导致服务不可用时，触发一次rebalance，重新分配消费组队列: 2.当故障Broker节点重新启动后，触发一次rebalance，重新分配消费组的订阅队列: 3.当Broker节点的某个topic进行队列扩容时(为了明显一点，使用环形分配策略): 4.当Broker节点的某个topic进行队列缩容时: 消费组变化1.当消费组启动一个Consumer时，触发一次rebalance，重新分配消费组队列: 2.当消费组某个Consumer因为宕机、停止、网络异常导致无法与Broker心跳等原因停止消费时，触发一次rebalance，重新分配消费组队列: rebalance过程整个过程由Broker检测并通知Consumer端，Consumer端接收到通知后调用RebalanceImpl类的rebalanceByTopic()方法进行rebalance。rebalance是以topic+消费组为粒度对队列进行重分配的，例如某个组订阅了5个topic，那么会遍历这5个topic并分别调用rebalanceByTopic()方法执行rebalance。 注意:由于rebalance都是通过Broker端发起通知，为了防止特殊原因导致Consumer端没有收到通知错过rebalance，Consumer端会开启RebalanceService线程，每隔10秒钟对订阅的topic进行一次rebalance。 分配策略平均分配策略(默认)(AllocateMessageQueueAveragely) 12345678910111213141516171819202122232425262728293031323334353637383940414243public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll,List&lt;String&gt; cidAll) &#123; //省略参数校验代码... // 获取当前Consumer在消费者集合(cidAll)中下标的位置 int index = cidAll.indexOf(currentCID); /** * Queue数除以Consumer数取余 * 如果mod等于0，说明Queue可以被平均分配 * 如果mod大于0，说明不可以被平均分配，一定程度平均分配后仍剩余mod个队列 */ int mod = mqAll.size() % cidAll.size(); /** * averageSize代表当前Consumer可以得到的队列数 * Queue数小于等于Consumer，averageSize=1，也就是平均分配1个队列(虽然靠后的Consumer可能啥都没分到) * Queue数大于Consumer的情况下，根据Queue能否被Consumer平均分配继续处理: * 如果能平均分配，直接计算Queue数除以Consumer数得到平均值 * 如果不能平均分配，继续判断当前Consumer在cidAll的index是否小于mod: * 如果小于则说明最大化平均后剩余的mod个队列还有自己一份，averageSize = Queue数除以Consumer数取整后+1 * 如果大于等于说明最大化平均后剩余的mod个队列和自己没缘分了，averageSize = Queue数除以Consumer数取整 */ int averageSize = mqAll.size() &lt;= cidAll.size() ? 1 : (mod &gt; 0 &amp;&amp; index &lt; mod ? mqAll.size() / cidAll.size() + 1 : mqAll.size() / cidAll.size()); /** * 后续会遍历mqAll集合提取属于当前Consumer的Queue，这里需要计算遍历的起始坐标 * 如果不能平均消费，且剩余的mod个队列有自己一份，startIndex = index * averageSize * 如果不能平均消费，且剩余的mod个队列和自己无缘，startIndex = index * averageSize + mod */ int startIndex = (mod &gt; 0 &amp;&amp; index &lt; mod) ? index * averageSize : index * averageSize + mod; // 根据Math.min()计算消费者最终需要消费的数量 int range = Math.min(averageSize, mqAll.size() - startIndex); // 遍历提取 for (int i = 0; i &lt; range; i++) &#123; result.add(mqAll.get((startIndex + i) % mqAll.size())); &#125; return result;&#125; 各种情况下Queue分配情况: 环形分配策略(AllocateMessageQueueAveragelyByCircle) 12345678910111213141516public List&lt;MessageQueue&gt; allocate(String consumerGroup, String currentCID, List&lt;MessageQueue&gt; mqAll, List&lt;String&gt; cidAll) &#123; //省略参数校验代码... // 获取当前Consumer在消费者集合(cidAll)中下标的位置 int index = cidAll.indexOf(currentCID); // 以index作为起点遍历Queue集合 for (int i = index; i &lt; mqAll.size(); i++) &#123; // 对下标取模(mod), 如果与index相等, 则存储到result集合中 if (i % cidAll.size() == index) &#123; result.add(mqAll.get(i)); &#125; &#125; return result;&#125; 各种情况下Queue分配情况: 手动配置分配策略(AllocateMessageQueueByConfig)自己发挥 机房分配策略(AllocateMessageQueueByMachineRoom)感觉与平均分配策略的逻辑差不多，就近机房的逻辑判断没看懂 一致性哈希分配策略(AllocateMessageQueueConsistentHash)牵涉到一致性哈希算法，以后在更新 与kafka区别Kafka是在消费组的众多Consumer中，选举一个作为Group Leader，由这个Group Leader来计算出分配结果并同步给其他Consumer，这种机制很好的避免了脑裂问题。 RocketMQ中，Consumer端无论是主动收到通知、还是RebalanceService线程触发的rebalance，都是每个Consumer自己按照分配策略给自己重新分配队列。如果消费组内各Consumer设置的分配策略以及获取的队列信息相同，那么计算出的分配结果也是相同的，不会有任何问题，如果不相同会导致脑裂，造成多个Consumer抢夺一个队列，有的队列无人问津。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(七)消费端","slug":"RocketMQ消费端","date":"2020-05-11T04:00:00.000Z","updated":"2021-01-20T14:09:32.826Z","comments":true,"path":"2020/05/11/RocketMQ消费端/","link":"","permalink":"http://yoursite.com/2020/05/11/RocketMQ%E6%B6%88%E8%B4%B9%E7%AB%AF/","excerpt":"","text":"springboot1.X集成RocketMQ依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;&#x2F;groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;&#x2F;artifactId&gt; &lt;version&gt;4.7.0&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; application.properties 12345678# 服务端口server.port&#x3D;8082# 消费者分组rocketmq.consumer.groupName&#x3D;GROUP_A# MQ注册中心地地址rocketmq.producer.namesrvAddr&#x3D;localhost:9876 启动Consumer 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586@Slf4j@Componentpublic class OrderReminderConsumer implements MessageListenerConcurrently &#123; @Value(&quot;$&#123;rocketmq.consumer.groupName&#125;&quot;) private String groupName; @Value(&quot;$&#123;rocketmq.producer.namesrvAddr&#125;&quot;) private String nameSrvAddr; private final DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(); /** * * 初始化 * * */ @PostConstruct public void start()&#123; try &#123; // 设置消费组 consumer.setConsumerGroup(groupName); // 设置注册中心地址 consumer.setNamesrvAddr(nameSrvAddr); // 设置偏移量 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET); // 设置消费模式 consumer.setMessageModel(MessageModel.CLUSTERING); // 设置订阅topic和tags，其中tags设置多个时使用||分割 consumer.subscribe(&quot;ORDER_REMINDER&quot;, &quot;*&quot;); //每次拉取10条 consumer.setConsumeMessageBatchMaxSize(10); // 设置消费失败重试次数 consumer.setMaxReconsumeTimes(16); // 设置监听者(自身) consumer.registerMessageListener(this); // 启动 consumer.start(); &#125; catch (Exception e) &#123; log.error(&quot;消费者启动失败......&quot;); &#125; &#125; /** * * 消费处理 * * */ @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messageExtList, ConsumeConcurrentlyContext context) &#123; for(MessageExt messageExt : messageExtList)&#123; try &#123; String message = new String(messageExt.getBody(), RemotingHelper.DEFAULT_CHARSET); log.info(&quot;接收消息成功, topic:&#123;&#125;, tags:&#123;&#125;, messageId:&#123;&#125;, messageKey:&#123;&#125;, message:&#123;&#125;&quot;, messageExt.getTopic(), messageExt.getTags(), messageExt.getMsgId(), messageExt.getKeys(), message); &#125; catch (Exception e) &#123; log.error(&quot;消费失败&quot;, e); return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; /** * * 关闭Consumer * * */ @PreDestroy public void stop() &#123; consumer.shutdown(); &#125;&#125; 推拉模式Consumer可以使用推模式、拉模式从Broker节点中获取消息并消费，分别对应DefaultMQPushConsumer(推模式)和DefaultMQPullConsumer(拉模式)俩个对象来实现。 拉模式(PULL)拉模式获取消息，具体实现需要使用者在Consumer自己编写代码，先通过NameServer获取订阅topic对应的MessageQueue列表，遍历此列表对每个MessageQueue对象批量获取消息，并记录该队列下一次要取的开始offset，获取完毕后在处理下一个MessageQueue。 这种模式由Consumer端主动向Broker节点发送请求拉取消息，拉取的相关逻辑可以自由控制(比如拉取频率、单次批量拉取数量等)，因此不会出现消息堆积的情况，只要专注维护每个队列的offset即可(最好在数据库维护，能与消费业务在一个事务中更好)。缺点也很明显，Consmuer端无法准确地决定何时去拉取最新的消息，循环时间间隔太短容易忙等，浪费CPU资源，时间间隔太长client的处理能力会下降，导致有些时候消息延迟。 于是阿里采用长轮询的方式来解决这个问题，Consumer发送请求到Broker拉取消息，如果Broker发现没有消息不会直接返回，而是把连接挂起(wait)，直到Producer投递新的消息过来在对请求线程进行唤醒返回(notify)。为了避免请求连接被阻塞对系统的开销，需要使用者根据自身业务场景合理的评估时间间隔，设置消费者对于长轮询的等待时间，由consumerTimeoutMillisWhenSuspend属性控制。 推模式(PUSH)推模式获取消息，DefaultMQPushConsumer在启动时需指定MessageListenerConcurrently监听器，用于监听最新的消息，达到实时消费的效果。然而严格意义上讲，RcoketMQ并没有提供任何Broker主动推消息的功能，PUSH的本质是consumer对PULL的一层封装，让使用者感觉消息是通过Broker推送过来的。 DefaultMQPushConsumer在启动成功后，会启动一个线程并运行类似while(true)的方法疯狂的去pullRequestQueue队列里面take()元素pullRequest，可以理解为队列里面的每一个pullRequest元素都是一个需求，需求的内容就是去Broker拉取消息(PullRequest对象就是拉取消息的参数)。如果没有元素说明此时不需要拉取消息，将线程自身挂起，如果有就取出并调用pullMessage方法访问Broker进行拉取，pullMessage方法内部是对PULL的一层封装，拉取到消息后扔给线程池的消费处理函数，无论拉没拉取到消息，都会将pullRequest元素放回队列。 由此可以看出推模式的本质还是拉模式，区别在于推模式是写个死循环一直调用PULL，相当于和Broker一直保持联系。拉消息、消费消息由不同的线程取处理，这就导致一个问题，如果订阅的主题，Producer投递消息的速度远超Consumer的消费能力，会导致消费端拉消息的线程拉取了大量的消息不能及时被消费线程处理掉，造成消息堆积。 最后messageListenerConcurrently的作用貌似是监听订阅的topic发生变化后，通知用。 消费模式RocketMQ的Consumer支持集群和广播俩种消费模式，可在初始化方法中指定，消费模式用于决定Consumer订阅Broker节点中topic-queue的分配规则。 集群模式 集群模式中，消费组名称相同的Consumer实例被视为一个Consumer集群，集群内部所有Consumer实例共同承担订阅的topic，在各个Borker节点中队列的消费工作。比如现在有个名为order的topic在Broker-a和Broker-b节点中各有4个队列，并且Group_A消费组有3个Consumer在订阅，Group_B消费组有4个Consumer在订阅: 图中可以看出不同的消费组分配情况相互隔离，互不影响。同一组内的各Consumer实例按照分配策略对应一部分队列，如果总队列数正好等于Consmuer数，那么直接按一对一方式分配；如果总队列数大于Consmuer数并且是其倍数，按照一对多的方式平均分配(如上图的GROUP_B)；如果总队列数大于Consmuer数但不是其倍数，仍然按照一对多的方式，会有个别Consumer被多分配一个(如上图的GROUP_A)；如果总队列数小于Consmuer数，先将队列按一对一分配出去，剩下的Consumer不会被分配到任何队列，也就接收不到任何消息。 将多个Consumer划分到一个组内的作用是topic的消息进行分片，采用并行处理的方式提高消费能力。另外一个作用是实现消费失败重试机制，因为Consumer在进行消费时可能因为各种异常导致消费逻辑执行失败，并返回RECONSUME_LATER状态，遇到这种情况会将消息回发到Broker，然后Broker尝试重新发送。 最后，在使用集群模式进行消费时，所有消费组名称以及订阅topic的所有队列的消费进度(逻辑偏移量)，全部存储在对应的Broker节点上(上篇文章讲到的config文件夹的consumerOffset.json文件中)，Consumer不进行任何进度的存储。 广播模式 广播模式中，任何一条消息都会发送到消费组内所有Consumer进行消费。也就是说消费组内有几个Consumer实例，消息就会被处理几遍。在实现方式上较集群模式简单一些，不用考虑队列分配情况: 与集群模式不同，广播模式下的Consumer在出现消费失败时(返回RECONSUME_LATER状态)不会进行失败重投，所以使用广播模式要额外关注消费失败情况，做好应对措施，防止消费失败引起的消息丢失。另外一个不同点是，消费组内每个Consumer消费进度由自身维护，源码中是LocalFileOffsetStore类负责记录存储。 顺序消费顺序消费首先要保证Producer将顺序的消息发送到同一个Queue中，然后单个Queue只会被单个Consumer消费，这一点是由RocketMQ的分配机制保证。以上的Demo代码是使用MessageListenerConcurrently并发监听，说明白点就是Consumer即使顺序的拉取到消息，也会采用多线程并行消费消息，仍然无法保证消费的顺序。 对此RocketMQ中提供了MessageListenerOrderly来实现真正的顺序消费，实现此接口并重写ConsumeOrderlyStatus方法，其他与并行消费没区别: 123456789101112131415@Slf4j@Componentpublic class OrderReminderConsumer implements MessageListenerOrderly &#123; // 省略代码... @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; list, ConsumeOrderlyContext consumeOrderlyContext) &#123; // 消费逻辑... return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; // 省略代码...&#125; MessageListenerOrderly使用风险: 并行消费变为串行消费，降低了Consumer的消费能力 如果某条消息在消费失败时，不会将失败告诉Broker执行重试，并且队列消费暂停 消息过滤Tag、SQL92和类过滤器(新版去除) 订阅关系一致同一个消费组内的所有Consumer还需遵循订阅关系一致性原则，才能保证消息的正常消费。这个原则要求消费组内的所有Consumer订阅的topic和对应tags必须保持一致，一旦订阅关系不一致就会导致消费混乱，甚至消息丢失。 消费组的订阅信息在Broker的存储结构由ConsumerManager类的consumerTable进行维护: 12private final ConcurrentMap&lt;String/* Group */, ConsumerGroupInfo&gt; consumerTable = new ConcurrentHashMap&lt;String, ConsumerGroupInfo&gt;(1024); ConsumerGroupInfo类存储了消费组的具体结构，类内部的subscriptionTable存储的topic的订阅详情: 12private final ConcurrentMap&lt;String/* Topic */, SubscriptionData&gt; subscriptionTable = new ConcurrentHashMap&lt;String, SubscriptionData&gt;(); SubscriptionData类存储了订阅的所有规则信息: 123456789101112131415161718192021 public class SubscriptionData implements Comparable&lt;SubscriptionData&gt; &#123; //订阅所有消息 public final static String SUB_ALL = &quot;*&quot;; // 类过滤模式标记 private boolean classFilterMode = false; // topic名称 private String topic; // 订阅tags，多个可用||隔开 private String subString; // 订阅tags集合 private Set&lt;String&gt; tagsSet = new HashSet&lt;String&gt;(); // tagcode集合 private Set&lt;Integer&gt; codeSet = new HashSet&lt;Integer&gt;(); // 订阅版本时间戳 private long subVersion = System.currentTimeMillis(); // 表达式类型 private String expressionType = ExpressionType.TAG; // 构造器、hashCode、equals、getset等...&#125; 由上面结构可以看出，消费组的订阅信息是以groupName为单位进行保存。当Consumer启动后，会将自己的订阅信息(List)发送到对应的Broker中，之后还会采取心跳机制不断将这些信息刷新到Broker中。Broker以新的订阅信息为基准与本地的进行对比，该新增的新增，该删除的删除，如果topic对应的SubscriptionData已存在，则根据subVersion属性进行对比，新的覆盖旧的。也就是说如果同一组内的Consumer订阅关系不一致，会导致该组在Broker中的订阅信息会因为新Consumer的加入或者心跳机制的刷新，不断覆盖掉旧信息，那这和消费混乱有什么关系呢？ 要想搞清楚这个问题，还需要清楚Consumer是如何去Broker拉取消息的，上面的推拉模式也简单说过，推模式是将PullRequest作为参数拉取消息，那就要知道PullRequest对象内部都有什么属性: 123456789101112public class PullRequest &#123; // 消费组名 private String consumerGroup; // 消息队列对象，内部包含queueId以及topic private MessageQueue messageQueue; // 不重要 private ProcessQueue processQueue; // 拉取的坐标 private long nextOffset; // 不重要 private boolean lockedFirst = false;&#125; 到这里问题就差不多搞清楚了，Consumer在拉取消息时，根据consumerGroup和topic获取到SubscriptionData对象，也就是消费组的订阅信息。然后根据对应的queueId以及nextOffset拉取消息，并按照订阅消息配置的tags以及filter等对消息进行筛选拉取，消费完毕后提交offset。 由于同一时刻NameServer保存的订阅信息只有一份，当同一消费组内的Consumer订阅关系不一致时，与NameServer保存的信息不符合的那部分Consumer会拉取到不属于自己的消息。比如tags不一致，会拉取到别的tags，如果topic不一致，直接报the consumer’s subscription not exist错误。 消费重试Consumer端的消费失败分为俩种，一种是EXCEPTION，另一种是TIMEOUT，当Broker感知到Consumer端消费失败后，会根据不同的失败类型采取不同的措施。Consumer的消费重试机制，仅仅在集群模式中有效，广播模式不会进行消息重试。 EXCEPTIONexception是指Consumer正常接收到消息后，在进行消费处理过程中发生异常，比如要将消息的内容插入数据库，正巧此时数据库宕机，又或者消息对应数据库查询出来的数据是脏数据，导致逻辑处理走不通等。这些都会引起消费逻辑的异常，通常我们会将消息的处理代码块使用try catch包起来(上面的例子)，如果正常执行就返回CONSUME_SUCCESS，抓取到异常就返回RECONSUME_LATER。 无论如何，Broker都会收到Consumer端的消费结果情况，如果成功就更新offset，如果失败重新尝试推送，重试次数默认是16次，考虑到异常恢复起来需要一些时间，所以每次重试都有一定的时间间隔，间隔依次为1S,5S,10S,30S,1M,2M····2H。RocketMQ会为每个消费组创建一个格式为%RETRY%+consumerGroup的重试队列，对于消费失败的消息根据间隔时间将其放入延迟topic(SCHEDULE_TOPIC_XXXX)，到达延迟时间点后发送到对应的重试队列，然后再次投递到Consumer。 实际开发中也许并不需要这么多重试次数，比如只需要3次重试次数，超过这个次数就记录到数据库或缓存，然后开启定时器等扫描在处理，或者人为干涉修复。这种方式首先要在Consumer设置重试次数，然后在消费前调用MessageExt类的getReconsumeTimes()方法查看重试次数，如果超过设置次数则将消息保存到数据库或缓存，然后直接返回CONSUME_SUCCESS。 TIMEOUTTIMEOUT是指因为种种原因导致Consumer端没有及时给Broker反馈消息的处理状态，导致Broker认为消息并没有被消费掉，然后会一直发送消息。超时时间可以调用Consumer的setConsumeTimeout()方法设置，默认为15(单位分钟)。 注:超时引起的重试不受重试次数条件的影响，会无限制的发送给Consumer直到成功。 死信队列当消息遇到EXCEPTION，并达到重试次数限制后仍然未成功，消息会投递到DLQ死信队列(%DLQ%RetryConsumer)，可以在控制台进行查看: 死信队列特点： 死信队列是以%DLQ%+消费组名称进行命名，换句话说每个消费组都有自己的死信队列 消费组在未产生死信消息的情况下，不会创建死信队列 消费组的死信队列包含组内所有的topic所属的死信消息，换句话说组内订阅的topic共享一个死信队列 消息回溯回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，消息回溯就是对这种场景的支持。Consumer是基于队列的offset进行拉取消息，因此消息回溯的只需要重新指定topic和queue的offset即可，另外RocketMQ还支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。 Consumer启动重置offset在Consumer端配置中，可以通过setConsumeFromWhere(ConsumeFromWhere)方法设置启动后消费的起点offset，其中传入参数ConsumeFromWhere是个枚举类: 123456789101112131415161718192021222324252627282930313233public enum ConsumeFromWhere &#123; &#x2F;** * 一个新的订阅组第一次启动从队列的最后位置开始消费&lt;br&gt; * 后续再启动接着上次消费的进度开始消费 *&#x2F; CONSUME_FROM_LAST_OFFSET, &#x2F;** @deprecated *&#x2F; @Deprecated CONSUME_FROM_LAST_OFFSET_AND_FROM_MIN_WHEN_BOOT_FIRST, &#x2F;** @deprecated *&#x2F; @Deprecated CONSUME_FROM_MIN_OFFSET, &#x2F;** @deprecated *&#x2F; @Deprecated CONSUME_FROM_MAX_OFFSET, &#x2F;** * 一个新的订阅组第一次启动从队列的最前位置开始消费 * 后续再启动接着上次消费的进度开始消费 *&#x2F; CONSUME_FROM_FIRST_OFFSET, &#x2F;** * 一个新的订阅组第一次启动从指定时间点开始消费 * 后续再启动接着上次消费的进度开始消费 * 时间点设置参见DefaultMQPushConsumer.consumeTimestamp参数 *&#x2F; CONSUME_FROM_TIMESTAMP;&#125; 控制台重置offset进入控制台点击Topic导航栏，筛选出topic行信息后，点击REST CONSUMER OFFSET按钮，选择要重置的消费组以及回溯时间:","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(六)消息存储","slug":"RocketMQ消息存储","date":"2020-05-09T04:00:00.000Z","updated":"2021-01-07T05:31:30.750Z","comments":true,"path":"2020/05/09/RocketMQ消息存储/","link":"","permalink":"http://yoursite.com/2020/05/09/RocketMQ%E6%B6%88%E6%81%AF%E5%AD%98%E5%82%A8/","excerpt":"","text":"存储文件Broker负责存储消息、主题、对应队列等，将这些内容持久化到配置文件的store文件夹中: 当生产者通过路由信息将消息发送到Broker后，Broker先将消息写到内存中，然后通过线程刷到磁盘。刷盘方式分为同步和异步俩种方式，在配置文件的flushDiskType属性中进行设置: config此文件夹存储了Broker运行需要的各种配置信息，采用json文本形式存储配置文件以及对应的备份文件: 文件名称 解析存储类 描述 topics.json TopicConfigManager 存储每个topic的读写队列数、权限、是否顺序等信息 consumerOffset.json ConsumerOffsetManager 记录每个Consumer在每个topic上对于该topic的consumequeue队列的消费进度 consumerFilter.json ConsumerFilterManager 存储每个消费者Consumer的过滤信息 subscriptionGroup.json SubscriptionGroupManager 存储每个消费者Consumer的订阅信息 delayOffset.json ScheduleMessageService 记录对于延迟主题SCHEDULE_TOPIC_XXXX的每个consumequeue队列的消费进度 commitlog此文件夹负责存储Broker节点接收到的消息，存储消息的文件名长度为20位，以起始物理偏移量的值进行命名，如果长度不够20位则在左侧补零，每个文件的大小默认1G，也就是1073741824字节，当文件写满则创建下一个文件。比如Broker接收到第一个消息后创建00000000000000000000代表第一个文件，起始偏移量为0，当文件写满1G后，创建名为00000000001073741824的文件继续存储消息，起始偏移量为1073741824。 注:这里的偏移量是指物理偏移量(1个字节代表一个偏移量)，并非按消息数量递增的逻辑偏移量，物理偏移量用于定位某个消息在此文件中的物理位置 消息在commitlog文件中的存储格式如下: 存储结构中，各部位代表的含义: 名称 占用磁盘 描述 msgLen 4字节 消息长度，具体指整个消息体所占用的字节大小 magicCode 4字节 魔数，固定值daa320a7 bodyCRC 4字节 消息体验证码 queueId 4字节 消息体发送到了哪个MessageQueue flag 4字节 创建Message对象时由生产者通过构造器设定的flag值 queueOffset 8字节 表示在队列中逻辑的偏移量 physicalPosition 8字节 表示在存储文件中的偏移量 sysFlag 4字节 是生产者相关的信息标识 msg born timestamp 8字节 消息创建时间 msg host 8字节 消息生产者的host store timestamp 8字节 消息存储时间 store host 8字节 消息存储机器的host reconsume times 4字节 消息重复消费次数 prepare transaction offset 8字节 消息事务相关偏移量 body length 4字节 消息体的长度 msg body 不固定 消息内容 topic length 1 主题名称长度(1字节=8位，因此topic长度不会超过127) topic length 不固定 主题名称 properties lengh 不固定 Properties内容长度 properties 不固定 Properties的内容 某个Broker节点接收到的所有topic-queue消息，全部写入一个文件中(直到写满为止)，这一点与Kafka有很大不同。Kafka是以topic-partition为单位创建存储消息的文件，存储文件的分类粒度比RocketMQ要细很多，也意味着相同的业务场景，kafka节点创建存储消息的文件数量肯定会比RocketMQ节点要多，且随着节点中topic和queue/partition的激增，数量差距越来越大。 当kafka的存储文件越来越多(单机以64个partition为分水岭)，顺序写入特性会被大大破坏从而引起大量的随机I/O，吞吐量会急剧下降，而RocketMQ的这个设计，很好的避免了这个问题。 consumequeueBroker节点接收到的任何topic-queue消息都会写在commitlog文件中，并且没有规则的分布情况，如果消费者想要拉取某个topic-queue消息时，需要整体检索commitlog文件，这种方式的效率难以保障。这就需要对commitlog文件的消息建立索引来加快消息的检索，而这些索引数据就是在consumequeue文件夹进行存储。 例如现在某个Broker节点中负责订单的发货(DELIVER_PACKAGE)、到货(ARRIVAL_PACKAGE)、签收(SIGN_PACKAGE)的三个消息通知topic，每个topic都有4个队列，目录结构如下: 由此图可以看出，consumequeue目录结构的分类粒度与Kafka存储消息文件的粒度类似，只不过consumequeue目录不存储具体的消息内容，只存储路由到该queue中的消息在CommitLog中的物理偏移量(offset)、消息大小(size)、消息所属的tag的hash值(tagCode)三个属性，每条索引占用磁盘空间固定为20字节。 文件写入当Broker收到某个topic-queue消息时，先将消息写入commitlog文件中并得到物理偏移量，然后进入consumequeue目录对应的文件夹创建文件，文件名长度为20位，以起始物理偏移量的值进行命名，如果长度不够20位则在左侧补零。每个文件默认可以存储30W个消息索引，文件磁盘大小也就是60W字节，比如Broker收到某个topic-queue的第一条消息时，创建文件00000000000000000000，起始物理偏移量为0，将刚才的物理偏移量、消息大小、tag的hash值写入创建的文件中，当写满后30W条消息时创建第二个文件00000000000006000000，起始物理偏移量为60W，继续存储写入的数据。 文件读取当Broker收到Consumer的消息拉取请求时，根据topic、queueId找到对应文件夹，通过文件夹里面各文件的名称计算出存储的逻辑偏移量范围，然后根据Consumer提供的offset锁定到具体检索哪个文件。将Consumer提供的offset*20后减去文件名的数值，即可得到要查询的消息在consumequeue索引中的物理偏移量位置，往后取20字节的数据就是消息的索引信息，拿到物理偏移量去commitlog即可查询最终的消息。 consumequeue文件夹创建的文件命名虽然和commitlog同样都是物理偏移量，不过consumequeue文件存储的数据量固定，且布局有序、有固定规则，因此可以通过文件名去定位具体的物理偏移量，不会存在检索效率的问题。 indexBroker除了通过Consumer提供的offset获取消息外，还支持通过MessageID或者MessageKey查询消息。使用ID查询处理起来比较简单，因为MessageID就是根据Broker+offset生成的，因此很容易找到对应的commitlog文件来读取消息。而MessageKey由生产者自己设定，RocketMQ为了保证其查询的效率，使用index文件夹记录对应的索引信息。 index文件由IndexHeader、HashSlot、Index三部分构成: IndexHeader中存储的都是一些文件基础数据: 名称 占用磁盘 描述 beginTimestamp 8字节 该索引文件第一个消息的存储(落盘)时间 endTimestamp 8字节 该索引文件最后一个消息的存储(落盘)时间 beginPhyoffset 8字节 该索引文件第一个消息在commitlog的物理偏移量 endPhyoffset 8字节 该索引文件最后一个消息在commitlog的物理偏移量 hashSlotCount 4字节 该索引文件目前的哈希槽个数 indexCount 4字节 该索引文件目前已存储的索引数量 HashSlot负责对索引内容进行分片:消息在进行index存储时，通过消息key的哈希值%500W定位哈希槽(貌似500W这个值可以修改)，因此可以理解为一个index文件的哈希槽最多500W个，另外IndexHeader与HashSlot的大小都是固定的，再文件中的位置不需要额外标记，可以直接定位获取。 其中每个哈希槽固定占有4字节，仅仅用来存储当前卡槽最后一个key在index部分的逻辑位置(整个索引文件index区域中第几个写入的)，这么做的目的仍然是节省磁盘空间，如果直接存储物理偏移量需要8个字节，这里四个字节就够了，因为IndexHeader与HashSlot的大小是固定的，每个索引数据在整个index的物理偏移量为: IndexHeader大小(40字节) + hashSlot大小(4字节) * 数量(500w) + 逻辑位置 * 每个index大小(20字节) Index存储真正的索引信息: 名称 占用磁盘 描述 key hash value 4字节 消息key的哈希值 phyOffset 8字节 消息在commitlog的物理偏移量(索引的核心数据) timeDiff 4字节 消息落盘时间与IndexHeader中的beginTimestamp的差值(节省磁盘空间，如果直接存储落盘时间就需要占用8字节) prevIndex 4字节 哈希槽的第一个索引prevIndex=0，后续的索引prevIndex=前一个索引的物理偏移量 索引文件创建过程:当Broker接收到消息后，先将消息写入commitlog文件中并得到物理偏移量，然后进入index文件夹查询最新创建的索引文件，如果此索引文件的IndexHeader的indexCount等于2000W则表示已满，获取当前时间戳作为名称创建新的索引文件，如果小于2000W直接进入写文件环节。 获取消息key的哈希值并%500W计算出卡槽号，如果此卡槽存储的值为0，表示目前下面还没有存储索引，写入索引数据(其中prevIndex=0)，如果卡槽存储的值不为0，通过卡槽值计算出索引数据所在的物理偏移量并取出，然后将新的索引数据写入文件(其中prevIndex=当前卡槽值)，然后刷新卡槽值为当前索引数据的逻辑位置(整个索引文件index区域中第几个写入的)，其实就是类似HashMap的数组+链表。 消息key查询过程:查询的传入值除了key外，还包含一个时间起始值以及截止值(这玩意在控制台貌似不需要?)，时间范围参数用于定位具体的索引文件，根据消息key的哈希值锁定具体的卡槽。通过卡槽值计算出最后一个索引数据在索引文件中的物理偏移量并取出，紧接着通过prevIndex属性递归遍历，再加上时间范围与timeDiff属性对比筛选，得出符合条件的phyOffset属性集合，去commitlog捞消息。由于key的hash相同，内容不一定相同，所以在捞消息的时候还要对key的内容进行筛选。 abort文件Broker启动时会在store目录创建此文件，在正常退出后会删除此文件。如果Broker在启动时发现store目录中发现abort文件存在，那么说明上次服务退出属于异常退出(宕机或者手动kill进程等)，异常退出会导致部分文件的写入逻辑没有执行完就被打断(比如某条消息只写入一半)，造成脏数据影响后续的解析。 lock这叼毛文件完全搜不到是干啥的 checkpointcheckpoint文件的作用是记录commitlog、consumequeue、index最后一次刷盘时间，此文件固定长度为4k。但是Broker仅仅使用了前24个字节，这24个字节按照8字节为单位划分为三部分，使用16进制数字表示上述的三个刷盘时间戳。 使用文本打开此文件，内容如下: 删除策略每个Broker节点存储的文件都会随着时间的推移不断增长，CommitLog、ConsumeQueue文件是基于文件内存映射机制，并且在启动的时候会将所有的文件加载，为了避免内存与磁盘的浪费、能够让磁盘能够循环利用、避免因为磁盘不足导致消息无法写入等引入了文件过期删除机制。 RocketMQ采用定时器扫描方式执行删除策略，并且在删除过程中不会关心消息是否被消费，删除策略在以下任一条件成立的情况才会执行批量删除: 消息文件过期(默认72小时)，且到达清理时点(默认是凌晨4点)，删除过期文件。 消息文件过期(默认72小时)，且磁盘空间达到了水位线(默认75%)，删除过期文件。 磁盘已经达到必须释放的上限(85%水位线)的时候，则开始批量清理文件(无论是否过期)，直到空间充足。 注：若磁盘空间达到危险水位线（默认90%），出于保护自身的目的，broker会拒绝写入服务。 高性能存储整个RocketMQ集群服务的本质是进行消息发送与消费，Producer发送消息到Broker端并进行磁盘写入，Consumer发送请求到Broker端并进行磁盘读取，也就是说RocketMQ的工作与磁盘数据的读写息息相关。上述的commitlog、consumequeue、index是在磁盘的存储结构上进行优化，除此之外，RocketMQ设计者们还从磁盘的读写层面进行了性能优化。 磁盘读过程 寻道 : 磁头移动定位到指定磁道，这部分时间代价最高 旋转延迟 : 在磁道位置确定后，中轴带动盘面旋转到合适的扇区开头处 数据传输 : 表示盘面继续转动，读取数据并传送到内存 顺序与随机读写对于磁盘的读写分为两种模式，顺序读写和随机读写。随机读写存在一个多次寻址的过程，而顺序读写相当于有一个物理索引，在读取的时候不需要寻找地址，因此顺序读写相对于随机读写，效率很高。 RocketMQ与Kafka在进行消息持久化时，都采用追加的方式写入磁盘文件(顺序写入)。Consumer在进行消费时，也是对磁盘文件进行顺序读取，每次要读取的数据在磁盘的位置，正好都在上次的后面，因此不需要寻道，移动到扇区开头处后直接进行数据传输，可以理解为RocketMQ与Kafka的顺序写入保证了顺序读取。 PageCache当操作系统的运行内存有大量剩余时，为了提高IO的性能，会将多余的内存抽取出来作为文件的缓存使用。操作系统将文件按大小切割为多个数据块，并放入PageCache中进行缓存。 当Broker进行文件写入时，操作系统只是将数据写入PageCache中，并采用异步方式将PageCache写入的数据刷盘到磁盘中，也就是说文件写入磁盘是纯内存操作的，内存IO相对于磁盘IO来说，效率提升很多。这也带来了一定的风险，写入PageCache的数据如果未来得及同步到磁盘就发生宕机，会导致这部分数据丢失，因此RocketMQ在Broker端配置文件中可以自己选择同步或者异步刷盘方式，效率与可靠性由开发者自己权衡，而kafka直接不支持同步刷盘(太奔放了)。 当Broker进行文件读取时，首先去PageCache中查询要操作的文件内容是否存在，如果存在则直接读取并返回，如果不存在则需要启动磁盘IO，读取完毕后将内容加入PageCache中，除了读取查询需要的数据外，操作系统还会往后预读取若干(至少1个，通常3个)页数据一并放入PageCache中，这么做的目的就是尽量减少磁盘IO的次数，尽量提高PageCache的命中率。如果保证多数情况下对文件都是顺序读取，配合PageCache的预读取，可以保证请求几乎都命中PageCache，大大提升文件读取的执行效率。 PageCache机制是牺牲可靠性(宕机引发数据丢失)的前提下，尽量将磁盘IO转化为内存IO从而提高执行效率，这种机制虽然是操作系统层面的优化，但是RocketMQ顺序读写完美契合了PageCache，使其发挥出优越的性能。 如果某Broker端负责的topic不多且Consumer消费进度几乎一致，那么PageCache在缓存数据很小的情况下依然能极大提高效率。如果topic数量极多且各Consumer消费进度完全不一致，那么PageCache缓存的数据也会激增，一旦超出PageCache所能承受的极限，会导致后续的磁盘IO无法缓存引发随机读写，性能并不能达到满意的效果。 零拷贝 以Linux系统为例，当A服务器需要读取B服务器的磁盘数据时，B服务器默认采用操作系统提供的read()、write()函数进行读取并传输，在此过程中涉及到四个步骤: 1.用户态切换到内核态，操作系统调用read()函数，将磁盘数据copy到内核缓冲区，此过程由MDA完成。 2.将内核缓冲区数据copy到用户缓冲区，内存之间的数据拷贝需CPU协助完成，copy完毕后内核态切回用户态。 3.用户空间的数据如果需要网络传送到其他服务器，需要调用write()函数，此时用户态切换到内核态，然后将用户缓冲区数据copy到内核socket发送缓冲区，涉及到内存之间的数据copy，仍然需CPU协助完成。 4.最后socket缓冲区数据需要复制到网卡缓冲区中，此操作由MDA完成，复制完毕后由网卡发送到客户端，然后CPU状态切回用户态。 步骤流程图: 整个过程涉及4次数据的copy、2次CPU调度、4次内核用户态的切换，频繁的数据复制以及内核/用户态的切换对系统开销非常大，因此便产生了零拷贝技术。零拷贝技术的思想是减少CPU调度和内核用户态切换的次数，实现方式分为mmap、sendfile等。 mmap通过虚拟内存映射，让多个虚拟地址指向同一个物理内存地址，用户空间通过映射关系共享内核空间的数据，内核缓冲区数据copy到用户缓冲区的步骤可以省略，这样从PageCache到网卡的传输就省掉了1次CPU调度、2次内核用户态切换: sendfile直接没有用户态进行参与，也不需要将数据拷贝到用户缓冲区，相比较mmap又少了一次CPU调度: mmap适合操作小块数据量，sendfile适合操作大块数据量，RocketMQ选择mmap方式，而Kafka选择sendfile方式，至于区别暂时没找到...","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(五)生产端","slug":"RocketMQ生产端","date":"2020-05-07T05:00:00.000Z","updated":"2020-12-21T12:25:35.069Z","comments":true,"path":"2020/05/07/RocketMQ生产端/","link":"","permalink":"http://yoursite.com/2020/05/07/RocketMQ%E7%94%9F%E4%BA%A7%E7%AB%AF/","excerpt":"","text":"springboot集成RocketMQ依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;&#x2F;groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;&#x2F;artifactId&gt; &lt;version&gt;4.7.0&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; application.properties 1234567891011121314151617# 服务端口server.port&#x3D;8082# 生产者分组rocketmq.producer.groupName&#x3D;GROUP_A# MQ注册中心地地址rocketmq.producer.namesrvAddr&#x3D;localhost:9876# 消息最大长度 默认 1024 * 4 (4M)rocketmq.producer.maxMessageSize &#x3D; 4096# 发送消息超时时间，默认 3000rocketmq.producer.sendMsgTimeOut&#x3D;3000# 发送消息失败重试次数，默认2rocketmq.producer.retryTimesWhenSendFailed&#x3D;2 将生产者注册到IOC 123456789101112131415161718192021222324252627282930313233343536@Configurationpublic class RocketMQProducerConfig &#123; @Value(&quot;$&#123;rocketmq.producer.groupName&#125;&quot;) private String groupName; @Value(&quot;$&#123;rocketmq.producer.namesrvAddr&#125;&quot;) private String namesrvAddr; @Value(&quot;$&#123;rocketmq.producer.maxMessageSize&#125;&quot;) private Integer maxMessageSize; @Value(&quot;$&#123;rocketmq.producer.sendMsgTimeOut&#125;&quot;) private Integer sendMsgTimeOut; @Value(&quot;$&#123;rocketmq.producer.retryTimesWhenSendFailed&#125;&quot;) private Integer retryTimesWhenSendFailed; /** * RocketMQ生产者对象 */ @Bean public DefaultMQProducer defaultProducer() throws MQClientException &#123; DefaultMQProducer producer = new DefaultMQProducer(groupName); producer.setNamesrvAddr(namesrvAddr); producer.setVipChannelEnabled(false); producer.setMaxMessageSize(maxMessageSize); producer.setSendMsgTimeout(sendMsgTimeOut); producer.setRetryTimesWhenSendAsyncFailed(retryTimesWhenSendFailed); producer.start(); return producer; &#125;&#125; 路由选择DefaultMQProducer类提供了fetchPublishMessageQueues方法，可以查看当前Producer从NameServer同步过来的topic路由信息: 1List&lt;MessageQueue&gt; messageQueueList = producer.fetchPublishMessageQueues(&quot;TEST_TOPIC&quot;); Producer向某个topic发送消息时，如果从NameServer同步的路由信息中发现，此topic在多个Broker中都存在队列，那么就需要依靠某种策略从中选择一个进行发送，这个策略由MQFaultStrategy类的selectOneMessageQueue方法实现: 1234567891011121314151617181920212223242526public MessageQueue selectOneMessageQueue(String lastBrokerName) &#123; // 如果上次发送的brokerName为空，直接轮询 if (lastBrokerName == null) &#123; return this.selectOneMessageQueue(); &#125; else &#123; // 对messageQueueList进行轮询选取 int index = this.sendWhichQueue.getAndIncrement(); for(int i = 0; i &lt; this.messageQueueList.size(); ++i) &#123; int pos = Math.abs(index++) % this.messageQueueList.size(); if (pos &lt; 0) &#123; pos = 0; &#125; // 如果此次轮询到的MessageQueue对应的Broker节点没任何问题，直接返回 MessageQueue mq = (MessageQueue)this.messageQueueList.get(pos); if (!mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125; // 直接轮询 return this.selectOneMessageQueue(); &#125;&#125; Producer采用轮询的方式发送消息，每次发送消息时调用无参的selectOneMessageQueue()方法，这个方法就是一个单纯的轮询策略。只是消息并不能保证每次都会发送成功，如果发送失败并且设置了重试次数，那么Producer会调用有参的selectOneMessageQueue()方法，将发送失败的Broker名称作为参数传进去，并且此次轮询会忽略掉这个Broker名称。 当消息经过重试发送成功后，有问题的Broker并没有被记录下来，这就导致下次发送消息时并不会知晓这个Broker有问题，仍然在轮询策略的选择范围内，仍然有发送失败的情况出现。想要避免此问题，就需要开启延迟故障。 延迟故障延迟故障功能通过创建Producer时调用setSendLatencyFaultEnable(true)开启(默认false)，开启后对于高延迟、有故障的Broker都会记录下来，并且根据故障的严重程度，给予一段不可用的时间。具体的规则维护在MQFaultStrategy类的俩个数组中: 12private long[] latencyMax = new long[]&#123;50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L&#125;;private long[] notAvailableDuration = new long[]&#123;0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L&#125;; latencyMax数组元素表示各种延迟的时间，notAvailableDuration数组元素表示各种不可用时间，这俩个数组的同一个下坐标对应的值就是延迟时间对应的惩罚时间。由此可以看到100ms以内的延迟都是正常的，其余的规定时间内会排除掉，从正常的Broker中轮询获取。 如果在极端的情况，所有的Broker延迟都高于100，都被视为故不可用的故障节点，这段时间的消息发送如何处理呢。RocketMQ提供了pickOneAtLeast()方法，从故障Broker列表中选择最优的一个，也就是俗话矮子里面拔将军: 1234567891011121314151617181920212223242526272829public String pickOneAtLeast() &#123; final Enumeration&lt;FaultItem&gt; elements = this.faultItemTable.elements(); List&lt;FaultItem&gt; tmpList = new LinkedList&lt;FaultItem&gt;(); // 先把故障的broker列表复制一份，后面好做打乱 while (elements.hasMoreElements()) &#123; final FaultItem faultItem = elements.nextElement(); tmpList.add(faultItem); &#125; // 打乱该列表 if (!tmpList.isEmpty()) &#123; Collections.shuffle(tmpList); // 排序 Collections.sort(tmpList); // 从前50%里面递增选取一个 final int half = tmpList.size() / 2; if (half &lt;= 0) &#123; return tmpList.get(0).getName(); &#125; else &#123; final int i = this.whichItemWorst.getAndIncrement() % half; return tmpList.get(i).getName(); &#125; &#125; return null;&#125; 从故障Broker列表中按照规则排序，然后从前半部分中轮询获取一个作为发送的目的地，因此重点在于排序规则，这就需要查看FaultItem类重写的排序方法了: 1234567891011121314151617181920212223242526public int compareTo(final FaultItem other) &#123; // 可用的笔不可用的优先级高 if (this.isAvailable() != other.isAvailable()) &#123; if (this.isAvailable()) return -1; if (other.isAvailable()) return 1; &#125; // 延迟低的比延迟高的优先级高 if (this.currentLatency &lt; other.currentLatency) return -1; else if (this.currentLatency &gt; other.currentLatency) &#123; return 1; &#125; // 被惩罚时间早的比晚的优先级高 if (this.startTimestamp &lt; other.startTimestamp) return -1; else if (this.startTimestamp &gt; other.startTimestamp) &#123; return 1; &#125; return 0; &#125; 这里并没有将选择结果固定为排序规则中最好的那个，主要是为了避免topic的消息聚集在一个Broker的队列中造成负担过重，负载均衡到所有故障Broker又失去了故障延迟的初衷，因此选择折中的方式，将前50%的节点采用轮询方式进行负载均衡。 发送方式同步发送 同步发送消息时，线程进入阻塞状态，直到发送完毕返回SendResult类 如果发送失败，会在默认的超时时间进行重试，最多重试俩次 返回SendResult类，并不代表发送成功，需要根据sendStatus来判断是否成功 可以根据返回的结果作相应处理，因此理论上不会出现消息丢失(可靠) 12345678// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;ORDER_REMINDER&quot;, &quot;LOGISTICS&quot;, message.getBytes());// 同步发送SendResult sendResult = producer.send(sendMsg); 异步发送 异步调用不存在返回值，投递的结果信息SendResult类在成功回调onSuccess()方法中 异步发送没有retry机制，投递失败回调onException()方法 异步调用主要请求耗时过长，或者对响应时间过于敏感的请求，比如大数据量的excel导入，选择用户群体后批量推送消息等 可以根据onSuccess()方法返回的结果作相应处理，因此理论上不会出现消息丢失(可靠) 1234567891011121314151617// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;TEST_TOPIC&quot;, &quot;tag&quot;, message.getBytes());// 异步发送producer.send(sendMsg, new SendCallback()&#123; @Override public void onSuccess(SendResult sendResult) &#123; // 发送成功回调逻辑 &#125; @Override public void onException(Throwable e) &#123; // 发送失败回调逻辑 &#125;&#125;); 单向发送 单向发送仅仅处理消息的发送，由于发送是否成功无法知晓，因此有几率造成数据丢失(不可靠) 优点在于发送消息的耗时非常短，一般在微秒级别 12345678// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;TEST_TOPIC&quot;, &quot;tag&quot;, message.getBytes());// 单向发送producer.sendOneway(sendMsg); 发送特点顺序发送Producer将消息发送到Broker节点后，Broker会找到对应的队列文件，并采用追加的方式将消息内容写入文件中，可以理解为RocketMQ可以保证队列级别的消息顺序。因此我们只需要将同一类数据发送到同一个队列中，就可以保证消息的顺序发送，Consumer在进行消费时也就毫无悬念的顺序消费了。 最常见的顺序消费场景就是使用canal或maxwell来订阅Mysql数据库的Binlog，同一条数据会产生多条操作日志，如果不做任何措施可能会导致Insert日志和Update日志被投递到不同的Broker中，这就有很大几率出现Update日志抢先在Insert日志处理前被消费处理，造成数据不一致的情况。对此最常见的解决方案是提取消息的业务唯一标示(比如id等)，和队列长度取余运算定位需要发送的Broker的节点进行发送。 12345678910111213141516171819// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;TEST_TOPIC&quot;, &quot;tag&quot;, message.getBytes());// 假设此binlog消息的主键id为666Long id = 666L;// 顺序发送SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; // arg的值就是send方法第三个参数(id)的值 Long id = (Long) arg; // mqs为此Producer从注册中心拿到的，需要发送 int index = id % mqs.size(); return mqs.get(index); &#125;, id);&#125; 延迟发送延迟消息的使用场景很多，例如电商系统的订单业务场景，用户下单后发送一个30分钟的延迟消息，30分钟后Consumer会收到此消息，然后检查订单是否已付款，如果未付款执行自动取消逻辑处理。 12345678910// 生产者对象@Autowiredprivate DefaultMQProducer producer;// 创建消息对象Message sendMsg = new Message(&quot;TEST_TOPIC&quot;, &quot;tag&quot;, message.getBytes());// 设置延迟级别sendMsg.setDelayTimeLevel(2);// 延迟发送SendResult sendResult = producer.send(sendMsg); RocketMQ商业版本支持任意精度的延迟消息，而开源版本仅仅支持18个特定时间的延迟功能，通过setDelayTimeLevel()方法进行控制，具体的延迟等级与延迟时间的对应关系如下: 延迟等级 延迟时间 1 1秒 2 5秒 3 10秒 4 30秒 5 1分钟 6 2分钟 7 3分钟 8 4分钟 9 5分钟 10 6分钟 11 7分钟 12 8分钟 13 9分钟 14 10分钟 15 20分钟 16 30分钟 17 1小时 18 2小时 Producer发送延迟消息时，消息首先会被投递到名为SCHEDULE_TOPIC_XXXX的topic中，这个topic是集群自动创建的，可以在控制台的Topic页面中勾选SYSTEM进行REFRESH查询，点开此topic的路由信息可以看到每个Broker节点都负责此topic的18个读写队列。 Producer会根据延迟等级值来决定将消息发送到SCHEDULE_TOPIC_XXXX的哪个队列号中，紧接着将真实的topic和queueId设置到Message的propertiesString属性中，然后选择一个Broker进行发送。每个Broker的SCHEDULE_TOPIC_XXXX的每个queue，都会对应一个定时器去刷新，是否有到达时间需要被发送的消息，若有就从propertiesString取出真实的topic和queueId发送出去。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(四)主题创建","slug":"RocketMQ主题创建","date":"2020-05-05T05:00:00.000Z","updated":"2020-12-19T07:55:50.337Z","comments":true,"path":"2020/05/05/RocketMQ主题创建/","link":"","permalink":"http://yoursite.com/2020/05/05/RocketMQ%E4%B8%BB%E9%A2%98%E5%88%9B%E5%BB%BA/","excerpt":"","text":"自动创建topic在默认情况下支持自动创建，开关由配置文件的autoCreateTopicEnable(默认true)属性决定，在项目启动后存储在BrokerConfig类中。如果某个Broker的自动创建设置为true，则Broker在启动后会在topicManager中创建名为TBW102的topic并向所有NameServer进行注册。 当Producer向某个topic投递消息时，首先会访问NameServer获取此topic的路由列表，这里假设此topic之前并没有被创建，那么得到的将是一个空列表，Producer会再次访问NameServer获取名为TBW102的topic的路由列表，如果整个集群中没有任何Broker支持自动创建，那么这个路由列表仍然是空的，此时会抛出No route info of this topic异常，如果集群中存在支持自动创建的Broker，那么就返回这些Broker的路由信息。 Producer拿到TBW102的路由列表后，会从中选择(默认轮询)一个Broker进行投递，Broker接收到此消息后会调用msgCheck方法对topic进行校验，先去topicConfigTable中查询此topic是否存在，在目前讨论的场景下是肯定不存在的，那么会以这个不存在的tpoic名称创建一个TopicConfig。这个类包含了topic的具体信息包括队列数、读写权限、同步/异步复制等，基本上沿用TBW102的属性，创建完毕后存入topicConfigTable中，然后将topicConfigTable中的所有数据同步到NameServer中。 topic自动创建流程图: 流程图可以看出，自动创建的topic仅仅在消息投递到的Broker节点中生成queue，一旦刷回注册中心，此topic的负载均衡能力就被固定(排除手动修改的情况)。如果某一时刻不存在的topic被多个Producer同时投递，且集群中支持自动创建的Broker节点数量还算可观，考虑到从投递消息开始直到刷回注册中心这段时间的并发情况，可能会有多个Broker都被分配此topic的queue，此topic仍然有很可观的并行执行能力。 这里换一种假设，不存在的topic第一次被Producer投递时，没有其他Producer同时进行，导致此topic仅仅分配在某一个Broker中。这就相当危险了，并行能力太差，如果消息量上来很容易造成积压。说这么多就是想表达自动创建的topic的配置信息，因为场景的不确定性很难达到理想值，因此在生产环境中最好关闭自动创建，所有topic都由开发人员根据业务场景主观判断并创建。 手动创建topic的手动创建可以通过linux命令来实现，也可以在console页面进行操作，命令操作相对于页面来说较麻烦一些，并且生产环境除非运维基本上不会有访问服务器的权限，所以这里只写控制台如何创建。 topic在控制台的创建界面: clusterName与BROKER_NAME clusterName与BROKER_NAME选项必须填写一个，用于指定topic在哪些Broker节点上创建。如果仅填写clusterName选项(支持多选)，则选中的集群所属Broker节点都会创建此topic信息，这种方式也叫集群创建。如果仅填写BROKER_NAME选项(支持多选)，则只在选中的Broker节点中创建，这种方式也叫Broker创建。如果俩个有存在选项值，则取并集。 writeQueueNums(写队列数)此参数决定了在每个选中的Broker节点中创建的队列数量，比如写队列数的值为4，在topic被创建后，涉及到的每个Broker对应的consumequeue文件夹下都会创建0、1、2、3四个文件夹(懒创建方式，只有消息投递到此文件夹才会被创建)，每个Producer启动后，都会从NameServer中获取到所有Broker的0、1、2、3号队列的路由信息，进行轮询投递消息。 readQueueNums(读队列数)此参数决定某个Broker负责的某个topic，同一个组内最多可连接的消费者数，在集群正常运行期间此参数似乎没有存在的意义。假设某个Broker上的写队列数是4，那么涉及到的每个Broker节点中都会创建0、1、2、3四个队列。如果设置的读队列数小于写队列数(比如3)，那么同一组内的Consumer只会从NameServer拿到1、2、3三个队列的路由信息，队列号3永远无法被消费。如果设置的读队列数大于写队列数(比如5)，由于一个队列在同一时刻只会被一个消费者连接(不考虑消费组不同和广播消费模式的情况)，即使启动了5个消费者，仍然只有4个消费者可以正常工作，多出来的那个消费者不会被分配任何路由信息，即使启动也没有意义。 扩容与缩容按照上述的理论，writeQueueNums小于readQueueNums情况下最多造成资源浪费，大于readQueueNums情况下则会导致个别队列无法被Consumer连接消费，造成严重的消息堆积问题，writeQueueNums与readQueueNums的值只有保持一致才是合理的，为什么不将俩个参数选项合并为一个呢? 其实这么设计的目的是方便队列的缩容与扩容，思考一个问题，假设某个topic在每个Broker上创建了128个队列，如果在用户无感知的情况下缩小到64个，或者扩容到256个？ 水平扩容关于扩容，可以先将读队列数修改为256，修改后触发再均衡，将队列重新分配给所有Consumer，并且此时队列号128-155虽然分配了Consumer，但是不会有任何消息进入，因为写队列数仍然是128，Producer投递消息只会路由队列号0-127。然后修改写队列数为256，Producer从NameServer获取到最新的关于此topic的路由信息变为0-255，后续投递消息就会覆盖到扩容的队列，供Consumer进行消费。 水平缩容关于缩容，可以先将写队列数修改为64，修改后会触发再均衡，将队列重新分配给所有Consumer，并且此时队列号64-127不会被路由到任何Producer，也就是说这些队列不会接收到新消息。由于读队列还是128，仍然可以继续消费队列号64-127的消息。直到队列号64-127全部消费完毕后(通过控制台查看)，修改读队列的值与写队列保持一致，Producer从NameServer获取到最新的关于此topic的路由信息变为0-63，后续不会对64-127号队列投递消息。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(三)注册中心","slug":"RocketMQ注册中心","date":"2020-05-04T05:00:00.000Z","updated":"2021-01-20T04:42:10.504Z","comments":true,"path":"2020/05/04/RocketMQ注册中心/","link":"","permalink":"http://yoursite.com/2020/05/04/RocketMQ%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83/","excerpt":"","text":"前言高可用性NameServer作为一个十分重要的核心组件，在整个RockteMQ集群运作过程中发挥着重要作用，NameServer服务一旦宕机，整个集群就无法正常运转，因此一定要集群部署，这样才能保证高可用性。NameServer在CAP理论中强调AP，仅保证最终一致性，集群各节点彼此之间互不通信，也就是某一刻NameServer节点之间的数据并不完全相同，但这对消息发送不会造成任何影响。 路由信息在RocketMQ源码中，namesrv模块的org.apache.rocketmq.namesrv.routeinfo.RouteInfoManager类负责存储Broker集群各节点注册的路由信息: HashMap&lt;String, List&gt; topicQueueTable此变量以topic为单位，记录对应的所有队列信息，因为一个topic的数据可以分散到多个Broker中，所以topic与QueueData集合是一对多的关系，QueueData类数据结构: 123456789101112public class QueueData implements Comparable&lt;QueueData&gt; &#123; &#x2F;&#x2F; 队列所属的Broker名称 private String brokerName; &#x2F;&#x2F; 读队列数量 private int readQueueNums; &#x2F;&#x2F; 写队列数量 private int writeQueueNums; &#x2F;&#x2F; Topic的读写权限(2是写 4是读 6是读写) private int perm; &#x2F;&#x2F; 同步复制还是异步复制标记 private int topicSynFlag;&#125; HashMap&lt;String, BrokerData&gt; brokerAddrTable此变量以Broker名称为单位，记录对应的所有主从节点信息，Broker名称与主从节点也是一对多的关系，不过主从节点集合被设计到BrokerData类中: 12345678public class BrokerData implements Comparable&lt;BrokerData&gt; &#123; &#x2F;&#x2F; 所属集群名称 private String cluster; &#x2F;&#x2F; broker名称 private String brokerName; &#x2F;&#x2F; key为节点id，value为节点地址端口 private HashMap&lt;Long, String&gt; brokerAddrs;&#125; HashMap&lt;String, Set&gt; clusterAddrTable此变量以Broker集群名称为单位，记录每个集群对应的Broker名称集合。 brokerLiveTable此变量以Broker地址端口为单位，记录每个Broker的实时信息，与BrokerLiveInfo类是一对一的关系: 12345678910class BrokerLiveInfo &#123; &#x2F;&#x2F; 上次心跳时间戳 private long lastUpdateTimestamp; &#x2F;&#x2F; 数据版本 private DataVersion dataVersion; &#x2F;&#x2F; 长连接通道 private Channel channel; &#x2F;&#x2F; Ha地址 private String haServerAddr;&#125; HashMap&lt;String, List&gt; filterServerTable此变量以Broker地址端口为单位，记录每个Broker的消费者在进行消费时的过滤逻辑，后续会详细讲。 由clusterAddrTable的结构可以判断，一个注册中心集群可以包含多个Broker集群，同一个Broker名称可以出现在多个不同的Broker集群中。 不过我发现了一个奇怪的问题，我有一个名称为lvt-cluster的集群，内部有个broker-a的Broker，然后在test-cluster集群中也用broker-a这个名称启动了一个Broker，控制台能看到这俩个Broker，当我使用kill杀死test-cluster集群中的broker-a时，在控制台仍然存在，然后我又kill掉lvt-cluster集群中的broker-a，俩个Broker在控制台都消失了。再次启动lvt-cluster集群中的broker-a，又出现了2个Broker，直到我重启注册中心集群，才回归正常。 服务注册Broker在启动的时候，会向NameServer注册自己的服务信息，由于NameServer支持集群部署，并且集群中各节点之间没有任何数据交互。因此每个Broker节点启动时，会获取NameSever的地址列表(乱序)，采用遍历列表的方式向每一个NameServer节点注册自己的信息。 启动并注册完毕后，Broker会启动一个定时任务，每隔30s定时向NameServer进行心跳更新。无论是启动时注册，还是心跳注册，NameServer接收到注册信息都不会持久化到本地，而是保存在上述的各个map中。 源码中Broker是通过NamesrvStartup类的main方法启动，main方法先是创建了一个BrokerController，然后调用其start()方法，在该方法中有如下代码: 1234567891011121314151617181920212223if (!messageStoreConfig.isEnableDLegerCommitLog()) &#123; startProcessorByHa(messageStoreConfig.getBrokerRole()); handleSlaveSynchronize(messageStoreConfig.getBrokerRole()); &#x2F;&#x2F; 重点在这里 this.registerBrokerAll(true, false, true);&#125;&#x2F;&#x2F; 开启定时任务 this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; try &#123; &#x2F;&#x2F; Broker会每隔30s向NameSrv注册并更新自身topic信息,完成心跳功能 BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister()); &#125; catch (Throwable e) &#123; log.error(&quot;registerBrokerAll Exception&quot;, e); &#125; &#125; &#x2F;&#x2F; 定时器延迟10秒后开始运行，间隔时间用函数绕了一圈，其实就是1000*30，单位毫秒 &#125;, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS); Broker的服务注册逻辑全部包含在BrokerController类的registerBrokerAll方法中，此方法并没有真正去处理注册的事情，而是委托doRegisterBrokerAll方法来处理，doRegisterBrokerAll也没有亲自去进行注册，而是委托内部的BrokerOuterAPI类的registerBrokerAll方法来处理: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public List&lt;RegisterBrokerResult&gt; registerBrokerAll( final String clusterName, final String brokerAddr, final String brokerName, final long brokerId, final String haServerAddr, final TopicConfigSerializeWrapper topicConfigWrapper, final List&lt;String&gt; filterServerList, final boolean oneway, final int timeoutMills, final boolean compressed) &#123; &#x2F;&#x2F; 使用内部类remotingClient获取NameServer集群中所有节点的IP地址 final List&lt;RegisterBrokerResult&gt; registerBrokerResultList &#x3D; Lists.newArrayList(); List&lt;String&gt; nameServerAddressList &#x3D; this.remotingClient.getNameServerAddressList(); &#x2F;&#x2F; 如果获取的集合不为空 if (nameServerAddressList !&#x3D; null &amp;&amp; nameServerAddressList.size() &gt; 0) &#123; &#x2F;&#x2F; 将Broker自身的各种信息写入requestHeader中 final RegisterBrokerRequestHeader requestHeader &#x3D; new RegisterBrokerRequestHeader(); requestHeader.setBrokerAddr(brokerAddr); requestHeader.setBrokerId(brokerId); requestHeader.setBrokerName(brokerName); requestHeader.setClusterName(clusterName); requestHeader.setHaServerAddr(haServerAddr); requestHeader.setCompressed(compressed); &#x2F;&#x2F; 将Broker的topic配置信息、过滤信息写入requestBody中 RegisterBrokerBody requestBody &#x3D; new RegisterBrokerBody(); requestBody.setTopicConfigSerializeWrapper(topicConfigWrapper); requestBody.setFilterServerList(filterServerList); &#x2F;&#x2F; 转码 final byte[] body &#x3D; requestBody.encode(compressed); final int bodyCrc32 &#x3D; UtilAll.crc32(body); requestHeader.setBodyCrc32(bodyCrc32); &#x2F;&#x2F; 使用CountDownLatch机制 并行注册 final CountDownLatch countDownLatch &#x3D; new CountDownLatch(nameServerAddressList.size()); for (final String namesrvAddr : nameServerAddressList) &#123; brokerOuterExecutor.execute(new Runnable() &#123; &#x2F;&#x2F; 省略... &#125;); &#125; &#x2F;&#x2F; 进入超时等待 try &#123; countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; &#125; &#125; return registerBrokerResultList;&#125; Broker将需要注册的信息整理好发送后，我们再来看看NameServer是如何接收的，这部分逻辑在RouteInfoManager类的registerBroker方法中: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115public RegisterBrokerResult registerBroker( final String clusterName, final String brokerAddr, final String brokerName, final long brokerId, final String haServerAddr, final TopicConfigSerializeWrapper topicConfigWrapper, final List&lt;String&gt; filterServerList, final Channel channel) &#123; &#x2F;&#x2F; 创建返回值 RegisterBrokerResult result &#x3D; new RegisterBrokerResult(); try &#123; try &#123; &#x2F;&#x2F; 加锁 this.lock.writeLock().lockInterruptibly(); &#x2F;&#x2F; 获取Broker所属集群名称 Set&lt;String&gt; brokerNames &#x3D; this.clusterAddrTable.get(clusterName); &#x2F;&#x2F; 初始化或保存Broker的集群名称 if (null &#x3D;&#x3D; brokerNames) &#123; brokerNames &#x3D; new HashSet&lt;String&gt;(); this.clusterAddrTable.put(clusterName, brokerNames); &#125; brokerNames.add(brokerName); &#x2F;&#x2F; 默认此Broker名称不是第一次注册 boolean registerFirst &#x3D; false; &#x2F;&#x2F; 获取Broker名称对应的所有节点(主从)信息 BrokerData brokerData &#x3D; this.brokerAddrTable.get(brokerName); &#x2F;&#x2F; 如果broker名称是第一次注册，初始化并标记 if (null &#x3D;&#x3D; brokerData) &#123; registerFirst &#x3D; true; brokerData &#x3D; new BrokerData(clusterName, brokerName, new HashMap&lt;Long, String&gt;()); this.brokerAddrTable.put(brokerName, brokerData); &#125; &#x2F;&#x2F; 获取当前broker的所有主从节点Map&lt;brokerId, IP:PORT&gt; Map&lt;Long, String&gt; brokerAddrsMap &#x3D; brokerData.getBrokerAddrs(); &#x2F;&#x2F; 遍历 Iterator&lt;Entry&lt;Long, String&gt;&gt; it &#x3D; brokerAddrsMap.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;Long, String&gt; item &#x3D; it.next(); &#x2F;&#x2F; 如果要注册的broker的地址已经存在，但是id不同，这属于脏数据，需要删除掉 &#x2F;&#x2F; 主要考虑到服务更换brokerId后立刻重启的情况 if (null !&#x3D; brokerAddr &amp;&amp; brokerAddr.equals(item.getValue()) &amp;&amp; brokerId !&#x3D; item.getKey()) &#123; it.remove(); &#125; &#125; &#x2F;&#x2F; 将当前Broker的IP地址注册到map中，如果put没有冲突也视为第一次注册 String oldAddr &#x3D; brokerData.getBrokerAddrs().put(brokerId, brokerAddr); registerFirst &#x3D; registerFirst || (null &#x3D;&#x3D; oldAddr); &#x2F;&#x2F; 如果Broker是主节点并且对应名称是第一次注册，保存topic的配置信息 if (null !&#x3D; topicConfigWrapper &amp;&amp; MixAll.MASTER_ID &#x3D;&#x3D; brokerId) &#123; if (this.isBrokerTopicConfigChanged(brokerAddr, topicConfigWrapper.getDataVersion()) || registerFirst) &#123; ConcurrentMap&lt;String, TopicConfig&gt; tcTable &#x3D; topicConfigWrapper.getTopicConfigTable(); if (tcTable !&#x3D; null) &#123; for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) &#123; this.createAndUpdateQueueData(brokerName, entry.getValue()); &#125; &#125; &#125; &#125; &#x2F;&#x2F; 保存心跳信息 BrokerLiveInfo prevBrokerLiveInfo &#x3D; this.brokerLiveTable.put(brokerAddr, new BrokerLiveInfo( System.currentTimeMillis(), topicConfigWrapper.getDataVersion(), channel, haServerAddr)); if (null &#x3D;&#x3D; prevBrokerLiveInfo) &#123; log.info(&quot;new broker registered, &#123;&#125; HAServer: &#123;&#125;&quot;, brokerAddr, haServerAddr); &#125; &#x2F;&#x2F; 保存过滤信息 if (filterServerList !&#x3D; null) &#123; if (filterServerList.isEmpty()) &#123; this.filterServerTable.remove(brokerAddr); &#125; else &#123; this.filterServerTable.put(brokerAddr, filterServerList); &#125; &#125; &#x2F;&#x2F; 如果注册的broker是从节点，通过名称寻找对应主节点，并保存主节点的IP地址 if (MixAll.MASTER_ID !&#x3D; brokerId) &#123; String masterAddr &#x3D; brokerData.getBrokerAddrs().get(MixAll.MASTER_ID); if (masterAddr !&#x3D; null) &#123; BrokerLiveInfo brokerLiveInfo &#x3D; this.brokerLiveTable.get(masterAddr); if (brokerLiveInfo !&#x3D; null) &#123; result.setHaServerAddr(brokerLiveInfo.getHaServerAddr()); result.setMasterAddr(masterAddr); &#125; &#125; &#125; &#125; finally &#123; this.lock.writeLock().unlock(); &#125; &#125; catch (Exception e) &#123; log.error(&quot;registerBroker Exception&quot;, e); &#125; return result;&#125; 服务注册的代码不是很难理解，就是往RouteInfoManager类的5个Map中塞数据，另外slave节点在注册后的返回值中，还会拿到对应master节点的IP地址，方便注册后展开数据同步操作。 服务发现Producer与Consumer在启动后会定时向NameServer获取路由信息，以保证后续工作的正常运行，定时任务代码如下: 123456789101112131415161718private void startScheduledTask() &#123; &#x2F;&#x2F; 其他代码...... this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; try &#123; MQClientInstance.this.updateTopicRouteInfoFromNameServer(); &#125; catch (Exception e) &#123; log.error(&quot;ScheduledTask updateTopicRouteInfoFromNameServer exception&quot;, e); &#125; &#125; &#125;, 10, this.clientConfig.getPollNameServerInteval(), TimeUnit.MILLISECONDS); &#x2F;&#x2F; 其他代码......&#125; 源码就写到这吧，写多了基本就没看的欲望了，Producer与Consumer在服务发现完毕后会得到TopicRouteData集合: 123456public class TopicRouteData extends RemotingSerializable &#123; private String orderTopicConf; private List&lt;QueueData&gt; queueDatas; private List&lt;BrokerData&gt; brokerDatas; private HashMap&lt;String&#x2F;* brokerAddr *&#x2F;, List&lt;String&gt;&#x2F;* Filter Server *&#x2F;&gt; filterServerTable;&#125; 通过queueDatas可以知道当前topic有多少个队列、每个队列所在的Broker服务名称，有了名称就可以通过brokerDatas找到对应的主从节点地址，有了地址就可以通过filterServerTable处理过滤逻辑、生产/消费消息。 故障剔除Broker节点每隔30秒会向NameServer发送一次心跳，并更新自身在brokerLiveTable中的心跳时间戳，NameServer节点每隔10秒会扫描一次brokerLiveTable，如果发现某个Broker的上次更新时间戳距离当前时间超过2分钟，则认为Broker已死亡，剔除其注册信息并关闭长连接。 故障节点剔除后并不会像Kafka那样采用再均衡策略通知Producer与Consumer，而是等待他们的服务发现机制自己去感知。这就意味着某个Broker节点挂了之后Producer与Consumer最长要等30秒才会感知到。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"rocketmq(二)服务部署","slug":"RocketMQ服务部署","date":"2020-05-03T05:00:00.000Z","updated":"2020-12-19T09:13:32.209Z","comments":true,"path":"2020/05/03/RocketMQ服务部署/","link":"","permalink":"http://yoursite.com/2020/05/03/RocketMQ%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/","excerpt":"","text":"前言由于RocketMQ是使用纯Java编写的，所以NameServer、Broker的运行必须依赖于JDK环境，安装过程中需要下载依赖，因此也必须要用到maven依赖，JDK就不写了，从maven的安装开始写。 maven下载文件wget http:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;maven&#x2F;binaries&#x2F;apache-maven-3.2.2-bin.tar.gz 解压文件tar -zxvf apache-maven-3.2.2-bin.tar.gz 编辑环境变量:vim &#x2F;etc&#x2F;profile 添加环境变量:export MAVEN_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;apache-maven-3.2.2export PATH&#x3D;$MAVEN_HOME&#x2F;bin:$PATH 刷新环境变量source &#x2F;etc&#x2F;profile 检查是否安装成功mvn -v 进入配置文件夹cd &#x2F;usr&#x2F;local&#x2F;apache-maven-3.2.2&#x2F;conf 编辑xml配置文件vi setting.xml 修改镜像仓库&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt; &lt;settings xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0&quot; xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot; xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;SETTINGS&#x2F;1.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;xsd&#x2F;settings-1.0.0.xsd&quot;&gt; &lt;localRepository&gt;&#x2F;usr&#x2F;local&#x2F;repo&lt;&#x2F;localRepository&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;&#x2F;id&gt; &lt;name&gt;aliyun maven&lt;&#x2F;name&gt; &lt;url&gt;http:&#x2F;&#x2F;maven.aliyun.com&#x2F;nexus&#x2F;content&#x2F;groups&#x2F;public&#x2F;&lt;&#x2F;url&gt; &lt;mirrorOf&gt;*&lt;&#x2F;mirrorOf&gt; &lt;&#x2F;mirror&gt; &lt;&#x2F;mirrors&gt; &lt;&#x2F;settings&gt; NameServer进入/apply/rocketmq/文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F; 下载安装包wget http:&#x2F;&#x2F;mirrors.hust.edu.cn&#x2F;apache&#x2F;rocketmq&#x2F;4.7.1&#x2F;rocketmq-all-4.7.1-source-release.zip 解压安装包unzip rocketmq-all-4.7.1-source-release.zip 重命名mv rocketmq-all-4.7.1-source-release &#x2F;apply&#x2F;rocketmq&#x2F;broker-a 进入文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;broker-a 下载依赖mvn -Prelease-all -DskipTests clean install -U 进入执行文件夹cd distribution&#x2F;target&#x2F;rocketmq-4.7.1&#x2F;rocketmq-4.7.1&#x2F;bin 编辑启动文件vim runserver.sh 修改jvm启动参数JAVA_OPT&#x3D;&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn512m -XX:MetaspaceSize&#x3D;128m -XX:MaxMetaspaceSize&#x3D;320m&quot; 创建conf文件夹mkdir -p &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf 创建propertiestouch &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;namesrv-a.properties 编辑propertiesvim &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;namesrv-a.properties 添加端口号# 服务端口号listenPort&#x3D;9876 进入执行文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;namesrv-a&#x2F;distribution&#x2F;target&#x2F;rocketmq-4.7.1&#x2F;rocketmq-4.7.1&#x2F;bin 启动nohup sh mqnamesrv -c &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;namesrv-a.properties &amp; 注:如果NameServer仅部署一台，或者每台都在不同的机器上，properties可以不配置(端口默认就是9876)，如果本地测试想要在一台服务器上配置多个，就需要区分端口 Broker进入/apply/rocketmq/文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F; 下载安装包wget http:&#x2F;&#x2F;mirrors.hust.edu.cn&#x2F;apache&#x2F;rocketmq&#x2F;4.7.1&#x2F;rocketmq-all-4.7.1-source-release.zip 解压安装包unzip rocketmq-all-4.7.1-source-release.zip 重命名mv rocketmq-all-4.7.1-source-release &#x2F;apply&#x2F;rocketmq&#x2F;broker-a 进入文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;broker-a 下载依赖mvn -Prelease-all -DskipTests clean install -U 进入执行文件夹cd distribution&#x2F;target&#x2F;rocketmq-4.7.1&#x2F;rocketmq-4.7.1&#x2F;bin 编辑启动文件vim runbroker.sh 修改jvm启动参数JAVA_OPT&#x3D;&quot;$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn512m&quot; 创建store文件夹mkdir -p &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;store-broker-a 创建commitlog文件夹mkdir -p &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;store-broker-a&#x2F;commitlog 创建propertiestouch &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;broker-a.properties 编辑propertiesvim &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;broker-a.properties 添加属性#服务端口号listenPort&#x3D;10911#集群名brokerClusterName &#x3D; lvt-cluster#broker服务名brokerName &#x3D; broker-a#0表示master，大于0表示各个slavebrokerId &#x3D; 0#删除文件时间点，默认凌晨 4点deleteWhen &#x3D; 04#文件保留时间,默认48小时fileReservedTime &#x3D; 48#Broker角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole &#x3D; ASYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType &#x3D; ASYNC_FLUSH#公网brokerIP1 &#x3D; 172.0.0.1#注册中心地址，多个使用;分开namesrvAddr&#x3D;172.0.0.1:9876#是否自动创建，生产建议关闭autoCreateTopicEnable&#x3D;true#持久化消息存储根路径storePathRootDir&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;store-broker-a#commitLog文件存储路径storePathCommitLog&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;store-broker-a&#x2F;commitlog 进入执行文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;broker-a&#x2F;distribution&#x2F;target&#x2F;rocketmq-4.7.1&#x2F;rocketmq-4.7.1&#x2F;bin 启动nohup sh mqbroker -c &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;conf&#x2F;broker-a.properties &amp; 注:在网上看到很多资料将配置写在broker.conf中，上述的不是方式不会读取这个配置文件，如果这么做也不会报错，因为这些参数全部自带默认值。 另外在配置属性中关于store的一些路径只能设置storePathRootDir、storePathCommitLog这俩个，其他的写进去会导致项目无法启动(如果写的路径是错的则不会，应该是没检测到路径就改用默认值了)。 还有个奇怪的事情，我在腾讯云部署的伪Broker集群，发现不同的节点端口号不能相邻，否则会报端口占用，目前是各服务的端口号隔几百。 Console进入git网址，下载源码(点击Download ZIP)https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;rocketmq-externals.git 上传到服务器/apply/rocketmq文件夹，并解压unzip &#x2F;apply&#x2F;rocketmq&#x2F;rocketmq-externals-master.zip 重命名文件夹mv &#x2F;apply&#x2F;rocketmq&#x2F;rocketmq-externals-master console 创建数据文件夹mkdir -p &#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;console-data 编辑application.propertiesvim &#x2F;apply&#x2F;rocketmq&#x2F;console&#x2F;rocketmq-console&#x2F;src&#x2F;main&#x2F;resources&#x2F;application.properties 修改属性# 注册中心地址端口rocketmq.config.namesrvAddr&#x3D;172.0.0.1:9876# 存放数据路径rocketmq.config.dataPath&#x3D;&#x2F;usr&#x2F;local&#x2F;rocketmq-data&#x2F;console-data# 是否需要登陆rocketmq.config.loginRequired&#x3D;true 编辑users.propertiesvim &#x2F;apply&#x2F;rocketmq&#x2F;console&#x2F;rocketmq-console&#x2F;src&#x2F;main&#x2F;resources&#x2F;users.properties 设置登录控制台的账号密码(注释的汉字别打进去，否则下面编译不通过)# 设置管理员，格式:username&#x3D;password[,N] 其中N是可选项:0为普通用户 1为管理员admin&#x3D;admin,1# 普通成员member&#x3D;member 进入解压文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;console&#x2F;rocketmq-console 执行编译(一定要编辑完配置在编译，否则配置无效)mvn clean package -Dmaven.test.skip&#x3D;true 进入jar包文件夹cd &#x2F;apply&#x2F;rocketmq&#x2F;console&#x2F;rocketmq-console&#x2F;target 启动服务nohup java -jar rocketmq-console-ng-2.0.0.jar &amp; 注:如果rocketmq.config.loginRequired设置为false，则不需要编辑users.properties设置登录用的账号密码。在设置为true的情况下，如果不编辑users.properties文件设置账号密码，会有个默认账号可以直接登录(admin/admin)，生产环境为了安全起见，建议自定义账号密码。","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"RocketMQ(一)架构原理","slug":"RocketMQ架构原理","date":"2020-05-01T05:00:00.000Z","updated":"2020-12-13T15:48:23.467Z","comments":true,"path":"2020/05/01/RocketMQ架构原理/","link":"","permalink":"http://yoursite.com/2020/05/01/RocketMQ%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86/","excerpt":"","text":"简介RocketMQ是阿里巴巴开源的消息中间件，使用Java语言开发，具有高吞吐量、高可用性，适合大规模分布式系统应用的特点。设计方面参考了kafka的整体机制和架构设计，并在此基础上添加了分布式事务、定时消息、消费失败重试、回溯消息等功能，虽然在吞吐量上无法企及kafka，但是扩展的诸多功能相对于kafka来说，更能胜任电商、金融等领域的复杂业务场景。 核心组件Broker:Broker是集群中最核心的，也是最复杂的组件，负责消息的存储、投递、查询，以及保证服务的高可用，支持容错机制、灾备机制、报警机制和丰富的监控指标。 NameServer:NameServer可以看作是RocketMQ的注册中心，类似于Dubbo、kafka的注册中心zookeeper，broker启动后会将自身管理的topic-queue信息注册到NameServer，为Producer或Consumer提供路由。 Name Server集群实例之间不会互相通讯，但是Broker会向所有的Name注册路由信息，所以每个NameServer实例上都保存了完整的路由信息。 Producer:Producer是发布消息的角色，在程序启动后通过NameServer获取所有Broker的路由信息，通过多种负载均衡的方式，选择相应的Broker Server 集群中的Queue发送消息。Producer 在发送消息时，支持快速失败，并且是低延迟的。 Consumer:Consumer是消费消息的角色，支持PUSH和PULL两种获取消息模式，支持集群和广播两种消费消息模式。 消息领域模型Topic:Topic的作用是将整个RocketMQ集群的消息进行划分，使不同类型的消息区分开来，以便于消费者针对不同的消息类型做不同的业务处理。 Tag:Tag可以看作是消息的二级分类，一般在相同业务模块中通过引入标签来标记不同用途的消息，另外RocketMQ允许消费者按照Tag对消息进行过滤，也可以通过Tag过滤不需要的数据。 Message:Message就是我们发送或消费的消息，用户在发送消息的时候可以设置messageKey，也就是消息的唯一识别MessageId，便于后续的查询和追踪。 Producer Group:开发者在启动Producer时可以指定一个生产组，如果没有指定会自动生成一个(默认为DEFAULT_PRODUCER)。Producer Group主要用于推送事务消息，比如Producer在投递事务消息时宕机，本地事务回滚，可以继续联系该组下的另外一个生产者实例，不至于导致业务走不下去。 Consumer Group:开发者在启动Producer时可以指定一个消费组，用于负载均衡共同消费消息。 部署模型 Broker特点:Broker服务分为Master与Slave，一个Master可以对应多个Slaver，Master与Slaver的对应关系通过指定相同的BrokerName、不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slaver。 Producer特点:Producer服务会随机与NameServer集群中的一个节点建立长连接，定期从NameServer获取topic-queue路由信息，然后与topic-queue所在的 BrokerServer的Master节点建立长连接，并且会定时向Master发送心跳。Producer集群完全是无状态的，可以随意集群部署。 Consumer特点:Consumer服务会随机与NameServer集群中的一个节点建立长连接，定期从NameServer获取topic-queue路由信息，然后与topic-queue所在的BrokerServer的Master节点建立长连接，并且会定时向Master和Salve发送心跳。 Consumer既可以从Master订阅消息，也可以从Salve订阅消息，Consumer在获取消息的时候，BrokerServer的Master节点会根据获取消息的偏移量与最大偏移量的距离、服务器是否可读等因素建议Consumer下次是从 Master或者Salve获取消息。 topic分布集群中所有topic都是以queue(1个或多个)的形式分散存储在各broker节点中，其中每个queue仅仅保存topic的一部分消息数据。这种架构设计与redis、elasticsearch的分片模式很相似，可以在整个RocketMQ集群服务运行过程中动态改变queue的数量，来控制同一时刻topic的并行处理能力。 假设一个Broker集群有3个节点，并且整个集群存储了3个topic: topic名称 queue数量 red 4 blue 5 green 6 topic在Broker的分布图: 注:不同的master节点存储的topic-queue数据完全不一致，而master与对应的slave节点负责的数据完全一致","categories":[{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"}],"tags":[]},{"title":"多线程(十七) 线程池","slug":"线程池","date":"2020-03-17T05:00:00.000Z","updated":"2020-11-28T05:59:53.061Z","comments":true,"path":"2020/03/17/线程池/","link":"","permalink":"http://yoursite.com/2020/03/17/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"简介解释线程池之前要先说一下池化技术，池化技术简单点来说，就是提前保存大量的资源，以备不时之需。而线程池就是利用池化技术保存线程资源的容器，同样也是Java多线程编程的重要基础。 多线程优点: 避免线程频繁的创建以及销毁带来的资源浪费 提高响应速度，任务到达时提前保存的线程可以立即执行，不需要等待临时创建 可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。 提供定时执行、定期执行、单线程、并发数控制等功能。 继承体系 Executor: 123public interface Executor &#123; void execute(Runnable command);&#125; Executor类是线程池顶级接口，只定义了一个执行无返回值任务的方法。 ExecutorService: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 public interface ExecutorService extends Executor &#123; &#x2F;&#x2F; 关闭线程池，不再接受新任务，但已经提交的任务会执行完成 void shutdown(); &#x2F;&#x2F; 立即关闭线程池，尝试停止正在运行的任务，未执行的任务将不再执行 &#x2F;&#x2F; 被迫停止及未执行的任务将以列表的形式返回 List&lt;Runnable&gt; shutdownNow(); &#x2F;&#x2F; 检查线程池是否已关闭 boolean isShutdown(); &#x2F;&#x2F; 检查线程池是否已终止，只有在shutdown()或shutdownNow()之后调用才有可能为true boolean isTerminated(); &#x2F;&#x2F; 在指定时间内线程池达到终止状态了才会返回true boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &#x2F;&#x2F; 执行有返回值的任务，任务的返回值为task.call()的结果 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &#x2F;&#x2F; 执行有返回值的任务，任务的返回值为这里传入的result,相当于给指针赋值 &#x2F;&#x2F; 当然只有当任务执行完成了调用get()时才会返回 &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); &#x2F;&#x2F; 执行有返回值的任务，返回值.get()为线程返回值 Future&lt;?&gt; submit(Runnable task); &#x2F;&#x2F; 批量执行任务，只有当这些任务都完成了这个方法才会返回，可以获取线程ID来区分集合中的返回值 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &#x2F;&#x2F; 在指定时间内批量执行任务，未执行完成的任务将被取消 &#x2F;&#x2F; 这里的timeout是所有任务的总时间，不是单个任务的时间 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &#x2F;&#x2F; 返回任意一个已完成任务的执行结果，未执行完成的任务将被取消 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &#x2F;&#x2F; 在指定时间内如果有任务已完成，则返回任意一个已完成任务的执行结果，未执行完成的任务将被取消 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ExecutorService类仍然只是接口，在Executor的基础上增加了关闭线程池、池内线程执行等相关操作。 ScheduledExecutorService: 12345678910111213141516171819202122 public interface ScheduledExecutorService extends ExecutorService &#123; &#x2F;&#x2F; 在指定延时后执行一次 public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit); &#x2F;&#x2F; 在指定延时后执行一次 public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); &#x2F;&#x2F; 在指定延时后开始执行，并在之后以指定时间间隔重复执行（间隔不包含任务执行的时间） &#x2F;&#x2F; 无论任务是否完成，只要到时间就执行下一次 public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); &#x2F;&#x2F; 在指定延时后开始执行，并在之后以指定延时重复执行（间隔包含任务执行的时间） &#x2F;&#x2F; 上次任务结束才开始倒计时，只可能一个线程在工作 public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit);&#125; ScheduledExecutorService接口在ExecutorService的基础上增加了定时任务的相关功能，这些定时功能又分为单次执行和重复执行。 AbstractExecutorService: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191public class ThreadPoolExecutor extends AbstractExecutorService&#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; public Future&lt;?&gt; submit(Runnable task) &#123; if (task &#x3D;&#x3D; null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask &#x3D; newTaskFor(task, null); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task &#x3D;&#x3D; null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask &#x3D; newTaskFor(task, result); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task &#x3D;&#x3D; null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask &#x3D; newTaskFor(task); execute(ftask); return ftask; &#125; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123; if (tasks &#x3D;&#x3D; null) throw new NullPointerException(); int ntasks &#x3D; tasks.size(); if (ntasks &#x3D;&#x3D; 0) throw new IllegalArgumentException(); ArrayList&lt;Future&lt;T&gt;&gt; futures &#x3D; new ArrayList&lt;Future&lt;T&gt;&gt;(ntasks); ExecutorCompletionService&lt;T&gt; ecs &#x3D; new ExecutorCompletionService&lt;T&gt;(this); try &#123; &#x2F;&#x2F; Record exceptions so that if we fail to obtain any &#x2F;&#x2F; result, we can throw the last exception we got. ExecutionException ee &#x3D; null; final long deadline &#x3D; timed ? System.nanoTime() + nanos : 0L; Iterator&lt;? extends Callable&lt;T&gt;&gt; it &#x3D; tasks.iterator(); &#x2F;&#x2F; Start one task for sure; the rest incrementally futures.add(ecs.submit(it.next())); --ntasks; int active &#x3D; 1; for (;;) &#123; Future&lt;T&gt; f &#x3D; ecs.poll(); if (f &#x3D;&#x3D; null) &#123; if (ntasks &gt; 0) &#123; --ntasks; futures.add(ecs.submit(it.next())); ++active; &#125; else if (active &#x3D;&#x3D; 0) break; else if (timed) &#123; f &#x3D; ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f &#x3D;&#x3D; null) throw new TimeoutException(); nanos &#x3D; deadline - System.nanoTime(); &#125; else f &#x3D; ecs.take(); &#125; if (f !&#x3D; null) &#123; --active; try &#123; return f.get(); &#125; catch (ExecutionException eex) &#123; ee &#x3D; eex; &#125; catch (RuntimeException rex) &#123; ee &#x3D; new ExecutionException(rex); &#125; &#125; &#125; if (ee &#x3D;&#x3D; null) ee &#x3D; new ExecutionException(); throw ee; &#125; finally &#123; for (int i &#x3D; 0, size &#x3D; futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123; try &#123; return doInvokeAny(tasks, false, 0); &#125; catch (TimeoutException cannotHappen) &#123; assert false; return null; &#125; &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; return doInvokeAny(tasks, true, unit.toNanos(timeout)); &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123; if (tasks &#x3D;&#x3D; null) throw new NullPointerException(); ArrayList&lt;Future&lt;T&gt;&gt; futures &#x3D; new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done &#x3D; false; try &#123; for (Callable&lt;T&gt; t : tasks) &#123; RunnableFuture&lt;T&gt; f &#x3D; newTaskFor(t); futures.add(f); execute(f); &#125; for (int i &#x3D; 0, size &#x3D; futures.size(); i &lt; size; i++) &#123; Future&lt;T&gt; f &#x3D; futures.get(i); if (!f.isDone()) &#123; try &#123; f.get(); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; &#125; &#125; done &#x3D; true; return futures; &#125; finally &#123; if (!done) for (int i &#x3D; 0, size &#x3D; futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123; if (tasks &#x3D;&#x3D; null) throw new NullPointerException(); long nanos &#x3D; unit.toNanos(timeout); ArrayList&lt;Future&lt;T&gt;&gt; futures &#x3D; new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done &#x3D; false; try &#123; for (Callable&lt;T&gt; t : tasks) futures.add(newTaskFor(t)); final long deadline &#x3D; System.nanoTime() + nanos; final int size &#x3D; futures.size(); &#x2F;&#x2F; Interleave time checks and calls to execute in case &#x2F;&#x2F; executor doesn&#39;t have any&#x2F;much parallelism. for (int i &#x3D; 0; i &lt; size; i++) &#123; execute((Runnable)futures.get(i)); nanos &#x3D; deadline - System.nanoTime(); if (nanos &lt;&#x3D; 0L) return futures; &#125; for (int i &#x3D; 0; i &lt; size; i++) &#123; Future&lt;T&gt; f &#x3D; futures.get(i); if (!f.isDone()) &#123; if (nanos &lt;&#x3D; 0L) return futures; try &#123; f.get(nanos, TimeUnit.NANOSECONDS); &#125; catch (CancellationException ignore) &#123; &#125; catch (ExecutionException ignore) &#123; &#125; catch (TimeoutException toe) &#123; return futures; &#125; nanos &#x3D; deadline - System.nanoTime(); &#125; &#125; done &#x3D; true; return futures; &#125; finally &#123; if (!done) for (int i &#x3D; 0, size &#x3D; futures.size(); i &lt; size; i++) futures.get(i).cancel(true); &#125; &#125;&#125; AbstractExecutorService是个抽象类，首先重写了ExecutorService类的submit()、invokeAny()、invokeAll()方法，另外还提供了一个newTaskFor方法用于构建RunnableFuture对象。 ThreadPoolExecutor: 123public class ThreadPoolExecutor extends AbstractExecutorService &#123; &#125; ThreadPoolExecutor是一个普通类，也是我们使用线程池时需要创建的实例，内部集成了AbstractExecutorService抽象类，也就意味着它包含了以上介绍的所有接口(除了ScheduledExecutorService)的处理逻辑，也是本章节要着重要分析的类。 ScheduledThreadPoolExecutor: 12345 public class ScheduledThreadPoolExecutor extends ThreadPoolExecutor implements ScheduledExecutorService &#123; &#x2F;&#x2F; 属性方法..&#125; ScheduledThreadPoolExecutor类看继承实现关系就能看明白，在继承了ThreadPoolExecutor类所有功能的情况下，通过实现ScheduledExecutorService接口又增加了线程定时任务执行的相关逻辑。 ForkJoinPool: 123public class ForkJoinPool extends AbstractExecutorService &#123; &#x2F;&#x2F; 属性方法..&#125; ForkJoinPool比较适合计算密集型的任务，以后有机会用到的话再写。 构造器参数在ThreadPoolExecutor类中有4个构造器，但最终调用的是如下这个构造器: 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) corePoolSize:核心线程大小，即在没有任务需要执行的时候线程池的大小，当所有核心线程都在执行任务时仍然有新任务提交，会直接进入阻塞队列。除非调用allowCoreThreadTimeOut()方法设置为true，这种情况下核心线程数空闲下来也会被回收掉。另外核心线程默认是懒加载模式，只有等到有任务的时候才会启动，比如常见的数据库连接池，在启动项目后首次访问数据库会打印{dataSource-1} inited日志，其实就是在懒加载核心线程，除非你调用prestartCoreThread()或prestartAllCoreThreads()方法提前启动核心线程。 maximumPoolSize:线程池中允许的最大线程数，如果说corePoolSize是控制同一时刻线程执行数量的下限，maximumPoolSize就是与之对应的上限。当阻塞队列已满并且当前线程个数小于maximumPoolSize，那么会创建新的线程来执行任务。这里值得一提的是getLargestPoolSize()方法，调用该方法会返回线程池在整个生命周期中曾经出现的最大线程个数。 keepAliveTime:线程空闲时的存活时间，当线程持续keepAliveTime时间处于空闲状态时，这个空闲线程会被销毁。默认情况下，该参数只会对非核心线程生效，如果调用allowCoreThreadTimeOut()被设置为true时，无论线程数多少，线程处于空闲状态超过一定时间就会被销毁掉。 unit:keepAliveTime的单位，TimeUnit是一个枚举类型，具体哪些就没必要讲了。 workQueue:阻塞队列，当所有核心线程都在执行任务时仍然有新任务提交时，会加入此队列等待。构造器中阻塞队列的范型必须是Runnable类型，换句话说只有实现Runnable接口的类才可以加入阻塞队列，这个下面会单独讲。 threadFactory:线程工厂，用于新线程的创建，创建时可以设定线程名、是否为daemon线程等等。 handler:拒绝策略，当阻塞队列已满并且线程池中的线程数量也达到最大限制，必须采取一种策略处理该任务。线程池提供了四种决绝策略，如果仍然无法满足业务需求，还可以通过实现RejectedExecutionHandler接口自定义拒绝策略。 阻塞队列线程池允许设置的阻塞队列对象，用来保存等待被执行的任务的阻塞队列，队列全部都是BlockingQueue接口的实现类，并且范型必须实现Runable接口，如下阻塞队列: ArrayBlockingQueue(有界队列):是一个基于数组实现的的阻塞队列，队列长度在创建后固定不可修改，此队列按照先进先出（FIFO）的原则对元素进行排序。ArrayBlockingQueue插入数据和获取数据，需要竞争到锁才可以执行，也就意味着这俩个操作无法并行执行，另外可以通过构造器参数设置竞争的公平性。 LinkedBlockingQueue(无界队列):是一个基于链表实现的的阻塞队列，如果在创建时没有在构造器中指定容量，那么容量默认为Integer.MAX_VALUE。LinkedBlockingQueue队列的插入和消费元素采用分离的锁控制，也就意味着这俩种操作可以并行执行，整体的吞吐性能要高于ArrayBlockingQueue，当队列达到最大容量时，插入元素的线程会进入阻塞，直到队列的元素被消费掉腾出空间才会被唤醒继续执行。 DelayQueue(延迟队列):此队列中在长度方面没有任何限制，因此往队列插入元素时不会产生任何阻塞，如果线程池任务想要加入此队列除了要实现Runnable接口外，还需要实现Delayed接口。获取元素时，只有当元素的延迟时间到了才可以从队列中获取到该元素，否则会进入阻塞。 PriorityBlockingQueue(优先级队列):此队列在长度方面仍然没有限制，插入元素操作也不会产生任何阻塞，如果线程池任务想要加入此队列除了要实现Runnable接口外，还需要实现Compator接口。在使用没有容量限制的队列时一定要注意，插入元素的速度绝对不能大于消费元素的速度，否则随着时间的积累，会耗尽系统的内存资源造成内存泄漏。 SynchronousQueue(无缓冲等待队列):队列中仅保存一个元素，只有对列为空才可以添加元素，之后只有等待元素被消费才可以继续添加。拥有公平(FIFO)和非公平(LIFO)策略，可以在创建时指定。 拒绝策略线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务。拒绝策略并不是设置就一定生效，比如阻塞队列选择无界的情况下，基本上队列堆积的任务没有到达Inteher.MAX_VALUE时，内存就爆了。java提供了四种线程池拒绝策略，当然你也可以通过继承这四个策略类，或者实现RejectedExecutionHandler接口自定义拒绝策略: AbortPolicy(异常中止策略):直接抛出RejectedExecutionException异常，也是线程池的默认拒绝策略。这种策略使用的时候要处理好抛出的异常，避免调用线程池的主线程因为异常打断后续的执行流程。 DiscardPolicy(丢弃策略):直接丢弃任务，因为此类在实现RejectedExecutionHandler接口并重写的rejectedExecution方法中啥都没做。如果你提交的任务无关紧要，可以选择使用此策略，我个人感觉这个策略几乎用不上，但凡有点良心的开发都会打印一行日志意思意思… DiscardOldestPolicy(弃老策略):放弃阻塞队列中最靠前的任务，并尝试让线程池执行当前线程。这种策略仍然会悄悄的丢掉任务，只不过保证新产生的任务优先执行，应该是满足特定场景使用的吧。 CallerRunsPolicy(调用者运行策略):当触发拒绝策略时，只要线程池没有关闭，就由提交任务的当前线程处理。原理是直接运行Runnable的run()方法，直接调用run()的方式都懂得，会阻塞调用者直到执行完毕。这种方式看似比较稳妥，能保证所有的任务都会被执行，但是拒绝策略的rejectedExecution()方法是包含在线程池的execute()方法中调用，execute()在执行过程中会占用一条线程，如果多个线程进入此阻塞策略并且线程执行时间过长，会严重影响线程池处理任务的吞吐量。因此这种策略一般在不允许失败、对性能要求不高、并发亮较小的场景下使用。 自定义:如果以上四种策略无法满足你的需求，那就需要考虑自定义策略了。比如dubbo的工作线程池自定义的拒绝策略是继承AbortPolicy类，打印完日志后调用父类抛异常、比如ActiveMQ中的拒绝策略属于最大努力执行任务型，当触发拒绝策略时，在尝试一分钟的时间重新将任务塞进任务队列，当一分钟超时还没成功时，就抛出异常。 参数设置线程池的使用难度不大，但用好线程池就需要对常用参数的含义有一定的理解，并且要考虑到应用程序所在服务器的CPU配置、任务的执行特点、任务执行过程中的内存使用率等，如果任务中涉及下游服务的调用，还要考虑到下游服务的抗并发能力等。可以将线程池要执行的任务进行分类: CPU密集型:例如内存中的计算、比较、转化等，尽量使用较小的线程池，一般为CPU核心数+1。即使当计算密集型的线程偶尔由于缺失故障或者其他原因而暂停时，这个额外的线程也能确保CPU的时钟周期不会被浪费。因为CPU密集型任务使得CPU使用率很高，尽量减少线程之间竞争引起的上下文切换带来的资源浪费。 IO密集型:例如网络IO(调用其他服务或接口)、磁盘IO(读写文件)等，可以使用稍大的线程池，一般为2*CPU核心数+1(如果调用下游服务还要考虑抗并发因素)。因为IO操作期间不占用CPU，不要让CPU闲下来，应加大线程数量，因此可以让CPU在等待IO的时候去处理别的任务，充分利用CPU时间。 混合型:可以将任务分成IO密集型和CPU密集型任务，然后分别用不同的线程池去处理。只要分完之后两个任务的执行时间相差不大，那么就会比串行执行来的高效。 注:通过公式推算出的线程池参数仅仅只是理想状态下的最优方案，实际最优参数需要根据服务器运行情况比，如线程执行过程中占用CPU时间、最大线程数峰值、拒绝策略出现频率等不断调整参数。 springboot线程池配置自定义线程池: 1234567891011121314151617181920212223242526272829@Configuration@EnableAsyncpublic class ThreadPoolConfig implements AsyncConfigurer &#123; &#x2F;** * 自定义线程池，若不重写会使用默认的线程池 *&#x2F; @Bean(&quot;asyncExecutor&quot;) @Override public Executor getAsyncExecutor() &#123; ThreadPoolTaskExecutor asyncExecutor &#x3D; new ThreadPoolTaskExecutor(); asyncExecutor.setCorePoolSize(16); asyncExecutor.setMaxPoolSize(32); asyncExecutor.setKeepAliveSeconds(180); asyncExecutor.setQueueCapacity(200); asyncExecutor.setThreadNamePrefix(&quot;buss-thread&quot;); &#x2F;&#x2F; 线程命名前缀 asyncExecutor.initialize(); return asyncExecutor; &#125; &#x2F;** * 自定义拒绝策略 *&#x2F; @Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() &#123; return new AbortPolicy(); &#125;&#125; 注: @EnableAsync注解一定要加，否则线程池异步调用不生效。 配置异步任务: 1234567891011121314151617181920212223242526@Servicepublic class UserServiceImpl implements UserService &#123; @Override public void updateById(UserTo to) &#123; &#x2F;&#x2F; ... &#125; @Async @Override public void asyncUpdateById(UserTo to) &#123; updateById(to); &#125; @Async @Override public Future&lt;Boolean&gt; asyncUpdateById(UserTo to) &#123; try&#123; updateById(to); &#125; catch()&#123; return new AsyncResult&lt;&gt;(Boolean.FALSE); &#125; return new AsyncResult&lt;&gt;(Boolean.TRUE); &#125;&#125; 如果想要使用异步方式调用某个方法，只需要加上@Async注解即可，如果需要返回值必须使用Future，其他返回值类型在调用后会立刻返回null，如果不需要返回值直接将方法返回值设置为void。最好封装一个异步方法，减少对原始方法的破坏，避免其他非异步使用的线程调用后返回null导致程序错误。 注:如果应用配置了多个线程池，则需要在@Async注解的value属性中指定线程池Bean名称，没有指定的情况下使用默认线程池(@primary注解的bean) 总结","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十六) ThreadLocal","slug":"ThreadLocal","date":"2020-03-16T05:00:00.000Z","updated":"2021-03-25T00:30:27.632Z","comments":true,"path":"2020/03/16/ThreadLocal/","link":"","permalink":"http://yoursite.com/2020/03/16/ThreadLocal/","excerpt":"","text":"简介ThreadLocal用于存储线程的局部变量，通过为每个线程提供一个独立的变量副本解决了变量并发访问的冲突问题，每个线程都可以通过set()和get()来对这个局部变量进行操作，但不会和其他线程的局部变量进行冲突，实现了线程的数据隔离。ThreadLocal诞生于JDK 1.2，直到JDK5.0开始支持范型。 应用场景ThreadLocal的应用场景比较广泛，例如web项目中登陆信息的存储、IOC中Request作用域的实现、Spring事物管理的实现、线程同步工具Exchanger的实现等。除了登录信息的存储以外，其他的多多少少都是涉及到底层的源码，写出来篇幅太大，所以下面简单讲述一下如何使用ThreadLocal存储登陆信息。 一般浏览器发送http请求到后端服务器，都会将用户信息的token以cookie或header形式携带过去，并在后端拦截器中对token校验是否合法。如果请求的接口中需要用到一次或多次用户信息(比如ID、名称、生日、职级等)进行业务处理，这就需要将用户信息从controller一层一层作为参数传递下去，这无疑增加了代码的复杂程度，重点是不够优雅，使用ThreadLocal完全可以避免这个问题。 1.用户信息对象: 12345678910111213141516@Data@ToStringpublic class UserInfo &#123; private Long id; private Long deptId; private String name; private String phone; private String email; private String birthday;&#125; 2.创建一个ThreadLocal封装类，内部定义一个私有ThreadLocal并对外提供get、set方法: 1234567891011121314151617181920212223242526public class UserInfoThreadLocal &#123; private static final ThreadLocal&lt;UserInfo&gt; threadLocal &#x3D; new ThreadLocal&lt;&gt;(); public static void set(UserInfo value)&#123; threadLocal.set(value); &#125; public static UserInfo get()&#123; return threadLocal.get(); &#125; public static void remove()&#123; threadLocal.remove(); &#125; public static UserInfo getAndValidate()&#123; UserInfo userInfo &#x3D; get(); if(userInfo &#x3D;&#x3D; null)&#123; &#x2F;&#x2F; 抛业务异常 &#125; return userInfo; &#125;&#125; 3.拦截器负责校验信息，并将合法的用户信息注册到ThreadLocal中: 12345678910111213141516171819202122232425262728293031@Componentpublic class LoginInfoInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; String token &#x3D; request.getHeader(&quot;token&quot;); if(StringUtils.isEmpty(token))&#123; &#x2F;&#x2F; 抛业务异常 &#125; &#x2F;&#x2F; 模拟查询用户信息 UserInfo userInfo &#x3D; new UserInfo(); userInfo.setId(323L); userInfo.setDeptId(542L); userInfo.setPhone(&quot;110&quot;); userInfo.setEmail(&quot;110@163.com&quot;); userInfo.setBirthday(&quot;1995-12-20&quot;); &#x2F;&#x2F; 放入UserInfoThreadLocal UserInfoThreadLocal.set(userInfo); return true; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; UserInfoThreadLocal.remove(); &#125;&#125; 4.web项目的controller层，获取并打印拦截器查询并校验通过的用户信息: 1234567891011121314151617@RestControllerpublic class TestController &#123; @Autowired private TestService testService; @RequestMapping(&quot;&#x2F;test&quot;) public void test()&#123; &#x2F;&#x2F; 获取用户信息并打印 UserInfo userInfo &#x3D; UserInfoThreadLocal.getAndValidate(); System.out.println(&quot;controller:&quot; + JSONObject.toJSONString(userInfo)); &#x2F;&#x2F; 调用service testService.testQuery(); &#125;&#125; 5.web项目的service层，获取并打印拦截器查询并校验通过的用户信息: 123456789101112131415161718192021@Servicepublic class TestServiceImpl implements TestService &#123; @Override public void testQuery() &#123; &#x2F;&#x2F; 获取用户信息并打印 UserInfo userInfo &#x3D; UserInfoThreadLocal.getAndValidate(); System.out.println(&quot;testQuery:&quot; + JSONObject.toJSONString(userInfo)); &#x2F;&#x2F; 调用私有方法 testMethod(); &#125; private void testMethod()&#123; &#x2F;&#x2F; 获取用户信息并打印 UserInfo userInfo &#x3D; UserInfoThreadLocal.getAndValidate(); System.out.println(&quot;testMethod:&quot; + JSONObject.toJSONString(userInfo)); &#125;&#125; 打印结果:controller:{“birthday”:”1995-12-20”,”deptId”:542,”email”:”&#49;&#49;&#48;&#x40;&#49;&#54;&#51;&#46;&#x63;&#111;&#x6d;“,”id”:323,”phone”:”110”}testQuery:{“birthday”:”1995-12-20”,”deptId”:542,”email”:”&#x31;&#49;&#48;&#64;&#x31;&#x36;&#51;&#x2e;&#x63;&#x6f;&#x6d;“,”id”:323,”phone”:”110”}testMethod:{“birthday”:”1995-12-20”,”deptId”:542,”email”:”&#x31;&#x31;&#48;&#x40;&#x31;&#x36;&#51;&#x2e;&#99;&#111;&#x6d;“,”id”:323,”phone”:”110”} 从上面的Demo代码可以看出来，只要在拦截器层面对token的验证通过，并将用户信息存储在创建的ThreadLocal对象中，就可以在任何逻辑层、任何方法直接获取用户信息，提高了代码的简介程度。 存储原理Thread类中有个成员变量threadLocals，这个变量的引用类型是ThreadLocal中的一个内部类ThreadLocalMap，这个类没有实现Map接口，本质上是一个table数组，数组中每个元素都是K-V键值对组成的Entry对象，其中K就是ThreadLocal实例，V就是要存储的局部变量对象。 源码解析hash算法ThreadLocalMap的存储逻辑和HashMap有一些相似的地方，内部都是维护一个Entry类型数组，然后通过对key的哈希码进行位与运算，定位出存储的数组坐标。ThreadLocal作为key提供的哈希码查询方法并非hashCode()，而是通过成员变量threadLocalHashCode去表达。 12345678910111213141516public class ThreadLocal&lt;T&gt; &#123; &#x2F;&#x2F; 哈希码 private final int threadLocalHashCode &#x3D; nextHashCode(); &#x2F;&#x2F; 下一个哈希码 private static AtomicInteger nextHashCode &#x3D; new AtomicInteger(); &#x2F;&#x2F; 哈希码递增跨度值 private static final int HASH_INCREMENT &#x3D; 0x61c88647; &#x2F;&#x2F; 哈希码递增方法 private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125;&#125; 存储哈希码的成员变量threadLocalHashCode被final修饰，也就意味着实例被创建时内部threadLocalHashCode固定为nextHashCode()方法返回的值。这个方法很有意思，每次调用都是将nextHashCode递增0x61c88647，并返回递增后的值。按照这个设计逻辑，每次创建的ThreadLocal实例的哈希值都是不同的，都会比上一次的哈希值高0x61c88647，并且考虑到会被多个线程创建，使用AtomicInteger维护递增值确保线程安全。 因此线程的threadLocals值必须由同一个实例进行存取，这样才能定位到同一个数组下坐标，这也是上述的例子中把ThreadLocal设计成static、final的原因。 set()源码ThreadLocal的set方法: 1234567891011121314public void set(T value) &#123; &#x2F;&#x2F; 获取调用set方法的当前线程 Thread t &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取当前线程的threadLocals属性 ThreadLocalMap map &#x3D; getMap(t); &#x2F;&#x2F; 如果已经初始化，继续往里面增加键值对 if (map !&#x3D; null) map.set(this, value); &#x2F;&#x2F; 如果没有初始化，创建一个ThreadLocalMap并增加一个键值对 else createMap(t, value);&#125; 如果ThreadLocalMap为null，调用createMap()初始化: 12345678910111213141516171819202122232425&#x2F;&#x2F; 为调用set方法的当前线程初始化threadLocals属性void createMap(Thread t, T firstValue) &#123; &#x2F;&#x2F; 使用带参数构造器 t.threadLocals &#x3D; new ThreadLocalMap(this, firstValue);&#125;&#x2F;&#x2F; ThreadLocalMap重载构造器 ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; &#x2F;&#x2F; 初始化table数组容量为16 table &#x3D; new Entry[INITIAL_CAPACITY]; &#x2F;&#x2F; 对key的hashCode进行位与运算取余数，计算出存储到table数组的坐标 int i &#x3D; firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); &#x2F;&#x2F; 将Entry插入ThreadLocalMap中，Entry构造器没啥复杂逻辑，不写了 table[i] &#x3D; new Entry(firstKey, firstValue); &#x2F;&#x2F; 此时长度固定为1，因为就一个Entry size &#x3D; 1; &#x2F;&#x2F; 这个方法是设置ThreadLocalMap扩容的阈值(固定为容量的2&#x2F;3)，类似HashMap的负载因子 setThreshold(INITIAL_CAPACITY);&#125; 如果Map已经被初始化，调用set()方法添加一个键值对: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; &#x2F;&#x2F; 获取Entry类型数组 Entry[] tab &#x3D; table; &#x2F;&#x2F; 获取数组长度 int len &#x3D; tab.length; &#x2F;&#x2F; 对哈希值使用位与运算定位到存储的数组坐标计作i int i &#x3D; key.threadLocalHashCode &amp; (len-1); &#x2F;&#x2F; 将i坐标在数据中的值取出，赋值给e &#x2F;&#x2F; 即使ThreadLocal实例的哈希值不同，位与运算后仍然会计算出相同的数组坐标，只要计算出的坐标已存储元素，for循环就继续下去 &#x2F;&#x2F; 每次循环完将i值重新赋值为i+1(如果+1后下标越界则赋值0)，并将新赋值的i坐标对应的数组元素赋值给e &#x2F;** * 1.每次循环取出数组坐标i对应的值，赋值给e * 2.虽然每个ThreadLocal实例的哈希值不同，但是经过位于运算后仍然会冲突，并且数组中每个坐标只会存储一个对象， * 不会像HashMap那样相同坐标使用链表或红黑树存储。 * 3.如果通过i取出的Entry为空，则跳出for循环 * 4.如果通过i取出的Entry不为空，进入循环体的逻辑处理，并且在处理完后对i+1操作(如果+1之后大于等于数组长度则设置为0) *&#x2F; for (Entry e &#x3D; tab[i]; e !&#x3D; null; e &#x3D; tab[i &#x3D; nextIndex(i, len)]) &#123; &#x2F;&#x2F; 执行到这里，说明数组下坐标i对应的Entry不为空，将Entry的key提取出来 ThreadLocal&lt;?&gt; k &#x3D; e.get(); &#x2F;&#x2F; 如果提取出来的key与需要set的key地址一致，直接覆盖其value if (k &#x3D;&#x3D; key) &#123; e.value &#x3D; value; return; &#125; &#x2F;&#x2F; 如果实体类Entry不为null，所属的key不为null(下面统一称为过期元素) if (k &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; k被回收，所在的e也没有存在的意义了，将需要设置的key、value覆盖到e中，覆盖完返回 replaceStaleEntry(key, value, i); return; &#125; &#125; &#x2F;&#x2F; 到这里说明i的值已经递增到对应下坐标为null了，直接new一个Entry存储进去 tab[i] &#x3D; new Entry(key, value); &#x2F;&#x2F; 数组长度+1 int sz &#x3D; ++size; &#x2F;&#x2F; 如果没有找到过期元素，并且新增后数组的长度超过阈值，进行扩容 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;&#x3D; threshold) rehash();&#125; 如果Entry是过期元素，那么这个Entry也没有任何存在的意义，因为没有任何途径能拿到此Entry的value。这时候就需要调用replaceStaleEntry()方法将此Entry替换掉，将此数组坐标重新利用起来: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value,int staleSlot) &#123; Entry[] tab &#x3D; table; int len &#x3D; tab.length; Entry e; &#x2F;&#x2F; staleSlot是前面set方法中检查出来的过期元素所在的坐标 int slotToExpunge &#x3D; staleSlot; &#x2F;&#x2F; 对数组从slotToExpunge坐标向前遍历，直到碰到过期元素后终止 for (int i &#x3D; prevIndex(staleSlot, len); (e &#x3D; tab[i]) !&#x3D; null; i &#x3D; prevIndex(i, len)) &#x2F;* * 如果此Entry是过期元素，则将当前坐标赋值给slotToExpunge * 可以理解为循环结束后，slotToExpunge的值会变为:坐标staleSlot往左最左边的过期元素 * 这个变量的作用是定位一个范围，清理过期元素工作就是将当前值作为数组坐标向右检查 *&#x2F; if (e.get() &#x3D;&#x3D; null) slotToExpunge &#x3D; i; &#x2F;&#x2F; 这个循环是向后遍历，与上面的循环正好相反 for (int i &#x3D; nextIndex(staleSlot, len); (e &#x3D; tab[i]) !&#x3D; null; i &#x3D; nextIndex(i, len)) &#123; &#x2F;&#x2F; 获取数组中Entry的key ThreadLocal&lt;?&gt; k &#x3D; e.get(); &#x2F;&#x2F; 如果之前存在相同的key if (k &#x3D;&#x3D; key) &#123; &#x2F;&#x2F; 覆盖原value值 e.value &#x3D; value; &#x2F;&#x2F; staleSlot是前面set方法查询到的过期元素，与当前循环的坐标i交换位置 tab[i] &#x3D; tab[staleSlot]; tab[staleSlot] &#x3D; e; &#x2F;&#x2F; 这俩值相等说明上一个for循环，往左没有找到任何E过期元素 &#x2F;&#x2F; 到目前为止需要清理的过期元素只有set方法检查出来的那一个，当前坐标的key和value都有值 &#x2F;&#x2F; 然而上面俩行代码已经将当前坐标的Entry与set检查出来的Entry交换位置了 &#x2F;&#x2F; 所以当前坐标对应的Entry是过期数据，将当前坐标赋值给slotToExpunge，准备后续清理工作 if (slotToExpunge &#x3D;&#x3D; staleSlot) slotToExpunge &#x3D; i; &#x2F;&#x2F; 清理过期的数据 cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#x2F;&#x2F; key的位置已经定位并覆盖value了，所有逻辑处理到此结束 return; &#125; &#x2F;&#x2F; 到这里说明要设置的key在数组中还没找到，并且左边的循环查询过期元素 &#x2F;&#x2F; 换句话说就是当前坐标i往左的元素都没毛病，往右检查清理元素的起点坐标要从i开始 if (k &#x3D;&#x3D; null &amp;&amp; slotToExpunge &#x3D;&#x3D; staleSlot) slotToExpunge &#x3D; i; &#125; &#x2F;&#x2F; 到这里说明数组遍历完了也没存在key，重新创建一个Entry并覆盖当前坐标 tab[staleSlot].value &#x3D; null; tab[staleSlot] &#x3D; new Entry(key, value); &#x2F;&#x2F; 如果这俩值相等，说明staleSlot坐标的左右元素都没问题，而且当前坐标也被新的Entry覆盖了，不需要清理 &#x2F;&#x2F; 如果不相等，要么坐标staleSlot的左边存在要清理的元素，要么就是右边，执行清理 if (slotToExpunge !&#x3D; staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);&#125; 上面对数组中Entry的检查中不难发现，无论往左还是往右一旦碰到为null的元素检查就停止了，这会漏掉一部分Entry的检查。因此在每次清理的时候，顺带将不为空的元素左移，挤出所有值为null的下坐标，确保所有不为null的Entry连续挨在一起。这些逻辑都在expungeStaleEntry方法中实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab &#x3D; table; int len &#x3D; tab.length; &#x2F;&#x2F;将上个方法检查出来的过期元素以及所属value的引用设置为null，方便GC回收 tab[staleSlot].value &#x3D; null; tab[staleSlot] &#x3D; null; &#x2F;&#x2F; 数组长度减1 size--; &#x2F;&#x2F; 顺着坐标向右遍历 Entry e; int i; for (i &#x3D; nextIndex(staleSlot, len); (e &#x3D; tab[i]) !&#x3D; null; i &#x3D; nextIndex(i, len)) &#123; &#x2F;&#x2F; 取出当前坐标的key ThreadLocal&lt;?&gt; k &#x3D; e.get(); &#x2F;&#x2F; 如果key为空，则将Entry和内部value设置为null，方便GC回收，数组长度也要减1 if (k &#x3D;&#x3D; null) &#123; e.value &#x3D; null; tab[i] &#x3D; null; size--; &#125; else &#123; &#x2F;&#x2F; 如果不为空,重新通过哈希值计算安插的数组坐标 int h &#x3D; k.threadLocalHashCode &amp; (len - 1); &#x2F;&#x2F; 如果通过哈希值计算的坐标不是当前坐标 if (h !&#x3D; i) &#123; &#x2F;&#x2F; 将当前坐标清空，对应的Entry已经被e指向，并不会丢掉 tab[i] &#x3D; null; &#x2F;&#x2F; 从哈希值计算的坐标开始，往右寻找null的坐标安放e，一旦发现要安插的坐标h左边有为null的坐标，就填充过去 while (tab[h] !&#x3D; null) h &#x3D; nextIndex(h, len); &#x2F;&#x2F; 将e赋值到最终计算出的坐标 tab[h] &#x3D; e; &#125; &#125; &#125; &#x2F;&#x2F; 返回值i代表从staleSlot往右循环过程中，碰到的第一个为null的坐标 return i;&#125; cleanSomeSlots主要用于控制扫描，检查还存不存在有问题的元素，如果有就清理掉。扫描的趟数为log2(数组长度)，执行过程中一旦发现了过期元素，扫描趟数会重置，并且返回值变为true: 12345678910111213141516171819202122232425262728293031private boolean cleanSomeSlots(int i, int n) &#123; boolean removed &#x3D; false; Entry[] tab &#x3D; table; int len &#x3D; tab.length; do &#123; &#x2F;&#x2F; 获取i的下一个坐标 i &#x3D; nextIndex(i, len); &#x2F;&#x2F; 取出Entry Entry e &#x3D; tab[i]; &#x2F;&#x2F; 如果循环过程中发现了过期元素 if (e !&#x3D; null &amp;&amp; e.get() &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; 重置n的值，也就是需要再次扫描log2(n)趟 n &#x3D; len; &#x2F;&#x2F; 返回值removed设置为true removed &#x3D; true; &#x2F;&#x2F; 清理元素并记录清理的坐标 i &#x3D; expungeStaleEntry(i); &#125; &#x2F;&#x2F; n每右移一次相当于n除以2，直到n除以2后小于0终止循环 &#125; while ( (n &gt;&gt;&gt;&#x3D; 1) !&#x3D; 0); &#x2F;&#x2F; 如果为true，代表执行过程中出现需要清理的元素 return removed;&#125; 数组扩容: 123456789private void rehash() &#123; &#x2F;&#x2F; 判断是否需要扩容前，再次清理一遍过期元素 expungeStaleEntries(); &#x2F;&#x2F; 超过阈值的3&#x2F;4，进行扩容 if (size &gt;&#x3D; threshold - threshold &#x2F; 4) resize();&#125; 整个set方法的执行过程分为俩部分，一部分是通过哈希值与数组长度的取余运算，定位到要存储的坐标，并解决坐标冲突的问题。另一部分也是最复杂的一部分，主要涉及到对过期元素的清理工作并防止内存泄漏，因为Entry对象中key的引用是弱引用，所指向的实例如果没有其他强引用指向，随时可能被回收掉。 通过实例的哈希值(threadLocalHashCode属性)，定位到要存储的坐标。 计算出的坐标可能会冲突(类似hashMap的哈希碰撞)，这时需要对比已存储的Entry的key与要存储的key是否一致。 如果key地址相同，直接覆盖value值，结束。 如果key为null(过期元素)，将要set的值包装成Entry覆盖当前坐标，然后进行扫描并清除所有过期元素 如果计算出来的坐标不存在冲突，直接插入此坐标 如果达到扩容的阈值，对数组进行扩容 get()源码ThreadLocal的get方法: 12345678910111213141516171819202122232425public T get() &#123; &#x2F;&#x2F; 获取调用此方法的线程 Thread t &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取线程的ThreadLocalMap ThreadLocalMap map &#x3D; getMap(t); &#x2F;&#x2F; 如果map不为null if (map !&#x3D; null) &#123; &#x2F;&#x2F; 获取数组元素Entry ThreadLocalMap.Entry e &#x3D; map.getEntry(this); &#x2F;&#x2F; 如果不为空，根据范型强转并返回，get方法到此结束 if (e !&#x3D; null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result &#x3D; (T)e.value; return result; &#125; &#125; &#x2F;&#x2F; 到这里说明map为null，或者获取的Entry为null，初始化 return setInitialValue();&#125; ThreadLocalMap的getEntry方法: 12345678910111213private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; &#x2F;&#x2F; 通过hashcode定位数组坐标 int i &#x3D; key.threadLocalHashCode &amp; (table.length - 1); Entry e &#x3D; table[i]; &#x2F;&#x2F; 如果坐标的Entry所属的key正是要提取的key，直接返回 if (e !&#x3D; null &amp;&amp; e.get() &#x3D;&#x3D; key) return e; else &#x2F;&#x2F; 顺着坐标往右寻找 return getEntryAfterMiss(key, i, e);&#125; 如果通过哈希值寻找Entry失败，也就是出现了坐标冲突，那就要往后遍历寻找: 12345678910111213141516171819202122232425private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab &#x3D; table; int len &#x3D; tab.length; &#x2F;&#x2F; 只要e不为null，就循环下去 while (e !&#x3D; null) &#123; ThreadLocal&lt;?&gt; k &#x3D; e.get(); &#x2F;&#x2F; 地址吻合说明当前Entry就是要找的对象，直接返回 if (k &#x3D;&#x3D; key) return e; &#x2F;&#x2F; 如果发现过期元素，执行清除方法 if (k &#x3D;&#x3D; null) expungeStaleEntry(i); else &#x2F;&#x2F; 记录遍历坐标的i+1 i &#x3D; nextIndex(i, len); &#x2F;&#x2F; 下一个Entry赋值给e e &#x3D; tab[i]; &#125; &#x2F;&#x2F; 到这里说明整个数组就不存在这个key return null; &#125; setInitialValue方法没啥逻辑，就是初始化线程的threadLocals: 12345678910111213141516171819private T setInitialValue() &#123; &#x2F;&#x2F; 这个方法写死的，返回null T value &#x3D; initialValue(); &#x2F;&#x2F;获取当前线程 Thread t &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取当前线程的threadLocals ThreadLocalMap map &#x3D; getMap(t); &#x2F;&#x2F; 通过get方法进入的，map肯定为null if (map !&#x3D; null) map.set(this, value); else &#x2F;&#x2F; 初始化threadLocals，并插入一个value为null的Entry createMap(t, value); return value;&#125; get方法相对于set方法而言要简单很多，无非就是根据哈希值计算数组坐标，顺带也会清理过期元素。 remove()源码ThreadLocal的remove()方法: 12345678public void remove() &#123; &#x2F;&#x2F; 获取当前线程的map ThreadLocalMap m &#x3D; getMap(Thread.currentThread()); &#x2F;&#x2F; 如果猫已经初始化，调用map的remove方法 if (m !&#x3D; null) m.remove(this);&#125; ThreadLocalMap的remove方法: 1234567891011121314151617181920212223242526private void remove(ThreadLocal&lt;?&gt; key) &#123; &#x2F;&#x2F; 获取数组信息 Entry[] tab &#x3D; table; int len &#x3D; tab.length; &#x2F;&#x2F; 通过哈希值计算数组坐标赋值给i int i &#x3D; key.threadLocalHashCode &amp; (len-1); &#x2F;&#x2F; 顺着坐标i往右遍历 for (Entry e &#x3D; tab[i]; e !&#x3D; null; e &#x3D; tab[i &#x3D; nextIndex(i, len)]) &#123; &#x2F;&#x2F; 如果发现过期元素 if (e.get() &#x3D;&#x3D; key) &#123; &#x2F;&#x2F; 对当前Entry进行清理，方便GC回收 e.clear(); &#x2F;&#x2F; 这个方法上面已经讲过了，向右扫描并清理过期元素 expungeStaleEntry(i); return; &#125; &#125;&#125; remove方法的作用不仅仅是清除指定的key，还会调用expungeStaleEntry()方法将清除的坐标继续向右遍历，清除遇到的所有过期元素，并且将null的坐标剔除掉。 内存泄漏以上面提到的储用户信息的场景为例，展示某请求线程在整个栈内存和堆内存的引用情况: 图中可以看出来ThreadLocal实例被一个强引用和一个弱引用(具体作用就不说了)指向，由于强引用是静态常量不可能被GC回收掉，请求线程必须要等到生命周期结束，自身包括内部的ThreadLocals才会被GC回收掉，弱引用在此处没有任何意义。 在使用线程池的时候有些线程可能很长时间才会死亡，核心线程甚至一直存活，这种情况要避免使用静态常量修饰ThreadLocal对象，因为线程一直执行任务，不停的积攒局部变量，由于静态常量强引用的存在，Entry的key不可能为null，value就永远不会被回收，当ThreadLocalMap中的entry足够多且占用内存较大时，很有可能发生内存溢出。 解决上述内存泄漏的办法就是每次都new一个ThreadLocal对象存取局部变量，逻辑处理完后手动调用remove()方法。ThreadLocal对象的引用在虚拟机栈的栈桢中，当方法执行完毕后将ThreadLocal设置为null，那么此时就只有entry的key以弱引用的方式指向堆中的ThreadLocal实例，因此ThreadLocal实例也会被回收，remove()会将key为null的entry清理掉，就不会发生内存溢出。 总结线程的局部变量是存储在线程自身的ThreadLocalMap中，而ThreadLocal对象仅仅只是个方便存取数据的快捷键而已，一般都是创建静态变量并提供静态存取方法，使用起来比较方便。另外在使用完毕后尽量使用remove()方法进行清理，方便GC尽快回收。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十五) 同步工具类-Phaser","slug":"同步工具类-Phaser","date":"2020-03-15T05:00:00.000Z","updated":"2021-02-19T09:24:21.294Z","comments":true,"path":"2020/03/15/同步工具类-Phaser/","link":"","permalink":"http://yoursite.com/2020/03/15/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-Phaser/","excerpt":"","text":"简介Phaser表示阶段器，用来解决控制多个线程分阶段共同完成任务的情景问题。它的功能与 CyclicBarrier和CountDownLatch有些类似，类似于一个多阶段的栅栏，并且功能更强大。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十四) 同步工具类-Exchanger","slug":"同步工具类-Exchanger","date":"2020-03-14T05:00:00.000Z","updated":"2021-02-19T09:24:09.250Z","comments":true,"path":"2020/03/14/同步工具类-Exchanger/","link":"","permalink":"http://yoursite.com/2020/03/14/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-Exchanger/","excerpt":"","text":"简介Exchanger也是一个线程同步的辅助类，用于两个线程之间交换信息。通过exchange方法相互交换数据，如果第一个执行到exchange方法，会等待第二个线程执行exchange，当两个线程都到达时，会进行数据交换。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十三) 同步工具类-Semaphore","slug":"同步工具类-Semaphore","date":"2020-03-13T05:00:00.000Z","updated":"2020-11-10T07:43:28.121Z","comments":true,"path":"2020/03/13/同步工具类-Semaphore/","link":"","permalink":"http://yoursite.com/2020/03/13/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-Semaphore/","excerpt":"","text":"基本概念Semaphore也是一个线程同步的辅助类，在多线程环境下用于协调各个线程, 以保证它们能够正确、合理的使用公共资源。信号量维护了一个许可集，我们在初始化Semaphore时需要为这个许可集传入一个数量值，该数量值代表同一时间能访问共享资源的线程数量。 使用场景这个应用就比较广泛了，主要用于流量控制，例如限制某接口或者静态资源的最大并发访问数，上代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Test &#123; private static Semaphore semaphore &#x3D; new Semaphore(2); public static void main(String[] args) &#123; for(int i &#x3D;1; i &lt;&#x3D; 10; i++)&#123; Thread thread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; select(); &#125; &#125;); thread.setName(&quot;线程序号&quot; + i); thread.start(); &#125; &#125; private static Object select()&#123; try &#123; &#x2F;&#x2F; 注册 semaphore.acquire(); &#x2F;&#x2F; 模拟查询耗时 Thread.currentThread().sleep(500L); &#x2F;&#x2F; 打印信息 StringBuilder info &#x3D; new StringBuilder(); info.append(Thread.currentThread().getName()); info.append(&quot;进入查询方法,&quot;); info.append(&quot;空闲通道:&quot;).append(semaphore.drainPermits()); info.append(&quot;,&quot;); info.append(&quot;等待线程数:&quot;).append(semaphore.getQueueLength()); System.out.println(info.toString()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; &#x2F;&#x2F; 释放 semaphore.release(); &#125; return new Object(); &#125;&#125; 打印结果:线程序号1进入查询方法,空闲通道:0,等待线程数:8线程序号2进入查询方法,空闲通道:0,等待线程数:8线程序号3进入查询方法,空闲通道:0,等待线程数:6线程序号4进入查询方法,空闲通道:0,等待线程数:6线程序号5进入查询方法,空闲通道:0,等待线程数:4线程序号6进入查询方法,空闲通道:1,等待线程数:4线程序号7进入查询方法,空闲通道:0,等待线程数:3线程序号8进入查询方法,空闲通道:0,等待线程数:2线程序号9进入查询方法,空闲通道:0,等待线程数:1线程序号10进入查询方法,空闲通道:0,等待线程数:0 打印结果可以看出来，同一时刻只能有2个线程对方法进行访问。 构造器源码12345678910&#x2F;&#x2F; 默认使用非公平锁public Semaphore(int permits) &#123; sync &#x3D; new NonfairSync(permits);&#125;&#x2F;&#x2F; 可以通过构造器参数指定是否公平竞争public Semaphore(int permits, boolean fair) &#123; sync &#x3D; fair ? new FairSync(permits) : new NonfairSync(permits);&#125; Semaphore对象可以通过构造器指定访问限制，还可以指定争夺的公平方式。 Sync源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID &#x3D; 1192457210091910933L; &#x2F;&#x2F; 初始化访问 Sync(int permits) &#123; setState(permits); &#125; final int getPermits() &#123; return getState(); &#125; &#x2F;&#x2F; 非公平方式获取AQS共享式资源 final int nonfairTryAcquireShared(int acquires) &#123; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F; 获取state值 int available &#x3D; getState(); &#x2F;&#x2F; 计算获取资源后值应该是多少 int remaining &#x3D; available - acquires; &#x2F;&#x2F; 如果大于等于0说明满足条件，将计算后值通过CAS修改后返回，如果小于0直接返回 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; &#x2F;&#x2F; 释放锁，就是把state加回来 protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; &#x2F;&#x2F; 获取state值 int current &#x3D; getState(); &#x2F;&#x2F; 计算加后的值 int next &#x3D; current + releases; &#x2F;&#x2F; 如果加后值小于当前state值，说明参数为负数，抛异常 if (next &lt; current) &#x2F;&#x2F; overflow throw new Error(&quot;Maximum permit count exceeded&quot;); &#x2F;&#x2F; 使用CAS方式修改值 if (compareAndSetState(current, next)) return true; &#125; &#125; &#x2F;&#x2F; state减操作 final void reducePermits(int reductions) &#123; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F; 获取state值 int current &#x3D; getState(); &#x2F;&#x2F; 计算减后的值 int next &#x3D; current - reductions; &#x2F;&#x2F; 如果减后值大于当前state值，说明参数为负数，抛异常 if (next &gt; current) &#x2F;&#x2F; underflow throw new Error(&quot;Permit count underflow&quot;); &#x2F;&#x2F; 使用CAS方式修改值 if (compareAndSetState(current, next)) return; &#125; &#125; &#x2F;&#x2F; 将state归零 final int drainPermits() &#123; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F; 获取state int current &#x3D; getState(); &#x2F;&#x2F; 如果是0直接返回0，不是0使用CAS设置成0在返回0，这是要干啥？ if (current &#x3D;&#x3D; 0 || compareAndSetState(current, 0)) return current; &#125; &#125;&#125; Sync类实现了很多方法: nonfairTryAcquireShared():非公平性获取共享式锁，不进行排队直接自旋获取。 tryReleaseShared():释放共享式锁，使用CAS方式对state执行加操作。 reducePermits():使用CAS方式对state执行减操作。 drainPermits():将state设置为0并返回，不知道想干啥? 公平/非公平Sync源码1234567891011121314151617181920212223242526272829303132333435363738&#x2F;&#x2F; 非公平static final class NonfairSync extends Sync &#123; private static final long serialVersionUID &#x3D; -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; &#x2F;&#x2F; 调用父类写好的方法，非公平式获取锁 protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125;&#125;&#x2F;&#x2F; 公平static final class FairSync extends Sync &#123; private static final long serialVersionUID &#x3D; 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; &#x2F;&#x2F; 无限自旋直到CAS修改成功 protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; &#x2F;&#x2F; 比非公平锁多了一个步骤，判断前面是否有人,如果前面有人就放弃 if (hasQueuedPredecessors()) return -1; int available &#x3D; getState(); int remaining &#x3D; available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125;&#125; 公平与非公平Sync逻辑几乎一样，只是公平锁在尝试获取资源的时候会先去判断前面是否已经有人，如果有人就放弃尝试，进入AQS的等待阻塞方法。而非公平锁不管前面有没有人都会尝试获取直到成功。 acquire()源码123456789101112131415161718192021public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; &#x2F;&#x2F; 先判断是否已经被中断 if (Thread.interrupted()) throw new InterruptedException(); &#x2F;&#x2F; 如果访问次数已经耗尽，进入doAcquireSharedInterruptibly()方法阻塞 if (tryAcquireShared(arg) &lt; 0) &#x2F;* * 源码就不贴了，AQS写好的方法: * 排在等待队列的第一个，自旋等待直到重写方法tryAcquireShared(arg)返回值大于0跳出自旋 * 排在等待队列的第二个开始，直接挂起一边呆着去... *&#x2F; doAcquireSharedInterruptibly(arg);&#125; 总结这没啥好说的，只不过现在都是分布式项目，如果限流的目的是减少数据库或静态资源的访问，单靠Semaphore无法实现，还需要依靠基于Redis或Zookeeper的分布式锁实现，感觉用处不多。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十二) 同步工具类-CyclicBarrier","slug":"同步工具类-CyclicBarrier","date":"2020-03-12T05:00:00.000Z","updated":"2020-11-10T07:19:10.297Z","comments":true,"path":"2020/03/12/同步工具类-CyclicBarrier/","link":"","permalink":"http://yoursite.com/2020/03/12/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-CyclicBarrier/","excerpt":"","text":"基本概念CyclicBarrier是一个同步的辅助类，允许一组线程相互之间等待，并设置一个公共屏障点，当组内线程达到这个屏障点的时候阻塞，阻塞在这个屏障点的线程数达到指定数量时，释放所有线程继续往下执行。CyclicBarrier在释放完线程后相当于重置之前的记录可以循环使用，所以称之为Cyclic(循环)Barrier(屏障)。 使用场景开发经历有限，目前为止还真没用过CyclicBarrier，一般场景使用CountDownLatch就够了，就随便写点吧。 1234567891011121314151617181920212223242526272829303132public class Test &#123; private static CyclicBarrier cyclicBarrier &#x3D; new CyclicBarrier(5, new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;屏障点回调线程，执行者:&quot; + Thread.currentThread().getName()); &#125; &#125;); public static void main(String[] args) &#123; for(int i &#x3D; 0; i&lt; 5;i++)&#123; Thread thread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + &quot;开始运行&quot;); cyclicBarrier.await(); System.out.println(Thread.currentThread().getName() + &quot;结束运行&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); thread.setName(&quot;线程&quot; + i); thread.start(); &#125; &#125;&#125; 打印结果:线程1开始运行线程0开始运行线程2开始运行线程3开始运行线程4开始运行屏障点回调线程，执行者:线程4线程4结束运行线程1结束运行线程0结束运行线程2结束运行线程3结束运行 打印结果可以看出来，当指定数量(构造器参数决定)的线程到达屏障点(await代码行)后，才能继续往下执行。如果在构造器中指定了回调线程，还需要等待回调线程执行完才可以往下执行，回调线程由最后一个阻塞的线程执行。 构造器源码12345678910111213&#x2F;&#x2F; 设置屏障阈值public CyclicBarrier(int parties) &#123; this(parties, null);&#125;&#x2F;&#x2F; 设置屏障阈值，同时增加回调线程功能public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;&#x3D; 0) throw new IllegalArgumentException(); this.parties &#x3D; parties; this.count &#x3D; parties; this.barrierCommand &#x3D; barrierAction;&#125; 成员变量1234567891011121314151617181920&#x2F;&#x2F; lock对象private final ReentrantLock lock &#x3D; new ReentrantLock();&#x2F;&#x2F; 跳闸，可以理解为打开屏障private final Condition trip &#x3D; lock.newCondition();&#x2F;&#x2F; 屏障阈值private final int parties;&#x2F;&#x2F; 回调线程private final Runnable barrierCommand;&#x2F;&#x2F; 每次使用屏障都会生成，内部的broken标记屏障是否破损private Generation generation &#x3D; new Generation();&#x2F;&#x2F; 默认设置falseprivate static class Generation &#123; boolean broken &#x3D; false;&#125; await()源码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192 &#x2F;&#x2F; 内部调用dowait()方法，并且参数传false，不支持超时 public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); &#x2F;&#x2F; cannot happen &#125; &#125; &#x2F;&#x2F; 真正进入等待的逻辑 private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock &#x3D; this.lock; &#x2F;&#x2F; 获取排他锁 lock.lock(); try &#123; final Generation g &#x3D; generation; &#x2F;&#x2F; 屏障被破坏则抛异常 if (g.broken) throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; &#x2F;&#x2F; 线程中断 则退出屏障 breakBarrier(); throw new InterruptedException(); &#125; &#x2F;&#x2F; 到达屏障的计数-1 int index &#x3D; --count; if (index &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; tripped &#x2F;&#x2F; index &#x3D;&#x3D; 0, 说明指定 count 的线程均到达屏障，此时可以打开屏障 boolean ranAction &#x3D; false; try &#123; final Runnable command &#x3D; barrierCommand; if (command !&#x3D; null) &#x2F;&#x2F; 若指定了 barrierCommand 则执行 command.run(); ranAction &#x3D; true; &#x2F;&#x2F; 唤醒阻塞在屏障的线程并重置 generation nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier(); &#125; &#125; &#x2F;&#x2F; loop until tripped, broken, interrupted, or timed out for (;;) &#123; try &#123; if (!timed) &#x2F;&#x2F; 若未指定阻塞在屏障处的等待时间，则一直等待；直至最后一个线程到达屏障处的时候被唤醒 trip.await(); else if (nanos &gt; 0L) &#x2F;&#x2F; 若指定了阻塞在屏障处的等待时间，则在指定时间到达时会返回 nanos &#x3D; trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g &#x3D;&#x3D; generation &amp;&amp; ! g.broken) &#123; &#x2F;&#x2F; 若等待过程中，线程发生了中断，则退出屏障 breakBarrier(); throw ie; &#125; else &#123; &#x2F;&#x2F; We&#39;re about to finish waiting even if we had not &#x2F;&#x2F; been interrupted, so this interrupt is deemed to &#x2F;&#x2F; &quot;belong&quot; to subsequent execution. Thread.currentThread().interrupt(); &#125; &#125; &#x2F;&#x2F; 屏障被破坏 则抛出异常 if (g.broken) throw new BrokenBarrierException(); if (g !&#x3D; generation) &#x2F;&#x2F; g !&#x3D; generation 说明所有线程均到达屏障处 可直接返回 &#x2F;&#x2F; 因为所有线程到达屏障处的时候，会重置 generation &#x2F;&#x2F; 参考 nextGeneration return index; if (timed &amp;&amp; nanos &lt;&#x3D; 0L) &#123; &#x2F;&#x2F; 说明指定时间内，还有线程未到达屏障处，也就是等待超时 &#x2F;&#x2F; 退出屏障 breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; nextGeneration()源码1234567891011private void nextGeneration() &#123; &#x2F;&#x2F; 唤醒阻塞在等待队列的线程 trip.signalAll(); &#x2F;&#x2F; 重置 count count &#x3D; parties; &#x2F;&#x2F; 重置 generation generation &#x3D; new Generation();&#125; breakBarrier()源码1234567891011private void breakBarrier() &#123; &#x2F;&#x2F; broken 设置为 true generation.broken &#x3D; true; &#x2F;&#x2F; 重置 count count &#x3D; parties; &#x2F;&#x2F; 唤醒等待队列的线程 trip.signalAll();&#125; reset()源码12345678910final ReentrantLock lock &#x3D; this.lock;lock.lock();try &#123; &#x2F;&#x2F; 唤醒阻塞的线程 breakBarrier(); &#x2F;&#x2F; break the current generation &#x2F;&#x2F; 重新设置 generation nextGeneration(); &#x2F;&#x2F; start a new generation&#125; finally &#123; lock.unlock();&#125; 总结CyclicBarrier依赖与Lock与Condition实现，await()方法使用Lock进行互斥，Condition对象负责挂起被屏障挡住的线程。Lock与Condition底层是基于AQS的，所以CyclicBarrier还是通过AQS实现。 CyclicBarrier内部有个屏障是否被打破的概念，维护在内部类Generation的broken属性中(默认是false)，并且可以通过breakBarrier()方法进行打破(修改为true)，调用这个方法的地方有三个，检测到中断、等待超时、reset()方法。当某个线程在等待过程中被中断或超时，会直接抛中断异常退出等待，不会对count执行-1操作，这会导致同一组线程会无限等待下去，因为count值永远无法到达0。使用reset()方法会重置count值，为了避免重置时还有残余线程没执行到await()方法，干扰重置后的count值导致下一轮提前结束。当遇到这些情况时，CyclicBarrier会修改broken=true来通知其他线程不要再等下去了。 CountDownLatch与CyclicBarrier区别: CountDownLatch CyclicBarrier 一个线程(或多个)线程等待另N个线程完成某事后才能继续执行 N个线程相互在某个点等待，知道所有线程都到达这个点解除等待 无法重复利用，没有提供state属性的重置方法 可以重复利用，提供reset()方法重置","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十一) 同步工具类-CountDownLatch","slug":"同步工具类-CountDownLatch","date":"2020-03-11T05:00:00.000Z","updated":"2020-11-17T14:38:18.233Z","comments":true,"path":"2020/03/11/同步工具类-CountDownLatch/","link":"","permalink":"http://yoursite.com/2020/03/11/%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB-CountDownLatch/","excerpt":"","text":"基本概念CountDownLatch是一种线程同步工具类，它允许一个或多个线程等待直到在其他线程中一组操作执行完成。你可以把它理解为一个计数器，对象被创建的时候指定总数，每有一个线程到达指定条件总数减1，当减到为0时代表所有线程都达到条件，所有等待线程被唤醒继续往下执行，因此CountDownlatch也被称为倒计时锁。 使用场景例如运营系统的流量、业务等统计功能，页面需要统计展示每日的新增用户量、订单数量、商品销售总量、商品销售总额等。如果每个统计类型的查询需要2秒，4个统计类型就需要8秒的时间才能返回给前端，用户显然是无法接受的。我们只需要将4个统计类型的查询由串行执行改为并行执行，等待所有线程都查询完在组装返回，那么整个请求的响应时间就缩短到的了2秒。 写个简单的Demo: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class Test &#123; public static void main(String[] args) &#123; long startTimeMillis &#x3D; System.currentTimeMillis(); CountDownLatch countDownLatch &#x3D; new CountDownLatch(4); Map&lt;String, Long&gt; statisticsMap &#x3D; new Hashtable&lt;&gt;(); &#x2F;&#x2F; 1.查询新增用户量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;addUserCount&quot;, 1000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 2.查询订单数量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;orderCount&quot;, 248300L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 3.查询商品销售总量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;commodityCount&quot;, 300L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 4.查询商品销售总额 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;totalSales&quot;, 9073180L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; long takeTimeMillis &#x3D; System.currentTimeMillis() - startTimeMillis; System.out.println(&quot;耗时:&quot; + takeTimeMillis + &quot;ms&quot;); System.out.println(&quot;返回值:&quot; + statisticsMap); &#125;&#125; 耗时:2006ms返回值:{commodityCount=300, totalSales=9073180, orderCount=248300, addUserCount=1000} 构造器源码1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync &#x3D; new Sync(count);&#125; CountDownLatch底层基于AQS实现，当我们调用CountDownLatch countDownLatch= new CountDownLatch(4) 创建一个实例时，会在对象内部创建一个继承AQS的Sync类，并将构造器的参数值赋值给state，所以state的值也代表CountDownLatch所剩余的计数次数。 Sync源码1234567891011121314151617181920212223242526272829303132333435363738private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID &#x3D; 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; &#x2F;&#x2F; 根据计数值是否耗尽(为0就算耗尽)，返回正数(1)或者负数(-1) protected int tryAcquireShared(int acquires) &#123; return (getState() &#x3D;&#x3D; 0) ? 1 : -1; &#125; &#x2F;&#x2F; 共享式释放锁的逻辑重写，主要提供给countDown()使用 protected boolean tryReleaseShared(int releases) &#123; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F; 获取当前state值 int c &#x3D; getState(); &#x2F;&#x2F; 如果state&#x3D;0，说明计数值已经耗尽了，不需要继续释放 if (c &#x3D;&#x3D; 0) return false; &#x2F;&#x2F; 使用CAS方式-1 int nextc &#x3D; c-1; &#x2F;&#x2F; 如果减完为0，证明是最后一个释放的，返回true if (compareAndSetState(c, nextc)) return nextc &#x3D;&#x3D; 0; &#125; &#125;&#125; Sync除了维护了state值以外，分别重写了tryAcquireShared()与tryReleaseShared()方法，主要提供给CountDownLatch的countDown()与await()方法调用。 countDown()源码1234567891011121314151617181920 &#x2F;&#x2F; 内部调用AQS的共享式释放锁public void countDown() &#123; sync.releaseShared(1); &#125; &#x2F;&#x2F; AQS的共享式释放锁 public final boolean releaseShared(int arg) &#123; &#x2F;&#x2F; if中的方法被CountDownLatch重写，仅当state不为0并且修改后为0时才返回true if (tryReleaseShared(arg)) &#123; &#x2F;&#x2F; 如果state修改后是0，说明自己是最后一个执行完毕的，需要唤醒所有等待的线程 doReleaseShared(); &#x2F;&#x2F; countDown()方法并没有利用返回值做其他事情，可以无视 return true; &#125; return false; &#125; countDown()方法的逻辑非常简单，就是利用静态内部类Sync的重写方法tryReleaseShared()，使用CAS方式对计数值(state)-1操作。如果返回true证明自身是最后一个执行完成的，还需要唤醒所有阻塞的等待线程。 await()源码12345678910111213141516171819 &#x2F;&#x2F; 内部调用AQS的共享式获取锁方式(支持中断)public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; &#x2F;&#x2F; AQS共享式获取锁方式(支持中断) public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; &#x2F;&#x2F; 如果已经是中断状态，直接抛出来 if (Thread.interrupted()) throw new InterruptedException(); &#x2F;&#x2F; 调用重写的共享式获取锁方法，如果返回值小于0证明计数值还没有耗尽，需要加入等待队列 if (tryAcquireShared(arg) &lt; 0) &#x2F;&#x2F; AQS的方法，前面已经解释过了，排队的第一个自旋等待，后面的挂起等待，直到tryAcquireShared()&gt;&#x3D;0 doAcquireSharedInterruptibly(arg); &#125; await()方法无非就是阻塞，第一个调用此方法的线程是自旋等待，直到计数值耗尽(state=0)跳出，如果有多个线程调用此方法等待，则使用park()函数挂起直到被唤醒。并且提供重载方法支持超时放弃，等待过程中支持中断响应。 await(timeout, unit)源码12345678910111213141516171819&#x2F;&#x2F; 内部调用AQS的共享式获取锁方式(支持超时与中断)public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));&#125;&#x2F;&#x2F; AQS的共享式获取锁方式(支持超时与中断)public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; &#x2F;&#x2F; 先做中断校验 if (Thread.interrupted()) throw new InterruptedException(); &#x2F;&#x2F; 如果tryAcquireShared()方法返回值大于0，也就是已经计数值已耗尽(state&#x3D;0) 直接返回就好了 &#x2F;&#x2F; 如果没有耗尽，进入阻塞方法，也是AQS源码 不解释了... return tryAcquireShared(arg) &gt;&#x3D; 0 || doAcquireSharedNanos(arg, nanosTimeout);&#125; 在await()基础上增加超时功能，防止意外情况导致条件永远无法满足，等待线程一直阻塞。 总结CountDownLatch的作用是牺牲运行内存(额外创建的线程需要额外的栈空间支出)以及CPU资源(请求过程中会有额外的线程加入CPU使用权争夺)来提高请求的响应效率。因此CountDownLatch不能盲目使用，要参考JVM大小、CPU核数等配置信息，还要估算接口的QPS，避免大量请求导致JVM栈溢出或CPU使用率到100%。 在创建CountDownLatch时，构造器参数值一定要和处理任务的子线程数相等，避免高于子线程数量造成死锁，或者低于子线程数造成部门数据丢失。子线程的countDown()方法最好放在finally代码块中，避免执行过程中出现异常导致没有被执行。为了保险起见，主线程最好使用支持超时的await()进行等待，彻底解决可能出现的死锁情况。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十) 线程通信","slug":"线程通信","date":"2020-03-10T05:00:00.000Z","updated":"2021-02-19T09:30:40.355Z","comments":true,"path":"2020/03/10/线程通信/","link":"","permalink":"http://yoursite.com/2020/03/10/%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1/","excerpt":"","text":"简介线程与线程之间不是相互独立的个体，有些时候需要相互通信来共同完成某个业务场景，多线程之间通信总体来说分为共享内存和消息通信机制。 wait/notify概念wait/notify采用消息通信机制来进行线程间的通信，某个线程必须达到特定条件才能继续执行下去，没有达到就将自己挂起等待，另一个线程的执行过程中会使条件达成并通知挂起等待的线程继续执行下去。 wait/notify都属于Object的方法，利用java自带的对象加锁机制争夺对应monitor，当线程不满足执行条件时调用Object的wait方法将自己挂起在monitor对象的_WaitSet上，其他线程在执行过程中将条件满足，紧接着使用Object的notify或notifyAll方法唤醒前述的等待线程，重新加入锁的竞争。 使用场景例如线程独有的join()方法就是通过wait/notify实现线程的合并(非异步调用)，在join线程执行过程中调用者线程只能等待，为了避免CPU的浪费，使用wait()方法将自己挂起在join线程的monitor对象的_WaitSet中，当join线程执行完毕后使用notify()唤醒调用者线程，继续往下执行。 简单的使用场景比如RocketMQ拉取消息时的长轮询机制，在拉取不到消息的时候将其挂起，直到Producer向本结点投递消息时，唤醒挂起的请求线程，拉取消息并返回。 复杂点的使用场景例如生产者/消费者模式，消费者线程使用while循环监听消息，如果消息队列为空则使用wait()将自己挂起，同样避免忙等造成CPU的浪费，生产者线程每次生产完数据都必须调用notify()方法，唤醒因消息队列为空而将自己挂起的消费者线程。下面是一段基于wait/notify机制的生产/消费模型： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Test &#123; private static Object obj &#x3D; new Object(); private static final Queue&lt;String&gt; messageQueue &#x3D; new LinkedBlockingDeque&lt;&gt;(); public static void main(String[] args) throws Exception &#123; Thread producerThread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i &#x3D; 1; i &lt;&#x3D; 9; i++) &#123; &#x2F;&#x2F; 生产消息 synchronized (obj) &#123; messageQueue.add(&quot;第&quot; + i + &quot;条消息&quot;); obj.notify(); &#125; &#x2F;&#x2F; 每生产三条暂停1秒 if (i &gt; 1 &amp;&amp; i % 3 &#x3D;&#x3D; 0) &#123; try &#123; System.out.println(&quot;暂停&quot;); Thread.currentThread().sleep(1000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#x2F;&#x2F; ... &#125; &#125; &#x2F;&#x2F; ... &#125;); Thread consumerThread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (obj) &#123; try &#123; while (true) &#123; if (messageQueue.isEmpty()) &#123; obj.wait(); &#125; String message &#x3D; messageQueue.poll(); System.out.println(&quot;消费者:&quot; + message); &#125; &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#x2F;&#x2F; ... &#125;); producerThread.start(); consumerThread.start(); &#125;&#125; 使用细节为什么wait()、notify()、notifyAll()必须在同步代码块中？这三个方法都是对对象的monitor中的_WaitSet进行操作，而进入同步代码块意味着已经持有对象锁，也就持有了monitor，才有资格对_WaitSet进行操作，因此必须在同步代码块中。 为什么wait()方法要放在while()循环而不是if中？被唤醒后线程从wait()代码之后继续执行，但是并不能保证每次被唤醒都是符合继续执行条件的，用while()被唤醒还会继续判断，不符合条件永远在while()中，而if不会。在N个线程通信的情况下，不能保证那一时刻条件被某个线程改变。 为什么wait()、notify()要定义在Object中而不是线程中？wait()与notify()的基本思想是把某个对象作为联络点，利用锁机制拿到monitor进行联络通信，而java提供的锁是对象级的而不是线程级的，锁属于对象而不是线程专有，因此wait()、notify()、notifyAll()这种锁级别操作属于Object而不是线程专有方法。 lock/condition概念既然java支持使用锁进行线程通信，synchronized可以，Lock必然也可以。lock/condition与wait/notify功能类似，通过Lcok对象创建Condition对象，利用Condition对象的await()与signal()方法来阻塞唤醒。 使用场景无 简单总结","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(九) Lock家族","slug":"Lock家族","date":"2020-03-09T05:00:00.000Z","updated":"2020-10-22T07:48:58.201Z","comments":true,"path":"2020/03/09/Lock家族/","link":"","permalink":"http://yoursite.com/2020/03/09/Lock%E5%AE%B6%E6%97%8F/","excerpt":"","text":"Lock继承体系Lock接口Lock接口诞生于JDK1.5，接口内部提供了最基本的加锁、释放锁方法: 1234567891011121314151617181920public interface Lock &#123; &#x2F;&#x2F; 直接加锁 void lock(); &#x2F;&#x2F; 支持可中断的加锁 void lockInterruptibly() throws InterruptedException; &#x2F;&#x2F; 尝试一次加锁 boolean tryLock(); &#x2F;&#x2F; 尝试一次加锁(支持超时停止阻塞) boolean tryLock(long time, TimeUnit unit) throws InterruptedException; &#x2F;&#x2F; 解锁 void unlock(); &#x2F;&#x2F; 创建一个Condition(作用于线程通信，后面会讲) Condition newCondition(); 使用层面既然是接口，就是提供给开发者实现用的，Java自带了ReentrantLock、Condition、ReentrantReadWriteLock实现类供开发者使用。如果这些类无法满足业务需求，开发者可以通过实现Lock接口并利用AQS框架，自己定义一个Lock的具体实现锁(是否公平、是否支持超时、是否支持重入等)，从而提高锁的灵活性。 与synchronized区别由于Lock可以自己定义是否公平、是否支持超时、是否支持重入等功能，相对于synchronized关键字来说可发挥的空间更多，也更灵活。但是Lock的加锁、释放锁需要开发者自己编写，如果考虑不周很可能造成死锁情况(最好在try中加锁，finally中释放锁)，而synchronized由JVM实现，完全不需要担心这些情况。 ReentrantLockReentrantLock就是Java自带的Lock实现类，字面的意思就能看出来是一把可重入锁，并且功能几乎与synchronized相似，我们看看源码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; &#x2F;&#x2F; 定义一个顶级同步器(内部包含一个非公平加锁方法，一个释放锁方法) abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID &#x3D; -5179523762034025860L; abstract void lock(); &#x2F;&#x2F; 非公平方式尝试一次加锁 final boolean nonfairTryAcquire(int acquires) &#123; &#x2F;&#x2F; 获取试图尝试加锁的线程 final Thread current &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取公共资源状态 int c &#x3D; getState(); &#x2F;&#x2F; 如果没其他线程持有锁，进行加锁 if (c &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 加锁前并没有校验等待队列是否已经有节点在等待了，这个if完全体现了非公平性 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; &#x2F;&#x2F; 如果有线程持有锁并且是自身，重入次数递增 else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123; int nextc &#x3D; c + acquires; if (nextc &lt; 0) &#x2F;&#x2F; overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; &#x2F;&#x2F; 到这里说明锁被其他线程占了，直接返回false return false; &#125; &#x2F;&#x2F; 释放锁 protected final boolean tryRelease(int releases) &#123; &#x2F;&#x2F; 计算递减后的重入次数 int c &#x3D; getState() - releases; &#x2F;&#x2F; 如果释放锁线程不是持有锁线程，抛异常(一般能执行这方法的都是持有锁线程) if (Thread.currentThread() !&#x3D; getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); &#x2F;&#x2F; 如果递减后为0，那就是真的释放锁了，清空自己的独占状态并返回 boolean free &#x3D; false; if (c &#x3D;&#x3D; 0) &#123; free &#x3D; true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; &#x2F;&#x2F; 返回调用此方法的线程是否持有锁 protected final boolean isHeldExclusively() &#123; return getExclusiveOwnerThread() &#x3D;&#x3D; Thread.currentThread(); &#125; &#x2F;&#x2F; 其他方法... &#125; &#x2F;&#x2F; 定义一个非公平同步器，继承顶级同步器 static final class NonfairSync extends Sync &#123; private static final long serialVersionUID &#x3D; 7316153563782823691L; &#x2F;&#x2F; 实现顶级同步器的lock加锁方法 final void lock() &#123; &#x2F;&#x2F; 尝试CAS 如果成功说明之前没线程加锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); &#x2F;&#x2F; 失败就在尝试获取一次，这里调用AQS的acquire()方法， &#x2F;&#x2F; AQS的acquire()方法又调用下面重写的tryAcquire方法 else acquire(1); &#125; &#x2F;&#x2F; 绕了一大圈，其实就是用非公平锁方式加锁 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125; &#x2F;&#x2F; 定义一个公平同步器，继承顶级同步器 static final class FairSync extends Sync &#123; private static final long serialVersionUID &#x3D; -3000897897090466540L; final void lock() &#123; acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current &#x3D; Thread.currentThread(); int c &#x3D; getState(); if (c &#x3D;&#x3D; 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123; int nextc &#x3D; c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; &#125; &#x2F;&#x2F; 无参构造器，默认使用非公平锁 public ReentrantLock() &#123; sync &#x3D; new NonfairSync(); &#125; &#x2F;&#x2F; 参数构造器，自行选择是否公平 public ReentrantLock(boolean fair) &#123; sync &#x3D; fair ? new FairSync() : new NonfairSync(); &#125; &#x2F;&#x2F; 加锁 public void lock() &#123; sync.lock(); &#125; &#x2F;&#x2F; 支持可中断加锁 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; &#x2F;&#x2F; 尝试一次加锁 public boolean tryLock() &#123; return sync.nonfairTryAcquire(1); &#125; &#x2F;&#x2F; 支持超时的加锁 public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; &#x2F;&#x2F; 解锁 public void unlock() &#123; sync.release(1); &#125; &#x2F;&#x2F; 其他方法....&#125; 重入支持ReentrantLock通过state属性控制重入，每次重入state+1、退出state-1，为0时代表释放锁。 是否公平锁 ReentrantLock类支持公平锁与非公平锁，并根据构造器初始化一个Sync(公平锁创建FairSync，非公平锁创建NonfairSync)，后续加锁释放锁等操作完全调用Sync实现。FairSync与NonfairSync除了加锁逻辑不一样，其他的逻辑(比如释放锁等)完全一样。 ReentrantLock加锁是使用Sync的lock()实现，公平锁(FairSync)是直接调用AQS的acquire()方法获取锁，然后调用重写的tryAcquire()方法。在重写方法里面如果可以加锁(state=0)，会先判断等待队列是否有元素在等待，如果没有元素可以直接加锁，如果加锁失败或存在元素，则加入等待队列尾部等待(按顺序排队)。 非公平锁(NonFairSync)在调用Sync的lock()方法时，只要可以加锁(state=0)，会直接使用CAS进行加锁(无视等待队列是否有元素)，如果插队失败了在调用AQS的acquire()再次加锁，重写的tryAcquire()方法还是会再次尝试插队，如果还是失败才会加入等待队列，因此非公平锁存在2次插队的操作。 ReadWriteLock接口没啥好写的 ReentrantReadWriteLock没啥好写的","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(八) AQS","slug":"AQS","date":"2020-03-08T05:00:00.000Z","updated":"2020-11-09T04:31:26.002Z","comments":true,"path":"2020/03/08/AQS/","link":"","permalink":"http://yoursite.com/2020/03/08/AQS/","excerpt":"","text":"AQS简介AQS的全称是AbstractQueuedSynchronizer，类内部定义了一套多线程访问共享资源的同步器框架，Java许多同步类的实现都依赖于它，比如常用的ReentrantLock、Semaphore、CountDownLatch等，我们也可以利用AQS自己实现一个锁。 AQS类内部的核心为volatile int state(共享资源)和CLH线程等待队列(阻塞队列)，整个AQS类内部大量的方法都是围绕state、CLH队列在处理逻辑。 statestate作为共享资源被应用在多线程竞争上，自带的volatile关键字可以保证可见性、有序性，在搭配CAS使用后可以保证操作的原子性。state初始状态为0，线程使用CAS对state+1成功后持有锁，后续每次重入state+1、退出state-1，state递减为0时代表锁释放。 CLH队列当线程竞争失败后会被封装成Node节点加入CLH队列，CLH队列在AQS中是以前驱节点(head)、后驱节点(tail)俩个成员构成的Node类型链表: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&#x2F;&#x2F; 前驱节点private transient volatile Node head;&#x2F;&#x2F; 后驱节点private transient volatile Node tail;&#x2F;&#x2F; 静态内部类Nodestatic final class Node &#123; &#x2F;** 共享锁 *&#x2F; static final Node SHARED &#x3D; new Node(); &#x2F;** 独占锁 *&#x2F; static final Node EXCLUSIVE &#x3D; null; &#x2F;** 表示线程已被取消 *&#x2F; static final int CANCELLED &#x3D; 1; &#x2F;** 表示后续线程需要取消阻塞 *&#x2F; static final int SIGNAL &#x3D; -1; &#x2F;** 表示线程在条件下等待 *&#x2F; static final int CONDITION &#x3D; -2; &#x2F;** 表示下一个获取共享应无条件传播 *&#x2F; static final int PROPAGATE &#x3D; -3; &#x2F;** * 节点等待状态 * 等于0:该节点尚未被初始化完成 * 大于0:说明该线程中断或者等待超时，需要移除该线程 * 小于0:该线程处于可以被唤醒的状态 *&#x2F; volatile int waitStatus; &#x2F;** 前驱节点 *&#x2F; volatile Node prev; &#x2F;** 后继节点 *&#x2F; volatile Node next; &#x2F;** 获取同步状态的线程 *&#x2F; volatile Thread thread; &#x2F;** 将单向列表变成双向列表 *&#x2F; Node nextWaiter; &#x2F;&#x2F; 是否为共享节点 final boolean isShared() &#123; return nextWaiter &#x3D;&#x3D; SHARED; &#125; &#x2F;&#x2F; 获取前继节点，没有就抛出异常 final Node predecessor() throws NullPointerException &#123; Node p &#x3D; prev; if (p &#x3D;&#x3D; null) throw new NullPointerException(); else return p; &#125; &#x2F;&#x2F; 无参构造器 Node() &#123; &#125; &#x2F;&#x2F; 构造器 Node(Thread thread, Node mode) &#123; &#x2F;&#x2F; Used by addWaiter this.nextWaiter &#x3D; mode; this.thread &#x3D; thread; &#125; &#x2F;&#x2F; 构造器 Node(Thread thread, int waitStatus) &#123; &#x2F;&#x2F; Used by Condition this.waitStatus &#x3D; waitStatus; this.thread &#x3D; thread; &#125;&#125; Node内部类主要通过waitStatus来表示状态，主要有五种状态: 状态 状态值 描述 INITAL 0 初始状态 CANCELLED 1 此节点的后继节点(或即将)被阻塞，因此当前节点在释放或取消时必须取消对其后继节点的阻塞 SIGNAL -1 此节点的后继节点(或将很快)被阻塞(通过park)，因此当前节点在释放或取消时必须取消对其后继节点的阻塞。为了避免争用，获取方法必须首先表明它们需要一个信号，然后重试原子获取，然后在失败时阻塞 CONDITION -2 节点线程等待在Condition上，当其他线程对Condition调用了signal()方法后，该节点从等待队列中转移到同步队列中，加入到对同步状态的获取中 PROPAGATE -3 与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态 链表入列链表的入列采用CAS方式进行，前驱节点与后驱节都是被volatile修饰的，因此使用CAS修改可以保证绝对安全，在enq方法中AQS使用死循环保证节点可以正确添加，只有成功添加后，当前线程才会从该方法返回，否则会一直执行下去: 123456789101112131415161718192021222324252627282930313233343536private Node addWaiter(Node mode) &#123; &#x2F;&#x2F; 新建Node Node node &#x3D; new Node(Thread.currentThread(), mode); &#x2F;&#x2F; CAS快速尝试添加尾节点(侥幸心理，万一成功了呢) Node pred &#x3D; tail; if (pred !&#x3D; null) &#123; node.prev &#x3D; pred; &#x2F;&#x2F;CAS设置尾节点 if (compareAndSetTail(pred, node)) &#123; pred.next &#x3D; node; return node; &#125; &#125; &#x2F;&#x2F;多次尝试 enq(node); return node;&#125; private Node enq(final Node node) &#123; &#x2F;&#x2F;多次尝试，直到成功为止 for (;;) &#123; Node t &#x3D; tail; &#x2F;&#x2F;tail不存在，设置为首节点 if (t &#x3D;&#x3D; null) &#123; if (compareAndSetHead(new Node())) tail &#x3D; head; &#125; else &#123; &#x2F;&#x2F;设置为尾节点 node.prev &#x3D; t; if (compareAndSetTail(t, node)) &#123; t.next &#x3D; node; return t; &#125; &#125; &#125; &#125; 当线程被封装成Node节点成功追加到等待队列尾部后，为了节约CPU资源就需要将当前线程挂起了(被阻塞的线程如果支持可中断并且被中断，自动唤醒并抛出中断异常): 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051final boolean acquireQueued(final Node node, int arg) &#123; &#x2F;&#x2F; 获取资源是否失败标记 boolean failed &#x3D; true; try &#123; &#x2F;&#x2F;标记等待过程中是否被中断过 boolean interrupted &#x3D; false; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F;拿到前驱节点 final Node p &#x3D; node.predecessor(); &#x2F;* * 如果前驱是head，说明自己排在第二位，有可能马上就被执行 * 所以再次尝试tryAcquire()获取，如果失败就挂起等待 * 当然有可能是第一位搞完了释放资源唤醒自己，也有可能被interrupt *&#x2F; if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123; &#x2F;&#x2F; 获取到资源后，把自己设置为head，也就是说head指向的永远是当前拿到资源的 setHead(node); &#x2F;&#x2F; 断绝与前驱节点的联系，方便被GC回收 p.next &#x3D; null; &#x2F;&#x2F; 成功获取资源后将失败标记为false failed &#x3D; false; &#x2F;&#x2F; 返回等待过程中是否被中断过 return interrupted; &#125; &#x2F;* * 先去检查自己是否真的可以被挂起了，如果不符合条件会进入下一次循环直到符合为止 * 调用park()方法将自己挂起，直到被唤醒 * 唤醒后会返回是否被中断标记，方便下次return出去 *&#x2F; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted &#x3D; true; &#125; &#125; finally &#123; &#x2F;&#x2F; 如果等待过程中没有成功获取资源(如timeout，或者可中断的情况下被中断了)，取消结点在队列中的等待。 if (failed) cancelAcquire(node); &#125;&#125; shouldParkAfterFailedAcquire方法，检查自己是否真的可以被挂起了: 123456789101112131415161718192021private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; &#x2F;&#x2F; 拿到前驱节点的状态 int ws &#x3D; pred.waitStatus; &#x2F;&#x2F; 如果前驱节点的状态是SIGNAL，那么前驱节点执行完会自动唤醒自己，放心的将自身挂起就好了 if (ws &#x3D;&#x3D; Node.SIGNAL) return true; &#x2F;&#x2F; 如果前驱节点执行过程中放弃了(超时或者其他的)，一直往前找，直到找到正常等待的状态节点 if (ws &gt; 0) &#123; do &#123; node.prev &#x3D; pred &#x3D; pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next &#x3D; node; &#125; else &#123; &#x2F;&#x2F; 如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; parkAndCheckInterrupt方法，就是挂起: 12345678private final boolean parkAndCheckInterrupt() &#123; &#x2F;&#x2F;调用park()使线程进入waiting状态 LockSupport.park(this); &#x2F;&#x2F;如果执行到这里，说明被唤醒，查看自己是不是被中断的。 return Thread.interrupted();&#125; 内部方法主要方法 acquire(int arg):独占式获取同步状态，如果当前线程获取成功则返回，否则加入等待队列 acquireInterruptibly(int arg):独占式获取同步状态(同上)，如果被打断直接抛异常 tryAcquire(int arg):独占式获取同步状态(供开发者重写) tryAcquireNanos(int arg，long nanosTimeout):独占式获取同步状态，增加超时限制 release(int arg):独占式释放同步状态，释放后将同步队列中第一个节点包含的线程唤醒 tryRelease(int arg):独占式释放同步状态(供开发者重写) acquireShared(int arg):共享式获取同步状态，如果当前线程获取成功则返回，否则加入等待队列 acquireSharedInterruptibly(int arg):共享式获取同步状态(同上)，如果被打断直接抛异常 tryAcquireShared(int arg):共享式获取同步状态(供开发者重写) tryAcquireSharedNanos(int arg，long nanosTimeout):共享式获取同步状态，增加超时限制 releaseShared(int arg):共享式释放同步状态，释放后将同步队列中第一个节点包含的线程唤醒 tryReleaseShared(int arg):共享式释放同步状态(供开发者重写) isHeldExclusively():当前同步器是否在独占式模式下被线程占用，一般该方法表示是否被当前线程所独占 方法虽然很多，不过很容易进行区分 首先争夺锁的方式有独占和共享 每种方式又包含加锁、释放锁方法 加锁的方法又分为直接加锁、超时加锁、中断加锁 直接加锁与中断加锁内部调用对应try开头的加锁方法处理 try开头的加锁方法采用模板模式，具体实现由开发者自己重写实现 最后一个是否独占并占用的查询 共享资源获取释放在需要开发者重写的获取资源方法中，独占式获取资源方法tryAcquire(int arg)返回值为boolean类型，仅仅需要告诉调用者获取成功还是失败即可。 而共享式获取资源方法acquireShared(int arg)返回int类型，大于等于零表示成功，小于零则表示失败，因为是共享所以允许多个线程访问获取，但有些时候我们需要限制访问数量。这就可以设置一个阈值，每次有线程进来时阈值-1消耗，当消耗为零的时候，后续线程就不允许访问了，直接进入等待队列。 同样的，共享式资源的释放相比较独占式逻辑也有不同，除了唤醒后继节点，还需要将阈值+1。 独占式源码解析acquire(获取锁) 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 先尝试用重写的tryAcquire(arg)方法，由于独占锁同一时刻只允许一个线程持有，这就需要开发者在重写方法时要利用好state属性，确保拿到锁的线程返回true，在没有释放前其他线程访问返回false。如果返回false就将线程封装成一个独占式锁加入队列中，紧接着尝试挂起线程。 release(释放锁) 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h &#x3D; head; if (h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0) unparkSuccessor(h); return true; &#125; return false;&#125; 先尝试调用重写的tryRelease(int arg)释放锁，如果成功后判断自身状态，如果节点状态不等于0(也就是还没退出等待队列)，调用unparkSuccessor方法释放锁。 12345678910111213141516171819202122232425262728private void unparkSuccessor(Node node) &#123; &#x2F;&#x2F; 获取当前节点的状态 int ws &#x3D; node.waitStatus; &#x2F;&#x2F; 如果小于0，使用CAS设置为0，0代表退出等待队列 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); &#x2F;&#x2F; 获取后继节点 Node s &#x3D; node.next; &#x2F;&#x2F; 如果没有后继节点，或者后继节点状态大于0，也就是说已经退出队列了 if (s &#x3D;&#x3D; null || s.waitStatus &gt; 0) &#123; &#x2F;&#x2F; 方便GC回收 s &#x3D; null; &#x2F;&#x2F; 不停的往后面找，直到找到状态正常的为止 for (Node t &#x3D; tail; t !&#x3D; null &amp;&amp; t !&#x3D; node; t &#x3D; t.prev) if (t.waitStatus &lt;&#x3D; 0) s &#x3D; t; &#125; &#x2F;&#x2F; 如果找到了就唤醒 if (s !&#x3D; null) LockSupport.unpark(s.thread); &#125; 这个方法的逻辑也很简单，使用CAS方式将自身节点状态设置为0，紧接着根据自身的waitStatus判断后继节点是否需要被唤醒，如果后继节点因为响应中断等情况放弃了，就继续往后找，直到找到可以背唤醒的节点线程。 acquireInterruptibly(获取锁并支持中断) 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; 先判断是否中断状态，如果是直接抛异常。如果不是中断状态，进入doAcquireInterruptibly(arg)方法。 123456789101112131415161718192021222324252627private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node &#x3D; addWaiter(Node.EXCLUSIVE); boolean failed &#x3D; true; try &#123; for (;;) &#123; final Node p &#x3D; node.predecessor(); if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next &#x3D; null; &#x2F;&#x2F; help GC failed &#x3D; false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; 代码逻辑与acquire几乎一致，AQS阻塞等待逻辑的老套路就是，如果等待线程的前驱节点不是head则使用park()挂起，在parkAndCheckInterrupt()中实现，紧接着下一行返回中断状态。处于挂起状态的线程如果被中断，会立刻结束挂起状态，因此在上面的代码中会满足第二个if判断，抛出中断异常。这里有个疑问，如果前驱节点是head，中断没做任何处理？ doAcquireNanos(获取锁并支持中断、超时)进入方法前获取当前时间戳，每次循环再次获取当前时间戳用差值判断是否超时，就算是被挂起的，也是调用park(this,nanosTimeout)进行挂起，到达超时时间直接跳出自旋。其他逻辑和doAcquireInterruptibly()一致。 共享式源码解析acquireShared(获取锁) 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125; 先尝试用重写的acquireShared(arg)方法，由于共享锁同一时刻时允许多个线程进行访问的，AQS将重写方法设计为支持同一时刻最大访问限制数，返回值的int类型，表示如果当前线程进入访问后还能剩余多少访问数，如果为负数证明已经没有访问名额了，只能阻塞等待。 releaseShared(释放锁) 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; 先尝试用重写的tryReleaseShared(arg)释放锁，加锁的时候是对state(访问限制数)-1，那么释放锁自然是加回来，这时有可能很多线程都在释放锁，因此在重写方法里加值要使用CAS方式。释放成功就代表有资源空闲出来，调用doReleaseShared方法唤醒后续节点。 123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h &#x3D; head; if (h !&#x3D; null &amp;&amp; h !&#x3D; tail) &#123; int ws &#x3D; h.waitStatus; if (ws &#x3D;&#x3D; Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; &#x2F;&#x2F; loop to recheck cases unparkSuccessor(h); &#125; else if (ws &#x3D;&#x3D; 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#x2F;&#x2F; loop on failed CAS &#125; if (h &#x3D;&#x3D; head) &#x2F;&#x2F; loop if head changed break; &#125;&#125; 在自旋的阶段，每一次循环的过程都是首先获得头结点，如果头结点不为空且不为尾结点(阻塞队列里面只有一个结点)，那么先获得该节点的状态，如果是SIGNAL的状态，则代表它需要有后继结点去唤醒，首先将其的状态变为0，因为是要释放资源了，它也不需要做什么了，所以转变为初始状态，然后去唤醒后继结点unparkSuccessor(h)，如果结点状态一开始就是0，那么就给他转换成PROPAGATE状态，保证在后续获取资源的时候，还能够向后面传播（这一块不明白）。 tryAcquireSharedNanos(获取锁并支持中断、超时)进入方法前获取当前时间戳，每次循环再次获取当前时间戳用差值判断是否超时，就算是被挂起的，也是调用park(this,nanosTimeout)进行挂起，到达超时时间直接跳出自旋。其他逻辑和tryAcquireShared()一致。 简单应用看懂AQS的原理机制后，我们可以尝试自己写一个不可重入锁，首先定义一下锁资源(AQS中的state)的含义，0表示未被加锁，1表示已经加锁。直接上代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class CustomLock &#123; private Sync sync; &#x2F;&#x2F; 自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; &#x2F;&#x2F; 判断是否锁定状态 @Override protected boolean isHeldExclusively() &#123; return getState() &#x3D;&#x3D; 1; &#125; &#x2F;&#x2F; 获取资源 @Override protected boolean tryAcquire(int arg) &#123; &#x2F;&#x2F; 使用CAS修改状态，如果成功设置当前资源为独占资源 if(compareAndSetState(0, 1))&#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; &#x2F;&#x2F; 释放资源 @Override protected boolean tryRelease(int arg) &#123; &#x2F;&#x2F;既然释放，肯定就是已占有状态了，为了代码健壮一点加层判断 if (getState() &#x3D;&#x3D; 0) throw new IllegalMonitorStateException(); &#x2F;&#x2F; 清空独占记录 setExclusiveOwnerThread(null); &#x2F;&#x2F; 释放共享资源，tryRelease还没执行完，线程仍然持有锁，因此不需要CAS修改 setState(0); return true; &#125; &#125; &#x2F;&#x2F; 在自定义加锁对象创建时，为其初始化一个同步器 public CustomLock()&#123; sync &#x3D; new Sync(); &#125; &#x2F;&#x2F; 加锁 public void lock() &#123; sync.acquire(1); &#125; &#x2F;&#x2F; 单次加锁尝试 public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; &#x2F;&#x2F; 释放锁 public void unlock()&#123; sync.release(1); &#125; &#x2F;&#x2F; 锁是否处于加锁状态 public boolean isLocked()&#123; return sync.isHeldExclusively(); &#125;&#125; 可重入锁在加锁、释放锁的时候需要对state进行加减操作，并且确保退出的时候state为零，再此期间其他线程访问时如果state大于等于零，则获取锁失败。由于这段代码设计的是不可重入锁，不需要记录次数，仅仅有加锁(1)和未加锁(0)俩中状态，因此lock()、tryLock()、unlock()方法传参随便写都可以，在内部类Sync重写AQS方法中已经写死。 利用AQS我们可以实现很多种同步机制，比如CountDownLatch、CyclicBarrier、Semaphore、Lock诸多实现类，都是利用AQS来实现。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(七) synchronized关键字","slug":"synchronized关键字","date":"2020-03-07T05:00:00.000Z","updated":"2020-10-19T07:47:11.609Z","comments":true,"path":"2020/03/07/synchronized关键字/","link":"","permalink":"http://yoursite.com/2020/03/07/synchronized%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"简介如果我们想要保证单个共享变量的原子操作，可以借助CAS来实现，当我们想要保证多个共享变量的原子操作时，那就要把对多个变量的操作代码整合在一起建立临界区，临界区同一时刻只能有一个线程访问。而synchronized关键字就是java老牌的互斥锁，保证操作的原子性、可见性、有序性，同时还保证锁的可重入性。 synchronized使用 修饰方法的时候，如果是普通方法，加锁目标是此实例对象(new出来的、存放在堆中的某个对象) 修饰方法的时候，如果是静态方法，加锁目标是当前类的class对象(存在方法区的类结构对象) 修饰代码块的时候，需要指定某个实例对象或class对象作为加锁目标 jvm对象头无论哪种方式实现线程同步，都必须指定一个对象并获得此对象的锁才有资格执行同步方法或代码块，synchronized的实现完全依赖于jvm，因此理解synchronized的底层实现，就必须理解对象在jvm是如何存储的，关于锁的那部分数据信息又是如何维护的。 在JVM虚拟机中，对象在内存中的存储布局，一般情况下分为三个区域： 对象头(包括标记字段、类型指针) 实例数据(存储对象自身定义的数据) 对齐填充(jvm要求对象的内存大小必须是8字节整倍数，对齐填充用于补全大小到整倍数) 如果对象是数组，还会有个区域记录数组的长度，用于判断数组对象的内存大小 有关对象锁的数据全部存储在对象头区域中，我们使用java提供的jol工具来看看对象的头部信息详细结构(测试为64位操作系统): 1.先添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jol-core&lt;&#x2F;artifactId&gt; &lt;version&gt;0.9&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 2.创建测试用对象 12345678910111213141516171819public class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name &#x3D; name; this.age &#x3D; age; &#125; public synchronized void doSomething()&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; ... &#125; &#125;&#125; 3.执行main方法 1234public static void main(String[] args) &#123; Person person &#x3D; new Person(&quot;李逍遥&quot;,18); System.out.println(ClassLayout.parseInstance(person).toPrintable());&#125; 4.打印结果 表头代表的含义： 列名 描述 OFFSET 偏移地址，单位字节 SIZE 占用的内存大小，单位字节 TYPE DESCRIPTION 类型描述，其中object header为对象头类型 VALUE 类型对应的值 颜色标记区域代表的含义： 区域 描述 红色 标记字段，内部结构比较复杂，而且会不断变化，下面单独讲 蓝色 类型指针，通常由64位组成，但是我们jvm会默认对其压缩到32位，因此占用4字节 绿色 实例数据，基本数据类型会直接打印值，引用数据类型显示(object) 黄色 对齐填充，图中对象占用总内存为20字节，因此对齐填充补了4字节确保是8字节倍数 与synchronized底层原理关联最为密切的就是红色区域了，这个区域也比其他区域更为复杂一点，标记字段拥有8字节的内存大小(也就是64位)，对象锁状态的不同，这64位存储的内容也不同： 标记字段中存储的信息： hash:存储对象哈希码，只有在调用hashCode()方法的时候才会生成，默认是没值的 age:jvm分代年龄，用于判断是否晋升老年代 biased_lock:偏向锁标识位 lock:锁状态标识位 JavaThread:保存持有偏向锁的线程ID epoch:保存偏向时间戳(并不是我们理解的long类型时间戳) Pointer to Lock Record:指向线程栈中锁记录的地址 Pointer to Monitor:指向jvm监控对象的地址 无锁状态所谓无锁状态，就是对象还没有被加过锁，也就是说内部的synchronized修饰的方法还没有任何线程调用过，上面打印的截图是没有调用hashCode()方法的，我们写个调用hashCode()方法的测试代码： 12345public static void main(String[] args)&#123; Object lockObject &#x3D; new Object(); System.out.println(&quot;哈希码 : &quot; + lockObject.hashCode()); System.out.print(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果： 我们把二进制数据拼接起来，拼接规则是从下至上、从右到左。 最终拼接结果为:00000000 00000000 00000000 01111011 00011101 01111111 11111111 00000001 取出哈希码:1111011 00011101 01111111 11111111 随便找个进制转换器就能算出来结果是:2065530879，与main方法打印的一致。 偏向锁偏向锁是jdk1.6引入的一项锁优化，意思是偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。 JVM启动时会进行一系列的复杂活动，比如装载配置，系统类初始化等等。在这个过程中会使用大量synchronized关键字对对象加锁，且这些锁大多数都不是偏向锁。为了减少初始化的时间，JVM默认采用延时加载偏向锁的机制(大概4秒左右)。在延迟时间内是没有偏向锁概念的，对象创建完毕后是无锁状态，即使需要进行锁升级也是直接升级到轻量级锁，当到达延迟时间之后创建出来的对象，锁状态都是偏向锁状态。 所以我们直接执行main方法是看不到偏向锁信息的，当然也可以在创建对象之前sleep五秒，不过这个方法太low逼了，JVM提供了取消偏向锁延迟加载命令:-XX:BiasedLockingStartupDelay=0 测试类走起: 1234public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); System.out.println(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果: 打印结果可以看出，对象还没有被作为加锁对象使用，偏向线程是空的。我们写个持有偏向线程的代码，并且手动调用一次gc看看age有没有增长: 1234567public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); System.gc(); synchronized (lockObject)&#123; System.out.print(ClassLayout.parseInstance(lockObject).toPrintable()); &#125;&#125; 打印结果: 打印结果中并不存在hashcode，这是因为在HotSpot虚拟机中，偏向锁与hashcode不可以并存(我估计是JavaThread占用的太多，没地方了…)，如果在无锁状态调用hashcode方法，直接升级到轻量级锁，如果是偏向锁状态下调用hashcode()，直接进入偏向锁撤销阶段。这种规则仅限于没有重写hashcode()方法的情况下。 偏向锁工作流程图: CAS获取偏向锁步骤整个流程图最大的疑问在于CAS获取偏向锁的这一步骤，如果线程A获取偏向锁并开始执行同步代码或方法块期间，线程B试图访问同步方法或代码块，按照我们的理解CAS成功是必然的，因为此刻线程A还在执行临界区代码，不会对标记字段进行修改干扰到线程B，这不就出现2个线程同时进入同步代码了吗？ 实时并非如此，无论是无锁状态(001)下的CAS，还是偏向锁状态下的CAS，期望值参数永远是null，也就意味着多个线程同时对无锁状态的同步代码争夺偏向锁，仅有一个线程会成功并成为偏向线程，之后任何线程在尝试CAS获取偏向锁永远是失败的(因为JavaThread已经非null)，直接进入偏向锁撤销阶段。 锁撤销偏向锁的撤销需要到达JVM的STW才会执行，这个时间点内所有字节码都不会执行，紧接着挂起偏向线程，根据isAlive()判断偏向线程状态再做后续处理: 如果处于未活动状态，说明偏向线程已经执行完毕并死亡，说明没有发生竞争，直接释放偏向锁。 如果处于活动状态并且已经退出同步代码块，说明没有发生竞争，释放偏向锁后需要唤醒线程继续执行。 如果处于活动状态并且未退出同步代码块，说明发生竞争,直接升级到轻量级锁。 锁重偏向通过对撤销步骤的了解不难发现，只有在到达安全点后，偏向线程已经死亡或者退出同步代码块，加锁对象的markword中JavaThread和epoch才会被清空，直到下一个线程获得偏向锁，加锁对象重新偏向另一个线程。 锁批量撤销JVM会以class为单位，为每个class分配一个偏向锁撤销计数器，每次class的实例被撤销偏向锁时计数器+1，当某个class的计数器达到阈值时(JVM参数控制)，JVM会将该class的所有实例批量撤销偏向锁，并且该class后续创建的所有实例都是不可偏向的(直接是轻量级锁)。 批量撤销阈值: -XX:BiasedLockingBulkRevokeThreshold = 40 锁批量重偏向重偏向操作需要等到安全点才可以触发，如果刚触发锁撤销操作的时候，偏向线程就执行完同步代码块，那么此时等待安全点是没有任何意义的，并且锁撤销也会占用一定的STW时间。由此可以看出频繁的锁撤销会对性能带来一定影响，为了解决这个问题，JVM引入了批量重偏向概念来减少锁撤销的频率。 与批量撤销的相似，批量重偏向也是在class的计数器达到一定阈值时触发，执行过程: 当到达安全点时发现偏向次数到达阈值触发批量重偏向，会对class中的epoch进行+1运算得出epoch_new jvm扫描所有该class的实例对象，并筛选出处于偏向锁状态的实例对象，把所有筛选对象的epoch改成epoch_new 退出安全点后，有线程需要尝试获取偏向锁，检查加锁对象的epoch与对应class的epoch是否一致 如果一致，根据JavaThread是否为自身ID决定撤销锁还是直接进入同步代码(还是原来的逻辑) 如果不一致说明偏向锁已经无效，不会因为加锁对象偏向其他线程而触发撤销操作，而是直接尝试CAS获取锁 注:我猜测此时期望值不在是null而是重新获取加锁对象的markword，获取到锁之后还会把class的epoch归零，因为epoch就2位不可能一直递增。 批量重偏向阈值: -XX:BiasedLockingBulkRebiasThreshold = 20 锁撤销计数器重置即使在竞争很少发生的应用中，随着时间的流逝，各class的锁撤销计数器总有到达阈值的时候。比如某个class的所有实例对象一小时才触发一次锁撤销，那么默认40小时后会触发批量锁撤销，后续所有对象的创建全都是轻量级锁。这种竞争程度简直毛毛雨，根本没必要使用轻量级锁增加无意义的性能消耗。对此JVM增加了两次批量锁撤销事件触发时差的阈值判断，如果距离上次批量撤销时差小于等于阈值时差就执行批量锁撤销，否则仅仅将锁撤销计数重置为零。 批量锁撤销时差阈值(毫秒): -XX:BiasedLockingBulkRebiasThreshold = 25000 启用禁用偏向锁撤销的作用很明显了，根据线程对此临界代码的访问是否发生竞争，来决定将锁恢复到无锁状态还是升级到轻量级。没有发生竞争的情况下，偏向锁的逻辑仍然能保证很好的性能，一旦发生竞争，就需要更高级的锁来最大化性能。偏向锁在竞争稍微激烈的情况下其实没什么卵用，如果你觉得你的应用对于大多数锁的竞争都是比较频繁的，偏向锁完全没有存在的必要，可以设置JVM启动参数来禁用偏向锁(默认延迟打开): 禁用偏向锁: -XX:-UseBiasedLocking 可重入性偏向锁是在没有发生竞争的情况下才存在，线程拿到偏向锁后成为偏向线程，在没有发生偏向锁撤销情况下，后续访问是没有资源消耗的，可以直接执行临界代码，这就代表偏向锁阶段完全支持可重入。 非公平性不存在竞争因此也不存在是否公平性可言。 轻量级锁轻量级锁也是jdk1.6引入的一项锁优化，是在锁发生竞争但竞争不是特别激烈情况下的折中解决方案，降低重量级锁使用过程中的性能消耗。 我们写个测试类(使用 -XX:-UseBiasedLocking命令，禁用偏向锁): 123456public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); synchronized (lockObject)&#123; System.out.println(ClassLayout.parseInstance(lockObject).toPrintable()); &#125;&#125; 打印结果: 轻量级锁的标记字段结构很简单，只存储锁标志、锁记录俩个信息，hashcode和age转移到Lock Record中进行存储。 轻量级锁工作流程图: 自旋次数在自旋竞争锁过程中，如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。这个自旋次数在jdk1.5是写死的参数无法更改，到了jdk1.6版本可以通过jvm参数控制自旋次数(默认10)，jdk1.7版本后又去掉了此参数，因为这个时候的jvm已经相当成熟，会根据内部收集的性能日志自己判定自旋次数。 轻量级锁自旋次数: -XX:PreBlockSpin=10 锁释放持锁线程执行完释放锁后，将拷贝的markword作为期望值，使用CAS修改加锁对象的markword，可以理解为将hashcode、age等信息还回去。有可能此时已经膨胀到重量级锁，加锁对象的markword已经变更，这种情况下CAS必然失败，这时候直接执行重量级锁的唤醒逻辑。 解锁操作为什么要用CAS来操作呢? 这是为了防止在解锁的时候，锁由于竞争的激烈程度再次提高，已经升级到重量级锁并且把其他线程阻塞，这种情况下如果不唤醒阻塞的线程，这些线程将永远阻塞在这里。 可重入性偏向线程执行过程中遇到锁升级信号(已经发出偏向锁撤销请求)，JVM会在该线程栈中分配一个Lock Record，并把加锁对象的markword拷贝进来，如果已经是轻量级锁情况下，线程访问临界代码前也会执行同样操作。这也就意味着持有轻量级锁过程中，加锁对象的hashcode、age等信息转移到了持锁线程的Lock Record中，持锁线程的Lock Record同样也会保存加锁对象markword的地址，两者是互相引用的关系，这样既能保证加锁对象的hashcode、GC年龄随时可以访问，也可以解决可重入的问题。 非公平性顶多俩线程在竞争，一个在执行，一个在自旋等待，因此也没有是否公平性可言。 重量级锁轻量级锁膨胀之后，就升级为重量级锁了。重量级锁是依赖对象关联的monitor锁来实现的，每个java对象都有一个与之对应的monitor对象，随着java对象一起创建一起销毁。而monitor又依赖操作系统的MutexLock(互斥锁)来实现的，所以重量级锁也被成为互斥锁。 在HotSpot虚拟机中，Monitor是基于C++实现的，封装成ObjectMonitor对象，具体成员变量: 属性名 默认值 属性描述 _header NULL 锁对象的原始对象头 _count 0 用来记录该线程获取锁的次数 _waiters 0 进入wait状态的线程数 _recursions 0 锁的重入次数 _object NULL 关联的锁对象 _owner NULL 指向持有ObjectMonitor对象的线程，锁释放后设置为null _WaitSet NULL 调用wait()方法后进入的wait集合 _WaitSetLock 0 操作WaitSet链表的锁 _Responsible NULL 防止搁浅情况 _succ NULL 假定继承线程 _cxq NULL 被挂起线程等待重新竞争锁的单向链表，为了避免插入和取出元素的竞争，所以Owner会从列表尾部取元素 FreeNext NULL Free list linkage _EntryList NULL 处于block状态的线程集合，被notify唤醒后重新加入竞争也是进入此队列 _SpinFreq NULL 自旋成功率 _SpinClock 0 自旋时钟 OwnerlsThread 0 表明当前owner原来持有轻量级锁 _previous_owner_tid 0 上一个获取锁的线程id 写个重量级锁mode: 1234567891011121314151617181920212223242526272829public static void main(String[] args)&#123; Object lockObject &#x3D; new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lockObject) &#123; while (true) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lockObject) &#123; while (true) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#125;).start(); System.out.println(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果: 阻塞过程monitor对象在轻量级锁膨胀后初始化，并且将状态设置为膨胀中(INFLATING)，在膨胀期间有线程访问直接进入忙等状态。当一个线程尝试获取锁并且获取失败，则将线程封装为ObjectWaiter插入到cxq的队列的队首，进入cxq队列的线程还会再次尝试自旋获取锁，如果还是失败则调用park函数挂起线程。park函数涉及到内核态的切换，因此比较耗时，也是被称为'重'锁的原因。 自旋目的争夺锁失败插入cxq队列后仍然会进行自旋的目的在于，防止同步块中代代码较少、执行比较快的情况下，频繁的park函数调用导致频繁的内核态的切换影响性能。关于自旋次数在JDK1.6之前默认10次，之后版本改成了适应性自旋由JVM自己控制。 防止搁浅当线程获得锁后，会去查询当前是否还有其他线程等待获取锁，如果没有则将_Responsible设置为自身，在进入cxq后自旋仍然没获取锁会再次判断_Responsible是否为自身，如果是则调用有时间限制的park方法，估计是考虑到特殊场景下所有线程都处于阻塞导致没有线程进行释放锁操作，出现搁浅情况。 线程释放当锁被释放后，会从_cxq或_EntryList中挑选一个线程唤醒，被选中的线程为假定继承人赋值给_succ，即使_succ重新加入竞争也不能保证会获取到锁，所以_succ也只能称为假定继承人。 重量级锁工作流程图: 可重入性monitor通过_owner属性判断线程有无权限进入同步代码块，再根据_recursions属性用来记录重入次数，进入临界代码时+1、退出时-1，由此可以保证重入性。 非公平性jvm在唤醒线程时会根据内部参数QMode的值决定使用哪种唤醒策略，可能从_cxq中选取一个，也可能从_EntryList中选取一个，_cxq队列的线程也会因为策略被转移到_EntryList队列的首部或尾部。被选中的线程也不保证能拿到锁，因此synchronized是非公平的。 GC标记如果设置finalize()或许还有一线生机，没设置就等死吧…. 锁降级synchronized是由JVM来实现的，因此锁是否支持降级完全取决于JVM设计者，本文所有技术点均来自HotSpot虚拟机。HotSpot虚拟机在进入安全点的时候，会去检查是否有空闲的monitor，如果有就试图进行降级。在轻量级锁释放锁的时候会将拷贝的markwordCAS修改回去，如果成功，是不是也代表降级为偏向锁了呢？这个问题没有找到答案，以后搞懂了再改。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"多线程(六) 锁分类","slug":"锁分类","date":"2020-03-06T05:00:00.000Z","updated":"2020-10-19T08:17:40.042Z","comments":true,"path":"2020/03/06/锁分类/","link":"","permalink":"http://yoursite.com/2020/03/06/%E9%94%81%E5%88%86%E7%B1%BB/","excerpt":"","text":"前言java中的锁可谓是五花八门，各种锁功能相似又不同，有的是概念、有的是java接口、有的是实现类，让你很难找到明显的分界线去区分并记住他们。所以学习锁首先要打消一种想法，就是一个锁只属于一个分类，比如一个锁可以同时是乐观锁、可重入锁，公平锁，就像一个人可以是男人、程序员、健身爱好者。 synchronized与Lockjava代码中两种加锁方式 一种是用synchronized关键字，另一种是用Lock接口的实现类。形象地说，synchronized关键字是自动档，可以满足一切日常驾驶需求。但是如果你想要玩漂移或者各种骚操作，就需要手动档了——各种Lock的实现类，因为Lock的实现类可以通过设置不同的参数改变锁的作用达到灵活适应场景的作用，而synchronized是关键字，底层有jvm实现，很多参数都是写死的。 悲观锁与乐观锁锁的一种宏观分类方式是悲观锁和乐观锁。悲观锁与乐观锁并不是特指某个锁(Java中没有哪个Lock实现类就叫PessimisticLock或OptimisticLock)，而是在并发情况下的两种不同策略。 悲观锁(Pessimistic Lock)，就是很悲观，每次去拿数据的时候都认为别人会修改。所以每次在拿数据的时候都会上锁，这样别人想拿数据就被挡住，直到悲观锁被释放。比如上面说的synchronized与Lock。 乐观锁(Optimistic Lock), 就是很乐观，每次去拿数据的时候都认为别人不会修改。所以不会上锁，这里的上锁是指互斥性质的上锁，在说明白点就是我加锁了谁也别想碰，除非我释放锁，乐观锁采用的是类似CAS的方式，保证操作数据不会干扰到其他线程。 悲观锁阻塞事务，乐观锁回滚重试，它们各有优缺点，不要认为一种一定好于另一种。像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行重试，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 自旋锁有一种锁叫自旋锁。所谓自旋，说白了就是一个** while(true) ** 无限循环。这个自旋锁与Atomic类的while实现的自旋代码不是一回事，下一章AQS会详细讲 synchronized锁升级前面提到synchronized关键字就像是汽车的自动档。一脚油门踩下去，synchronized会从无锁升级为偏向锁，再升级为轻量级锁，最后升级为重量级锁，就像自动换挡一样。那么自旋锁在哪里呢？这里的轻量级锁就是一种自旋锁。 初次执行到synchronized代码块的时候，锁对象变成偏向锁(通过CAS修改对象头里的锁标志位，说明白点就是锁记住了第一次和他发生关系的线程)，字面意思是“偏向于第一个获得它的线程”的锁，执行完同步代码块后，线程并不会主动释放偏向锁。第二次访问如果还是此线程，那么就没有加锁释放锁这一说，正常执行。 一旦有第二个线程加入锁竞争并发现锁是偏向锁，会去断线程A是否仍然存活。如果线程A仍然存活，将线程A暂停，此时偏向锁升级为轻量级锁，之后线程A继续执行，线程B自旋。但是如果判断结果是线程A不存在了，则线程B持有此偏向锁，锁不升级。 在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。 自旋锁避免不了的问题就是竞争特别激烈的情况下，其他线程只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做**忙等(busy-waiting)**。显然，此忙等是有限度的(有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改)。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁(依然是CAS修改锁标志位，但不修改持有锁的线程ID)。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起(而不是忙等)，等待将来被唤醒。在JDK1.6之前，synchronized直接加重量级锁，很明显现在得到了很好的优化。 可重入锁(递归锁)可重入锁的字面意思是“可以重新进入的锁”，即允许同一个线程多次获取同一把锁。比如一个递归函数里有加锁操作，递归过程中这个锁会阻塞自己吗？如果不会，那么这个锁就是可重入锁(因为这个原因可重入锁也叫做递归锁)。 公平锁、非公平锁如果多个线程申请一把公平锁，那么当锁释放的时候，先申请的先得到，非常公平。显然如果是非公平锁，后申请的线程可能先获取到锁，是随机或者按照其他优先级排序的。 对ReentrantLock类而言，通过构造函数传参可以指定该锁是否是公平锁，默认是非公平锁。一般情况下，非公平锁的吞吐量比公平锁大，如果没有特殊要求，优先使用非公平锁。对于synchronized而言，它也是一种非公平锁，但是并没有任何办法使其变成公平锁。 可中断锁这里的关键是理解什么是中断。Java并没有提供任何直接中断某线程的方法，只提供了中断机制。何谓“中断机制”？线程A向线程B发出“请你停止运行”的请求(线程B也可以自己给自己发送此请求)，但线程B并不会立刻停止运行，而是自行选择合适的时机以自己的方式响应中断，也可以直接忽略此中断。也就是说，Java的中断不能直接终止线程，而是需要被中断的线程自己决定怎么处理。这好比是父母叮嘱在外的子女要注意身体，但子女是否注意身体，怎么注意身体则完全取决于自己。 读写锁、共享锁、互斥锁读写锁其实是一对锁，一个读锁(共享锁)和一个写锁(互斥锁、排他锁)，Java提供了ReadWriteLock接口和实现类ReentrantReadWriteLock来实现读写锁。 读锁：防止读的时候其他线程写，允许读的时候其他线程读 写锁：防止写的时候其他线程读或写 使用锁带来的问题死锁、活锁、饥饿","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(五) CAS","slug":"CAS","date":"2020-03-05T05:00:00.000Z","updated":"2021-02-06T07:54:32.077Z","comments":true,"path":"2020/03/05/CAS/","link":"","permalink":"http://yoursite.com/2020/03/05/CAS/","excerpt":"","text":"什么是CASCAS的全称是Compare and Swap(比较和交换)，是一种特殊的修改数据的方式，线程通过CAS修改数据时整个过程涉及到三个数据：要修改的内存数据V、执行CAS操作前读取V并将V的值复制到工作空间计作A(预期值)、修改后的数据B，执行CAS操作中当且仅当预期值A和内存值V相同时，将内存值V修改为B并返回true，否则视为修改失败返回false。 Atomic对CAS的应用Atomic包是Java.util.concurrent下的另一个专门为线程安全设计的Java包，包含多个原子操作类，我们以AtomicInteger为例看看java如何通过CAS实现原子性。 incrementAndGet方法，以原子方式将当前值增加1并返回增加后的值： 1234public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 我们发现incrementAndGet方法把这个操作委托给unsafe类的getAndAddInt方法处理，我们继续看getAndAddInt方法源码： 123456789101112public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; &#x2F;&#x2F; 读取AtomicInteger在内存中对应的值，并复制一份赋值给var5，作为期望值 var5 &#x3D; this.getIntVolatile(var1, var2); &#x2F;&#x2F; 将AtomicInteger对象引用、偏移量、预期值、修改后的值交给compareAndSwapInt也就是CAS方法循环执行，直到true &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 代码中我们可以看到，真正的CAS修改操作是compareAndSwapInt方法，我们继续往下看： 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 到这里的时候我们发现compareAndSwapInt方法是被native修饰的，说明接下来的代码是使用C++实现的了。源码就不贴了，这个方法实际上是利用处理器提供的汇编指令CMPXCHG。当CPU执行此修改指令时发现带有CMPXCHG前缀，那么会采用CAS方式(比较并交换操作数)修改数据，并且保证比较、交换俩个步骤不会被上下文切换打断。当且仅当预期值var4与要修改的内存值相等时，将内存值修改为var5。 如果你细心的话会发现，在多核CPU的操作系统中仅仅保证CAS的俩个步骤不被上下文切换打断没什么卵用，如果俩个线程并行同时对某个AtomicInteger(0)执行incrementAndGet方法，怎么保证高速缓存中取出的期望值不是脏数据？怎么保证多个处理器不会同时执行到CAS的比较操作并且都返回true，继而同时修改内存值为1，最终导致结果应该是2却因为线程安全问题变为1？ 我们回头看看AtomicInteger的其他源码： 12345678910111213141516... private volatile int value; public AtomicInteger(int initialValue) &#123; value &#x3D; initialValue; &#125; public AtomicInteger() &#123; &#125; public final int get() &#123; return value; &#125; ... AtomicInteger内部有个int类型的value属性，代表着自身的值，并且AtomicInteger读写操作都是围绕这个值进行的，并且这个类被volatile修饰的。到这里思路就清晰了，volatile修饰符保证了value值的可见性，线程不会出现读到脏数据的情况。 对于第二种情况百度的资料很少提及，所以也无法确定CPU到底如何解决这个问题。但是我在知乎上看到了俩个感觉还算靠谱的答案。首先被volatile修饰的变量会使用MESI协议确保同一时刻只有一个处理器修改值，并且把其他处理器此值的缓存设为无效，当第二个处理器想要修改值时发现无效，CAS操作失败，返回false，另一个答案则表示当多个处理器同时使用cmpxchg指令(也就是CAS)操作同一个数据时，总线会进行仲裁只有一个处理器执行CAS，其他处理器连比较操作都不会执行，直到上一个处理器执行完毕后总线再次仲裁并选中自己。 第一种答案强调使用MESI的失效机制解决问题，第二种答案则强调将CAS视为一个整体，在执行比较操作的时候就会利用MESI协议将数据修改为M状态。不同的CPU架构可能解决问题的方式也不同，总之CPU保证多处理器并行执行CAS不会出错，Java保证volatile+自旋CAS修改数据的原子性，以后搞懂了再更新。 ABA问题Java在1.5版本引进了AtomicStampedReference类，采用版本号的机制解决这个操蛋的问题。 总结 CAS是典型的乐观派操作，每次都迷之自信认为操作一定成功，但是在高并发比较严重的情况下会导致大量线程不断的循环，增大CPU的消耗。 CAS只能保证单个共享变量的原子操作，如果操作涉及多个共享变量，必须要排他锁解决 仅仅依靠CAS无法保证原子性，必须配合CPU缓存锁一起保证。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(四) volatile关键字","slug":"volatile关键字","date":"2020-03-04T05:00:00.000Z","updated":"2021-03-15T15:33:13.654Z","comments":true,"path":"2020/03/04/volatile关键字/","link":"","permalink":"http://yoursite.com/2020/03/04/volatile%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"概述volatile是Java的一个修饰符，它在多线程编程开发中保证了共享变量的可见性和有序性。相对于各种排他锁，volatile在使用和执行成本上占用资源较少。 实现原理那么volatile如何保证可见性和有序性呢？我们写一段单例模式的java代码： 123456789101112131415161718192021package com.test;public class SingletonObject &#123; &#x2F;&#x2F; 单例对象 private static volatile SingletonObject instance; &#x2F;&#x2F; 获取单例对象方法 public static SingletonObject get()&#123; if(instance &#x3D;&#x3D; null)&#123; instance &#x3D; new SingletonObject(); &#125; return instance; &#125; public static void main(String[] args) &#123; SingletonObject.get(); &#125;&#125; 然后用idea运行main方法并打印汇编代码，jvm参数：-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly-XX:CompileCommand=compileonly,*SingletonObject.get (只打印SingletonObject的get方法) 运行打印结果： 1234567891011121314# &#123;method&#125; &#123;0x0000000128e022b0&#125; &#39;get&#39; &#39;()Lcom&#x2F;test&#x2F;SingletonObject;&#39; in &#39;com&#x2F;test&#x2F;SingletonObject&#39;# [sp+0x40] (sp of caller) 省略代码..... 0x000000010af1fb54: movb $0x0,(%rax,%rsi,1) 0x000000011b6f4e58: lock addl $0x0,(%rsp) ;*putstatic instance ; - com.test.SingletonObject::get@13 (line 12) 省略代码..... 0x000000010af1f701: mov %r12b,(%r11,%r10,1) 0x000000011b6f4a05: lock addl $0x0,(%rsp) ;*putstatic instance ; - com.test.SingletonObject::get@13 (line 12) 省略代码..... 我们可以看到被volatile修饰的共享变量进行写操作的时候，会比普通公共变量的读写操作多一行lock addl $0x0,(%rsp)前缀的代码，lock前缀指令有俩个作用： 使用总线锁或缓存一致性协议来保证数据的可见性。 不是内存屏障却能完成类似内存屏障的功能，阻止屏障两遍的指令重排序保证有序性。 总结volatile的使用场景不是很多，常用在多线程下的状态标记量和双重检查等，也有很多地方配合CAS来实现无锁编程。因为volatile只能保证线程每次拿到的数据是最新的，对于数据的单纯查询没有任何问题(jvm自动保证基本数据类型和引用的取值赋值为原子操作，lock指令保证有序性和可见性)，但是对于i++、懒汉式单例模式等对变量操作依赖当前值的情况，就显得无能为力。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(三) 生命周期和常用方法","slug":"多线程生命周期和常用方法","date":"2020-03-03T05:00:00.000Z","updated":"2020-11-03T01:42:03.748Z","comments":true,"path":"2020/03/03/多线程生命周期和常用方法/","link":"","permalink":"http://yoursite.com/2020/03/03/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%92%8C%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"线程状态以及转化NEW(新建) 使用new创建出线程后，进入新建状态 此时jvm为其分配内存以及其成员变量 除此之外没有任何特征，方法也不会被执行 RUNNABLE(就绪) 调用对象的start()方法，进入就绪状态 此时jvm会为其创建方法调用栈和程序计数器 线程拥有被CPU调度资格，开始疯狂争夺使用权 RUNNING(运行) 抢到CPU使用权时，开始执行run()方法，进入运行状态 线程只有通过start()后争夺到CPU时间片的方式运行run()方法，才可以实现异步执行 如果直接调用run()方法运行，系统会当作普通方法，不会异步执行 BLOCKED(阻塞) 处于运行状态的线程在进入synchronized关键字修饰的方法或代码块时，进入阻塞状态 阻塞的过程就是线程在抢夺锁的过程，因此阻塞是被动的 阻塞在某个锁上的线程，在锁被释放后会主动去争取，争取到锁后回到运行状态，因此脱离阻塞状态是主动的 WAITING(等待) 调用wait()、join()方法时，进入等待状态 因此进入等待状态是主动的，需要有事件主动唤醒 TIMED_WAITING(等待) 调用sleep(long)、wait(long)、join(long)方法时，进入超时等待状态 同等待状态，到达参数指定时间自动唤醒 TERMINATED(终止) run()方法或call()方法运行完毕，线程正常结束 线程执行代码过程中抛出未捕获异常或直接ERROR 调用stop()方法，也是个奇葩的方法，不推荐使用 附加状态转化图： 类型转化。 isAlive()1public final native boolean isAlive(); 判断当前线程是否活着，只有当线程进入RUNNABLE(就绪)或RUNNING(运行)状态才返回true。 sleep(long millis)1public static native void sleep(long millis) throws InterruptedException; Thread的静态方法，使当前线程放弃CPU时间片，在指定时间内不参与CPU竞争，在到达指定时间后变为runnable状态并重新加入CPU竞争。如果当前线程持有锁，在睡眠过程中不会放弃锁的占有权 join(long millis)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#x2F;&#x2F; 无参方法，调用重载方法传入固定参数0public final void join() throws InterruptedException &#123; join(0);&#125;&#x2F;&#x2F; 支持超时的join方法public final synchronized void join(long millis) throws InterruptedException &#123; &#x2F;&#x2F; 获取当前时间戳 long base &#x3D; System.currentTimeMillis(); &#x2F;&#x2F; 记录已经延迟多久 long now &#x3D; 0; &#x2F;&#x2F; 参数校验，不能小于0 if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; &#x2F;&#x2F; 没有超时限制情况下 if (millis &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 线程只有处于活着状态才进行处理 while (isAlive()) &#123; &#x2F;&#x2F; 这里意味着调用此方法的线程直接被wait方法挂起，没有提供任何notify方法唤醒，只能被动的等待线程运行完毕后死亡 wait(0); &#125; &#125; else &#123; &#x2F;&#x2F; 线程只有处于活着状态才进行处理 while (isAlive()) &#123; &#x2F;&#x2F; 还需要延迟多久 long delay &#x3D; millis - now; &#x2F;&#x2F; 如果已达到延迟时间限制，跳出循环 if (delay &lt;&#x3D; 0) &#123; break; &#125; &#x2F;&#x2F; 挂起进入等待状态 wait(delay); &#x2F;&#x2F; 执行到这里说明等待时间已到，重新计算已经延迟多久了，等待下一次进入while循环调用break now &#x3D; System.currentTimeMillis() - base; &#125; &#125;&#125; 源码可以看出来join是用的wait()实现的，wait方法是object的方法，作用是让调用这个Object.wait()的线程处于等待状态，除非其他线程调用这个Object.notify()唤醒，或者这个Object死亡阻塞状态才会变成可运行状态，如果join方法带参数，那就等到参数时间结束自动唤醒自己。 如果在一个线程执行中创建另外一个线程并使用join()，那么主线程会被挂起，等待子线程执行完在继续往下执行。说白了和执行过程中调用另一个方法没什么区别，无非就是有个超时时间限制，超过时间限制主线程就取消等待继续执行。使用isAlive()进行判断，也就意味着线程如果没有进入RUNNABLE(就绪)或RUNNING(运行)状态，join方法不会起任何作用。 join其实合理理解成是线程合并，当在一个线程调用另一个线程的join方法时，当前线程阻塞等待被调用join方法的线程执行完毕才能继续执行，所以join的好处能够保证线程的执行顺序，但是如果调用线程的join方法其实已经失去了并行的意义，虽然存在多个线程，但是本质上还是串行的，最后join的实现其实是基于等待通知机制(wait+notify)的。 yield()1public static native void yield(); Thread的静态方法，暂停当前正在执行的线程对象，并执行其他线程。被暂停的线程会让出CPU的使用权给其他线程获得运行机会，自身转化为RUNNABLE(就绪)状态，但是这么做并不一定能达到让出CPU资源的目的，因为让出CPU使用权的时候，自身回到可运行状态与其他同优先级线程一起再去竞争CPU时间片，如果这个线程是个欧皇还会被再次选中，出现这种情况也就意味着此次yield()方法并没有任何效果。 目前想不到什么应用场景，如果一个线程的优先级特别低，执行内容也不是很重要，又怕他被CPU调度的次数多，可以适当的调用此方法减少执行的次数，把CPU资源给其他重要的线程工作。 interrupt()1234567891011121314151617public void interrupt() &#123; &#x2F;&#x2F;如果调用中断的是线程自身，则不需要进行安全性判断 if (this !&#x3D; Thread.currentThread()) checkAccess(); &#x2F;&#x2F; synchronized (blockerLock) &#123; Interruptible b &#x3D; blocker; if (b !&#x3D; null) &#123; interrupt0(); &#x2F;&#x2F; 只是设置中断标志 b.interrupt(this); return; &#125; &#125; interrupt0();&#125; 每个线程内部都维护了一个中断标志(默认false)，调用线程的interrupt()方法时会根据当前线程的中断标志和阻塞情况，判断是否需要抛出异常： 如果中断标志为false，且没有被阻塞，修改中断标志为true。 如果中断标志为true，此时调用wait、sleep、join方法时会抛出InterruptedException异常，恢复中断标志为false。 如果已经被wait、sleep、join方法阻塞，调用interrupt()会抛出InterruptedException异常，恢复中断标志为false。 这里提到的阻塞，只是因为wait、sleep、join方法导致线程被堵住无法继续执行，并不是线程七大状态的BLOCKED(阻塞)状态。BLOCKED(阻塞)状态只由synchronized导致，而且不能被打断，相同的，IO阻塞也不能被打断。 由此可以看出来interrupt()方法中断的不是线程的运行，而是中断线程的阻塞状态，并且采用抛异常的方式引起线程的注意，被中断线程可以通过try catch方式自己决定如何应对中断信号。 比如使用kafka采用while(true)的方式消费数据时，又希望在某个时刻终止这个线程，并且终止过程中要保证此刻正在处理的那条消息处理完毕后才能终止，可以采用interrupt()方法+wait、sleep、join的一种来实现： 1234567891011121314151617181920212223242526272829303132public void run()&#123; &#x2F;&#x2F; 创建消费者 Properties props &#x3D; createProperties(&quot;localhost:9092&quot;, &quot;groups&quot;); props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;); KafkaConsumer&lt;String, String&gt; consumer &#x3D; new KafkaConsumer&lt;&gt;(props); &#x2F;&#x2F; 设置消费topic consumer.subscribe(Arrays.asList(&quot;topic-name&quot;)); while (true) &#123; &#x2F;&#x2F; 每次拉取消息 ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(100); &#x2F;&#x2F; 循环处理 for (ConsumerRecord&lt;String, String&gt; record : records) &#123; &#x2F;&#x2F; 消费逻辑.. &#x2F;&#x2F; wait或sleep或join阻塞1毫秒，试探线程有没有被中断 try &#123; Thread.wait(1); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; 关闭消费者对象 consumer.close(); return; &#125; &#125; &#125;&#125; stop()强制终止线程的运行，并立即释放掉此线程持有的锁，这些锁可能用来维护数据一致性的，所以此方法被废弃。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(二) 并发编程三大特性","slug":"并发编程三大特性","date":"2020-03-02T05:00:00.000Z","updated":"2021-03-15T15:30:39.325Z","comments":true,"path":"2020/03/02/并发编程三大特性/","link":"","permalink":"http://yoursite.com/2020/03/02/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7/","excerpt":"","text":"可见性可见性是指一个线程对共享变量的修改，其他线程可以立即感知到这个变化 计算机中程序的执行，本质上是线程指令在CPU处理器上的执行，并且在执行必然牵涉到数据的读和写，程序运行过程的临时数据都是存放在主内存(RAM)中，因此CPU在处理数据的时候也必然牵涉到和主内存的交互。处理器访问内存时，需要先获取内存总线的控制权，任何时刻只能有一个处理器获得内存总线的控制权，可以理解为同一时刻某个内存地址只可能被一个处理器访问。 随着硬件技术的不断发展，现在的CPU处理速度已经远远超过主内存的访问速度，如果任何时候对数据的操作都要和内存进行交互，会大大降低指令的执行速度，因此就有了CPU高速缓存： 高速缓存的产生大大减少了CPU直接访问主内存的频率，也减少了内存访问速度对CPU的拖累，提高了CPU的执行效率。如果是单核CPU的操作系统中，只有一个高速缓存，没有任何问题。但是多核CPU的诞生打破了这个规则，处理器对数据的修改在没有做任何措施的情况下，不会及时通知到其他处理器的缓存，这就导致其他处理器的数据是脏数据。 比如i++操作，编译成指令后大概有三步骤： 将i=0从主内存复制到 对i进行加1运算 将运算后的值刷回主内存 假设俩个线程对公共变量i=0执行i++操作，我们期望俩个线程都执行完毕后i的值变为2，由于操作系统配置是多核CPU，俩个线程分别在不同的CPU上并行执行，用时间线流程图模拟执行效果: 图中可以看出CPU-1计算完毕后还没来得及将数据i刷回主内存，另一个CPU就去主内存获取i值并且到的是脏数据，这导致i最终值并不是我们期望的结果。对此问题，早期的解决方案是总线加锁，一个处理器在总线上输出LOCK#信号，使得其他处理器对内存的操作请求都会被阻塞，该处理器独占共享内存。方法简单粗暴，就是锁定范围太大(整个共享内存)，导致CPU利用率急剧下降。 CPU如何保证可见性？为了解决总线锁开销过大问题，CPU提出了缓存一致性解决方案，主要有Directory协议、Snoopy协议、MESI协议。这个说下MESI协议，这个协议只会对高速缓存中的某个数据加锁(如果数据不在缓存中，还是会总线加锁)，不会影响到内存中其他数据的读写。MESI协议将数据划分为四种状态，通过总线嗅探机制让所有处理器监听数据状态的变化，达到缓存一致的目的: 我们重点关注一下修改缓存数据的情况，对于E状态的数据，只有自己在读，可以直接把数据设置为M状态，对于S状态的数据，说明有多个处理器在读，必须将其他处理器对此数据的缓存作废，然后才能把数据的状态设置为M。当其他处理器发现自己的缓存是I状态时，就去主内存再次读取，而MESI协议保证其他处理器去主内存读取此数据前，将修改后的数据从高速缓存刷回主内存，并把数据状态改为E。 高并发情况下可能出现俩个处理器同时修改变量，并同时向总线发出将各自的缓存行更改为M状态的情况，此时总线会采取裁决机制进行裁决，将其中一个置为M状态，另一个置为I状态，且I状态的缓存行修改无效。 Java自带的可见性操作： volatile关键字(采用MESI协议保证，如果数据不在缓存中就用总线锁) synchronized关键字(同一时刻就一个线程操作，还有啥不可见的) Lock相关类(跟synchronized一个套路) 原子性原子性操作是指一个或多个操作，要么全部执行且在执行过程中不被任何因素打断，要么全部不执行。并且针对某个值的原子操作在被执行的过程中，CPU绝不会再去进行其他的针对该值的操作 java作为一门高级语言，一个可执行线程会被编译成多条指令序列交由CPU执行，既然是多条指令，在执行过程中就存在被上下文切换打断的可能。在多线程编程中如果有的操作不具有原子性，同样会导致运行结果与预期的不一致，比如i++操作： 同样的i++操作，可见性与原子性对线程安全强调的角度却不一样，可见性强调线程在修改完数据后未及时从缓存刷新到主内存，导致另一个线程获取脏数据，继而影响到最终计算结果，而原子性强调非原子操作在执行过程中被上下文打断，在未切回期间另一个线程对数据i进行了递增操作，导致数据最终出现错误。 CPU如何保证原子性？首先，处理器自动保证单条指令、基本内存操作的原子性，因此中断只会发生在指令之间。在单核CPU中保证操作原子性非常简单，只要禁止CPU在原子操作过程中发生上下文切换，那么就可以保证多线程对某个公共变量的多步骤操作都是串行的。嗯，有点线程安全的味道了。到了多核CPU时代，仅仅保证原子操作的执行不被CPU打断已经没什么卵用了，因为多个线程可以并行执行修改一个公共变量，线程之间又出现了干扰。对此，CPU又提出了CAS来解决这个问题(CAS下一章会讲)。 Java自带的原子性操作： 基本数据类型的赋值(long、double无法保证) 所有引用类型的赋值 synchronized关键字(采用jvm的monitor，monitor底层采用CPU的CAS) Lock相关类(采用aqs，aqs底层采用CPU的CAS) java.concurrent.Atomic包下所有类(采用CPU的CAS) 注:CPU和Java(内存读写)的原子性与数据库的原子性还是有区别的，CPU和Java(内存读写)执行原子操作过程中发生中断的唯一可能就是断电，这时候所有内存数据全部消失，也就没讨论的意义了。而数据库的增删改操作涉及的都是持久化的磁盘数据，就算执行过程发生断电，持久化的数据仍然存在，因此数据库的原子操作增加了事务回滚概念，只要事务没提交，就相当于没执行。无论CPU还是Java还是数据库，都是强调整体的成败，不允许仅执行部分操作的存在。 有序性有序性是指程序按照写代码的顺序执行 处理器和编译器为了提高程序运行效率，可能会对输入代码进行优化，并且不保证程序中各个语句的执行先后顺序同代码中的顺序一致。当然，CPU和编译器是在遵循as-if-serial语意的前提下对指令重排，而不是随意重排。首先CPU保证调度线程过程中，单线程的执行结果不会受指令重排影响导致结果不一致，编译器保证编译过程中不会对有依赖关系的数据进行指令重排。由此看出多线程情况下还是会有问题： CPU如何保证有序性？处理器主要通过内存屏障机制来解决有序性问题，如果不想让它重排，在两条指令中间加一道屏障。拿X86平台来说，有几种主要的内存屏障： lfence，是一种Load Barrier(读屏障)，在lfence指令前的所有读操作当必须在lfence指令后的所有读操作前完成 sfence, 是一种Store Barrier(写屏障)，在sfence指令前的所有写操作当必须在sfence指令后的所有写操作前完成 mfence, 是一种General Barrier(通用屏障)，在mfence指令前的所有读写操作当必须在mfence指令后的所有读写操作前完成 除了内存屏障，也可以使用原子指令，如x86上的”lock…”前缀 Java自带的有序性操作： volatile关键字(内存屏障) synchronized关键字(单线程操作，as-if-serial语意自动保证) Lock相关类(单线程操作，as-if-serial语意自动保证) 总结原子性、可见性、有序性问题是一切线程安全问题的根源，单纯的保证操作具有某一种特性只能解决某一部分场景问题。Java提供了很多类以及修饰符，提供了不同维度的保证，底层也都是封装CPU提供的措施来实现。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(一) 基本概念","slug":"多线程基本概念","date":"2020-03-01T05:00:00.000Z","updated":"2020-11-28T09:15:11.902Z","comments":true,"path":"2020/03/01/多线程基本概念/","link":"","permalink":"http://yoursite.com/2020/03/01/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","excerpt":"","text":"进程操作系统进行资源分配和调度的基本单位，每一个进程都是一个应用程序的执行实例，比如我们启动的一个java项目就是一个jvm进程，操作系统为jvm分配运行内存等资源，进程中包含一个或多个线程，线程之间共享进程的资源(比如堆、栈、方法区等)。 线程CPU运行的最小单位，线程之间共享进程的资源，也有自己的私有空间，比如虚拟机栈、本地方法栈、程序计数器。 进程上下文切换线程上下文切换CPU通过分配时间片来执行任务，当一个任务的时间片用完，就会切换到另一个任务。在切换之前会保存上一个任务的状态，当下次再切换到该任务，就会加载这个状态，任务从保存到再加载的过程就是一次上下文切换。 切出：一个线程被剥夺处理器的使用权而被暂停运行 切入：一个线程被系统选中占用处理器开始或继续运行 线程的上下文是什么？对于CPU来说一个线程就是多条指令集合，线程的运行实质上是多条指令在CPU上的运行，而上下文是指线程私有空间的内容。比如虚拟机栈、本地方法栈保存了某一时刻线程局部变量的值，程序计数器保存了线程此刻执行到哪一条指令的位置。 导致上下文切换的原因？ CPU分配的时间片用完了 有个优先级更高的线程需要被执行 手动操作比如java线程的sleep、yield、wait、join、synchronized、lock等 读取数据库操作由于数据量较大引起IO阻塞,线程会被挂起直到读取完毕再次回归等待被CPU调度 上下文切换的过程？放发生切换的时候，CPU会把被挂起线程的上下文保存在程序计数器和寄存器中，程序计数器存储正在执行的指令序列的位置、寄存器存储工作变量，然后从高速缓存中清除掉被挂起线程的上下文，去加载新线程的上下文到高速缓存中。因此线程上下文的切换需要消耗CPU的资源。 并发与并行单CPU操作系统中多个线程同时运行，实质上是交替占有CPU使用权的过程，同时运行只是CPU处理过快造成的错觉，这种现象可以称作为线程并发运行。 到了多CPU时代才实现真正意义上的多线程同时运行，比如4颗CPU的操作系统可以做到4个线程的同时运行，但是操作系统中可能有很多线程需要被执行，比如有16个线程在运行，那么平均4个线程仍然要争夺一个CPU的使用权，只是同一时刻必然有4个争夺到使用权，这种现象称作为线程并行运行。 由此可以看出，操作系统中CPU的数量对多线程编程非常重要。因此项目开发中要尽量参考所在服务器的CPU配置，作出适当的线程池参数以避免频繁的上下文切换带来的性能损耗。同样在选取机器配置上尽量考虑放置服务的线程特点，比如存放redis服务选用多处理器的CPU没有任何意义，redis永远只在一个处理器上面运行。 线程安全在开发中使用过线程都知道，多线程编程需要面对线程安全问题，而线程安全问题归根结底就三个方面:可见性、原子性、有序性，下一章节会详细讲解这些问题。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]}],"categories":[{"name":"缓存中间件","slug":"缓存中间件","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"redis","slug":"缓存中间件/redis","permalink":"http://yoursite.com/categories/%E7%BC%93%E5%AD%98%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"},{"name":"消息中间件","slug":"消息中间件","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RocketMQ","slug":"消息中间件/RocketMQ","permalink":"http://yoursite.com/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/RocketMQ/"},{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]}