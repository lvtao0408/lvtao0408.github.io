{"meta":{"title":"来杯冰镇可乐","subtitle":"","description":"","author":"lvtao","url":"http://yoursite.com","root":"/"},"pages":[{"title":"所有分类","date":"2020-09-29T01:49:01.545Z","updated":"2020-04-12T05:48:42.451Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"多线程(十五) 常见问题场景","slug":"常见问题场景","date":"2020-03-16T05:00:00.000Z","updated":"2020-10-19T08:45:31.882Z","comments":true,"path":"2020/03/16/常见问题场景/","link":"","permalink":"http://yoursite.com/2020/03/16/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%9C%BA%E6%99%AF/","excerpt":"","text":"简介待更新","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十四) 性能调优","slug":"性能调优","date":"2020-03-15T05:00:00.000Z","updated":"2020-10-19T08:44:35.889Z","comments":true,"path":"2020/03/15/性能调优/","link":"","permalink":"http://yoursite.com/2020/03/15/%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/","excerpt":"","text":"简介待更新","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十三) 异步或并行","slug":"异步或并行","date":"2020-03-14T05:00:00.000Z","updated":"2020-10-19T08:43:55.698Z","comments":true,"path":"2020/03/14/异步或并行/","link":"","permalink":"http://yoursite.com/2020/03/14/%E5%BC%82%E6%AD%A5%E6%88%96%E5%B9%B6%E8%A1%8C/","excerpt":"","text":"简介待更新","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十二) 线程池","slug":"线程池","date":"2020-03-13T05:00:00.000Z","updated":"2020-10-19T08:43:19.343Z","comments":true,"path":"2020/03/13/线程池/","link":"","permalink":"http://yoursite.com/2020/03/13/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"","text":"简介待更新","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(十一) ThreadLocal","slug":"ThreadLocal","date":"2020-03-12T05:00:00.000Z","updated":"2020-10-19T08:43:11.150Z","comments":true,"path":"2020/03/12/ThreadLocal/","link":"","permalink":"http://yoursite.com/2020/03/12/ThreadLocal/","excerpt":"","text":"简介待更新","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(九) 线程通信","slug":"线程通信与协作","date":"2020-03-10T05:00:00.000Z","updated":"2020-11-06T01:19:06.718Z","comments":true,"path":"2020/03/10/线程通信与协作/","link":"","permalink":"http://yoursite.com/2020/03/10/%E7%BA%BF%E7%A8%8B%E9%80%9A%E4%BF%A1%E4%B8%8E%E5%8D%8F%E4%BD%9C/","excerpt":"","text":"简介线程与线程之间不是相互独立的个体，有些时候需要相互通信来共同完成某个业务场景，多线程之间通信总体来说分为共享内存和消息通信机制。 wait/notify概念wait/notify采用消息通信机制来进行线程间的通信，某个线程必须达到特定条件才能继续执行下去，没有达到就将自己挂起等待，另一个线程的执行过程中会使条件达成并通知挂起等待的线程继续执行下去。 wait/notify都属于Object的方法，利用java自带的对象加锁机制争夺对应monitor，当线程不满足执行条件时调用Object的wait方法将自己挂起在monitor对象的_WaitSet上，其他线程在执行过程中将条件满足，紧接着使用Object的notify或notifyAll方法唤醒前述的等待线程，重新加入锁的竞争。 使用场景例如线程独有的join()方法就是通过wait/notify实现线程的合并(非异步调用)，在join线程执行过程中调用者线程只能等待，为了避免CPU的浪费，使用wait()方法将自己挂起在join线程的monitor对象的_WaitSet中，当join线程执行完毕后使用notify()唤醒调用者线程，继续往下执行。 在例如生产者/消费者模式，消费者线程使用while循环监听消息，如果消息队列为空则使用wait()将自己挂起，同样避免忙等造成CPU的浪费，生产者线程每次生产完数据都必须调用notify()方法，唤醒因消息队列为空而将自己挂起的消费者线程。下面是一段基于wait/notify机制的生产/消费模型： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class Test &#123; private static Object obj &#x3D; new Object(); private static final Queue&lt;String&gt; messageQueue &#x3D; new LinkedBlockingDeque&lt;&gt;(); public static void main(String[] args) throws Exception &#123; Thread producerThread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i &#x3D; 1; i &lt;&#x3D; 9; i++) &#123; &#x2F;&#x2F; 生产消息 synchronized (obj) &#123; messageQueue.add(&quot;第&quot; + i + &quot;条消息&quot;); obj.notify(); &#125; &#x2F;&#x2F; 每生产三条暂停1秒 if (i &gt; 1 &amp;&amp; i % 3 &#x3D;&#x3D; 0) &#123; try &#123; System.out.println(&quot;暂停&quot;); Thread.currentThread().sleep(1000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#x2F;&#x2F; ... &#125; &#125; &#x2F;&#x2F; ... &#125;); Thread consumerThread &#x3D; new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (obj) &#123; try &#123; while (true) &#123; if (messageQueue.isEmpty()) &#123; obj.wait(); &#125; String message &#x3D; messageQueue.poll(); System.out.println(&quot;消费者:&quot; + message); &#125; &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#x2F;&#x2F; ... &#125;); producerThread.start(); consumerThread.start(); &#125;&#125; 为什么wait()、notify()、notifyAll()必须在同步代码块中？这三个方法都是对对象的monitor中的_WaitSet进行操作，而进入同步代码块意味着已经持有对象锁，也就持有了monitor，才有资格对_WaitSet进行操作，因此必须在同步代码块中。 为什么wait()方法要放在while()循环而不是if中？被唤醒后线程从wait()代码之后继续执行，但是并不能保证每次被唤醒都是符合继续执行条件的，用while()被唤醒还会继续判断，不符合条件永远在while()中，而if不会。在N个线程通信的情况下，不能保证那一时刻条件被某个线程改变。 为什么wait()、notify()要定义在Object中而不是线程中？wait()与notify()的基本思想是把某个对象作为联络点，利用锁机制拿到monitor进行联络通信，而java提供的锁是对象级的而不是线程级的，锁属于对象而不是线程专有，因此wait()、notify()、notifyAll()这种锁级别操作属于Object而不是线程专有方法。 lock/condition既然java支持使用锁进行线程通信，synchronized可以，Lock必然也可以。lock/condition与wait/notify功能类似，通过Lcok对象创建Condition对象，利用Condition对象的await()与signal()方法来阻塞唤醒。 CountDownLatch概念CountDownLatch是一种线程同步工具类，它允许一个或多个线程等待直到在其他线程中一组操作执行完成。你可以把它理解为一个计数器，对象被创建的时候指定总数，每有一个线程到达指定条件总数减1，当减到为0时代表所有线程都达到条件，所有等待线程被唤醒继续往下执行，因此CountDownlatch也被称为倒计时锁。 使用场景例如运营系统的流量、业务等统计功能，页面需要统计展示每日的新增用户量、订单数量、商品销售总量、商品销售总额等。如果每个统计类型的查询需要2秒，4个统计类型就需要8秒的时间才能返回给前端，用户显然是无法接受的。我们只需要将4个统计类型的查询由串行执行改为并行执行，等待所有线程都查询完在组装返回，那么整个请求的响应时间就缩短到的了2秒。 上代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697public class Test &#123; public static void main(String[] args) &#123; long startTimeMillis &#x3D; System.currentTimeMillis(); CountDownLatch countDownLatch &#x3D; new CountDownLatch(4); Map&lt;String, Long&gt; statisticsMap &#x3D; new Hashtable&lt;&gt;(); &#x2F;&#x2F; 1.查询新增用户量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;addUserCount&quot;, 1000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 2.查询订单数量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;orderCount&quot;, 248300L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 3.查询商品销售总量 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;commodityCount&quot;, 300L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); &#x2F;&#x2F; 4.查询商品销售总额 new Thread(new Runnable() &#123; @Override public void run() &#123; &#x2F;&#x2F; 模拟两秒查询 try &#123; Thread.sleep(2000L); statisticsMap.put(&quot;totalSales&quot;, 9073180L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; &#x2F;&#x2F; 倒计时锁-1 countDownLatch.countDown(); &#125; &#125; &#125;).start(); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;返回值:&quot; + statisticsMap); long takeTimeMillis &#x3D; System.currentTimeMillis() - startTimeMillis; System.out.println(&quot;耗时:&quot; + takeTimeMillis + &quot;ms&quot;); &#125;&#125; 打印结果:返回值:{commodityCount=300, totalSales=9073180, orderCount=248300, addUserCount=1000}耗时:2006ms CountDownLatch的本质是牺牲运行内存(额外创建的4个线程，每个线程JVM默认分配1M栈空间)以及CPU资源(线程需要在CPU上执行嘛)来提高请求的响应效率。因此CountDownLatch不能盲目使用，要参考JVM大小、CPU核数等配置信息，还要估算接口的QPS，避免大量请求导致JVM栈溢出或CPU使用率到100%。其次装载返回值的容器一定要保证线程安全，避免返回数据不全。 构造器CountDownLatch底层基于AQS实现，当我们调用CountDownLatch countDownLatch= new CountDownLatch(4) 创建一个实例时，会在对象内部创建一个继承AQS的Sync类，并将构造器的参数值赋值给state，所以state的值也代表CountDownLatch所剩余的计数次数。 1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync &#x3D; new Sync(count);&#x2F;&#x2F;创建同步队列，并设置初始计数器值&#125; 静态内部类Sync除了设置state外，分别重写了tryAcquireShared与tryReleaseShared方法： 123456789101112131415161718192021222324252627private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID &#x3D; 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() &#x3D;&#x3D; 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; &#x2F;&#x2F; Decrement count; signal when transition to zero for (;;) &#123; int c &#x3D; getState(); if (c &#x3D;&#x3D; 0) return false; int nextc &#x3D; c-1; if (compareAndSetState(c, nextc)) return nextc &#x3D;&#x3D; 0; &#125; &#125; &#125; countDown()方法当我们调用countDownLatch.countDown()的时候，实质是调用静态内部类Sync的releaseShared()方法： 123public void countDown() &#123; sync.releaseShared(1); &#125; 继续往下看，if中调用的tryReleaseShared()方法是重写的方法，使用CAS将state-1，如果state-1之后是0则返回true，其他情况都是false，重点是使用CAS对state-1操作，至于返回值这里并不重要 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false; &#125; 因此countDown()方法的最终目的是state大于0的情况下，使用CAS方式将state进行-1操作。 await()方法当我们调用countDownLatch.await()的时候，实质上是调用静态内部类Sync的acquireSharedInterruptibly()方法： 123public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; 第二个if中的tryAcquireShared()方法，也是Sync重写的方法，当state等于0的时候if条件是不满足的，也就意味着await()方法到此执行结束，线程不会受到阻塞，当state不等于0的时候(计数次数还没减到0)，才会走doAcquireSharedInterruptibly()方法。 1234567public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg); &#125; AQS的阻塞逻辑之前已经提过了，只有等待队列的第一个是自旋争夺资源，后面的元素是调用park()挂起，在自旋过程中再次调用重写的tryAcquireShared()方法，返回值大于0(state=0)就跳出自旋。 12345678910111213141516171819202122232425private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node &#x3D; addWaiter(Node.SHARED); boolean failed &#x3D; true; try &#123; for (;;) &#123; final Node p &#x3D; node.predecessor(); if (p &#x3D;&#x3D; head) &#123; int r &#x3D; tryAcquireShared(arg); if (r &gt;&#x3D; 0) &#123; setHeadAndPropagate(node, r); p.next &#x3D; null; &#x2F;&#x2F; help GC failed &#x3D; false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; await()方法的作用是让调用线程处于阻塞状态直到state减到0，并且等待过程中支持可中断。 CyclicBarrierCyclicBarrier是一个同步的辅助类，允许一组线程相互之间等待，并设置一个公共屏障点，当组内线程达到这个屏障点的时候阻塞，阻塞在这个屏障点的线程数达到指定数量时，释放所有线程继续往下执行。CyclicBarrier在释放完线程后相当于重置之前的记录可以循环使用，所以称之为Cyclic(循环)Barrier(屏障)。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(九) Lock家族","slug":"Lock家族","date":"2020-03-09T05:00:00.000Z","updated":"2020-10-22T07:48:58.201Z","comments":true,"path":"2020/03/09/Lock家族/","link":"","permalink":"http://yoursite.com/2020/03/09/Lock%E5%AE%B6%E6%97%8F/","excerpt":"","text":"Lock继承体系Lock接口Lock接口诞生于JDK1.5，接口内部提供了最基本的加锁、释放锁方法: 1234567891011121314151617181920public interface Lock &#123; &#x2F;&#x2F; 直接加锁 void lock(); &#x2F;&#x2F; 支持可中断的加锁 void lockInterruptibly() throws InterruptedException; &#x2F;&#x2F; 尝试一次加锁 boolean tryLock(); &#x2F;&#x2F; 尝试一次加锁(支持超时停止阻塞) boolean tryLock(long time, TimeUnit unit) throws InterruptedException; &#x2F;&#x2F; 解锁 void unlock(); &#x2F;&#x2F; 创建一个Condition(作用于线程通信，后面会讲) Condition newCondition(); 使用层面既然是接口，就是提供给开发者实现用的，Java自带了ReentrantLock、Condition、ReentrantReadWriteLock实现类供开发者使用。如果这些类无法满足业务需求，开发者可以通过实现Lock接口并利用AQS框架，自己定义一个Lock的具体实现锁(是否公平、是否支持超时、是否支持重入等)，从而提高锁的灵活性。 与synchronized区别由于Lock可以自己定义是否公平、是否支持超时、是否支持重入等功能，相对于synchronized关键字来说可发挥的空间更多，也更灵活。但是Lock的加锁、释放锁需要开发者自己编写，如果考虑不周很可能造成死锁情况(最好在try中加锁，finally中释放锁)，而synchronized由JVM实现，完全不需要担心这些情况。 ReentrantLockReentrantLock就是Java自带的Lock实现类，字面的意思就能看出来是一把可重入锁，并且功能几乎与synchronized相似，我们看看源码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; &#x2F;&#x2F; 定义一个顶级同步器(内部包含一个非公平加锁方法，一个释放锁方法) abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID &#x3D; -5179523762034025860L; abstract void lock(); &#x2F;&#x2F; 非公平方式尝试一次加锁 final boolean nonfairTryAcquire(int acquires) &#123; &#x2F;&#x2F; 获取试图尝试加锁的线程 final Thread current &#x3D; Thread.currentThread(); &#x2F;&#x2F; 获取公共资源状态 int c &#x3D; getState(); &#x2F;&#x2F; 如果没其他线程持有锁，进行加锁 if (c &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 加锁前并没有校验等待队列是否已经有节点在等待了，这个if完全体现了非公平性 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; &#x2F;&#x2F; 如果有线程持有锁并且是自身，重入次数递增 else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123; int nextc &#x3D; c + acquires; if (nextc &lt; 0) &#x2F;&#x2F; overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; &#x2F;&#x2F; 到这里说明锁被其他线程占了，直接返回false return false; &#125; &#x2F;&#x2F; 释放锁 protected final boolean tryRelease(int releases) &#123; &#x2F;&#x2F; 计算递减后的重入次数 int c &#x3D; getState() - releases; &#x2F;&#x2F; 如果释放锁线程不是持有锁线程，抛异常(一般能执行这方法的都是持有锁线程) if (Thread.currentThread() !&#x3D; getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); &#x2F;&#x2F; 如果递减后为0，那就是真的释放锁了，清空自己的独占状态并返回 boolean free &#x3D; false; if (c &#x3D;&#x3D; 0) &#123; free &#x3D; true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; &#x2F;&#x2F; 返回调用此方法的线程是否持有锁 protected final boolean isHeldExclusively() &#123; return getExclusiveOwnerThread() &#x3D;&#x3D; Thread.currentThread(); &#125; &#x2F;&#x2F; 其他方法... &#125; &#x2F;&#x2F; 定义一个非公平同步器，继承顶级同步器 static final class NonfairSync extends Sync &#123; private static final long serialVersionUID &#x3D; 7316153563782823691L; &#x2F;&#x2F; 实现顶级同步器的lock加锁方法 final void lock() &#123; &#x2F;&#x2F; 尝试CAS 如果成功说明之前没线程加锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); &#x2F;&#x2F; 失败就在尝试获取一次，这里调用AQS的acquire()方法， &#x2F;&#x2F; AQS的acquire()方法又调用下面重写的tryAcquire方法 else acquire(1); &#125; &#x2F;&#x2F; 绕了一大圈，其实就是用非公平锁方式加锁 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125; &#125; &#x2F;&#x2F; 定义一个公平同步器，继承顶级同步器 static final class FairSync extends Sync &#123; private static final long serialVersionUID &#x3D; -3000897897090466540L; final void lock() &#123; acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; final Thread current &#x3D; Thread.currentThread(); int c &#x3D; getState(); if (c &#x3D;&#x3D; 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123; int nextc &#x3D; c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; &#125; &#x2F;&#x2F; 无参构造器，默认使用非公平锁 public ReentrantLock() &#123; sync &#x3D; new NonfairSync(); &#125; &#x2F;&#x2F; 参数构造器，自行选择是否公平 public ReentrantLock(boolean fair) &#123; sync &#x3D; fair ? new FairSync() : new NonfairSync(); &#125; &#x2F;&#x2F; 加锁 public void lock() &#123; sync.lock(); &#125; &#x2F;&#x2F; 支持可中断加锁 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; &#x2F;&#x2F; 尝试一次加锁 public boolean tryLock() &#123; return sync.nonfairTryAcquire(1); &#125; &#x2F;&#x2F; 支持超时的加锁 public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; &#x2F;&#x2F; 解锁 public void unlock() &#123; sync.release(1); &#125; &#x2F;&#x2F; 其他方法....&#125; 重入支持ReentrantLock通过state属性控制重入，每次重入state+1、退出state-1，为0时代表释放锁。 是否公平锁 ReentrantLock类支持公平锁与非公平锁，并根据构造器初始化一个Sync(公平锁创建FairSync，非公平锁创建NonfairSync)，后续加锁释放锁等操作完全调用Sync实现。FairSync与NonfairSync除了加锁逻辑不一样，其他的逻辑(比如释放锁等)完全一样。 ReentrantLock加锁是使用Sync的lock()实现，公平锁(FairSync)是直接调用AQS的acquire()方法获取锁，然后调用重写的tryAcquire()方法。在重写方法里面如果可以加锁(state=0)，会先判断等待队列是否有元素在等待，如果没有元素可以直接加锁，如果加锁失败或存在元素，则加入等待队列尾部等待(按顺序排队)。 非公平锁(NonFairSync)在调用Sync的lock()方法时，只要可以加锁(state=0)，会直接使用CAS进行加锁(无视等待队列是否有元素)，如果插队失败了在调用AQS的acquire()再次加锁，重写的tryAcquire()方法还是会再次尝试插队，如果还是失败才会加入等待队列，因此非公平锁存在2次插队的操作。 ReadWriteLock接口没啥好写的 ReentrantReadWriteLock没啥好写的","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(八) AQS","slug":"AQS","date":"2020-03-08T05:00:00.000Z","updated":"2020-10-22T07:47:24.824Z","comments":true,"path":"2020/03/08/AQS/","link":"","permalink":"http://yoursite.com/2020/03/08/AQS/","excerpt":"","text":"AQS简介AQS的全称是AbstractQueuedSynchronizer，类内部定义了一套多线程访问共享资源的同步器框架，Java许多同步类的实现都依赖于它，比如常用的ReentrantLock、Semaphore、CountDownLatch等，我们也可以利用AQS自己实现一个锁。 AQS类内部的核心为volatile int state(共享资源)和CLH线程等待队列(阻塞队列)，整个AQS类内部大量的方法都是围绕state、CLH队列在处理逻辑。 statestate作为共享资源被应用在多线程竞争上，自带的volatile关键字可以保证可见性、有序性，在搭配CAS使用后可以保证操作的原子性。state初始状态为0，线程使用CAS对state+1成功后持有锁，后续每次重入state+1、退出state-1，state递减为0时代表锁释放。 CLH队列当线程竞争失败后会被封装成Node节点加入CLH队列，CLH队列在AQS中是以前驱节点(head)、后驱节点(tail)俩个成员构成的Node类型链表: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&#x2F;&#x2F; 前驱节点private transient volatile Node head;&#x2F;&#x2F; 后驱节点private transient volatile Node tail;&#x2F;&#x2F; 静态内部类Nodestatic final class Node &#123; &#x2F;** 共享锁 *&#x2F; static final Node SHARED &#x3D; new Node(); &#x2F;** 独占锁 *&#x2F; static final Node EXCLUSIVE &#x3D; null; &#x2F;** 表示线程已被取消 *&#x2F; static final int CANCELLED &#x3D; 1; &#x2F;** 表示后续线程需要取消阻塞 *&#x2F; static final int SIGNAL &#x3D; -1; &#x2F;** 表示线程在条件下等待 *&#x2F; static final int CONDITION &#x3D; -2; &#x2F;** 表示下一个获取共享应无条件传播 *&#x2F; static final int PROPAGATE &#x3D; -3; &#x2F;** * 节点等待状态 * 等于0:该节点尚未被初始化完成 * 大于0:说明该线程中断或者等待超时，需要移除该线程 * 小于0:该线程处于可以被唤醒的状态 *&#x2F; volatile int waitStatus; &#x2F;** 前驱节点 *&#x2F; volatile Node prev; &#x2F;** 后继节点 *&#x2F; volatile Node next; &#x2F;** 获取同步状态的线程 *&#x2F; volatile Thread thread; &#x2F;** 将单向列表变成双向列表 *&#x2F; Node nextWaiter; &#x2F;&#x2F; 是否为共享节点 final boolean isShared() &#123; return nextWaiter &#x3D;&#x3D; SHARED; &#125; &#x2F;&#x2F; 获取前继节点，没有就抛出异常 final Node predecessor() throws NullPointerException &#123; Node p &#x3D; prev; if (p &#x3D;&#x3D; null) throw new NullPointerException(); else return p; &#125; &#x2F;&#x2F; 无参构造器 Node() &#123; &#125; &#x2F;&#x2F; 构造器 Node(Thread thread, Node mode) &#123; &#x2F;&#x2F; Used by addWaiter this.nextWaiter &#x3D; mode; this.thread &#x3D; thread; &#125; &#x2F;&#x2F; 构造器 Node(Thread thread, int waitStatus) &#123; &#x2F;&#x2F; Used by Condition this.waitStatus &#x3D; waitStatus; this.thread &#x3D; thread; &#125;&#125; Node内部类主要通过waitStatus来表示状态，主要有五种状态: 状态 状态值 描述 INITAL 0 初始状态 CANCELLED 1 此节点的后继节点(或即将)被阻塞，因此当前节点在释放或取消时必须取消对其后继节点的阻塞 SIGNAL -1 此节点的后继节点(或将很快)被阻塞(通过park)，因此当前节点在释放或取消时必须取消对其后继节点的阻塞。为了避免争用，获取方法必须首先表明它们需要一个信号，然后重试原子获取，然后在失败时阻塞 CONDITION -2 节点线程等待在Condition上，当其他线程对Condition调用了signal()方法后，该节点从等待队列中转移到同步队列中，加入到对同步状态的获取中 PROPAGATE -3 与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态 链表入列链表的入列采用CAS方式进行，前驱节点与后驱节都是被volatile修饰的，因此使用CAS修改可以保证绝对安全，在enq方法中AQS使用死循环保证节点可以正确添加，只有成功添加后，当前线程才会从该方法返回，否则会一直执行下去: 123456789101112131415161718192021222324252627282930313233343536private Node addWaiter(Node mode) &#123; &#x2F;&#x2F; 新建Node Node node &#x3D; new Node(Thread.currentThread(), mode); &#x2F;&#x2F; CAS快速尝试添加尾节点(侥幸心理，万一成功了呢) Node pred &#x3D; tail; if (pred !&#x3D; null) &#123; node.prev &#x3D; pred; &#x2F;&#x2F;CAS设置尾节点 if (compareAndSetTail(pred, node)) &#123; pred.next &#x3D; node; return node; &#125; &#125; &#x2F;&#x2F;多次尝试 enq(node); return node;&#125; private Node enq(final Node node) &#123; &#x2F;&#x2F;多次尝试，直到成功为止 for (;;) &#123; Node t &#x3D; tail; &#x2F;&#x2F;tail不存在，设置为首节点 if (t &#x3D;&#x3D; null) &#123; if (compareAndSetHead(new Node())) tail &#x3D; head; &#125; else &#123; &#x2F;&#x2F;设置为尾节点 node.prev &#x3D; t; if (compareAndSetTail(t, node)) &#123; t.next &#x3D; node; return t; &#125; &#125; &#125; &#125; 当线程被封装成Node节点成功追加到等待队列尾部后，为了节约CPU资源就需要将当前线程挂起了(被阻塞的线程如果支持可中断并且被中断，自动唤醒并抛出中断异常): 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051final boolean acquireQueued(final Node node, int arg) &#123; &#x2F;&#x2F; 获取资源是否失败标记 boolean failed &#x3D; true; try &#123; &#x2F;&#x2F;标记等待过程中是否被中断过 boolean interrupted &#x3D; false; &#x2F;&#x2F; 自旋 for (;;) &#123; &#x2F;&#x2F;拿到前驱节点 final Node p &#x3D; node.predecessor(); &#x2F;* * 如果前驱是head，说明自己排在第二位，有可能马上就被执行 * 所以再次尝试tryAcquire()获取，如果失败就挂起等待 * 当然有可能是第一位搞完了释放资源唤醒自己，也有可能被interrupt *&#x2F; if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123; &#x2F;&#x2F; 获取到资源后，把自己设置为head，也就是说head指向的永远是当前拿到资源的 setHead(node); &#x2F;&#x2F; 断绝与前驱节点的联系，方便被GC回收 p.next &#x3D; null; &#x2F;&#x2F; 成功获取资源后将失败标记为false failed &#x3D; false; &#x2F;&#x2F; 返回等待过程中是否被中断过 return interrupted; &#125; &#x2F;* * 先去检查自己是否真的可以被挂起了，如果不符合条件会进入下一次循环直到符合为止 * 调用park()方法将自己挂起，直到被唤醒 * 唤醒后会返回是否被中断标记，方便下次return出去 *&#x2F; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted &#x3D; true; &#125; &#125; finally &#123; &#x2F;&#x2F; 如果等待过程中没有成功获取资源(如timeout，或者可中断的情况下被中断了)，取消结点在队列中的等待。 if (failed) cancelAcquire(node); &#125;&#125; shouldParkAfterFailedAcquire方法，检查自己是否真的可以被挂起了: 123456789101112131415161718192021private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; &#x2F;&#x2F; 拿到前驱节点的状态 int ws &#x3D; pred.waitStatus; &#x2F;&#x2F; 如果前驱节点的状态是SIGNAL，那么前驱节点执行完会自动唤醒自己，放心的将自身挂起就好了 if (ws &#x3D;&#x3D; Node.SIGNAL) return true; &#x2F;&#x2F; 如果前驱节点执行过程中放弃了(超时或者其他的)，一直往前找，直到找到正常等待的状态节点 if (ws &gt; 0) &#123; do &#123; node.prev &#x3D; pred &#x3D; pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next &#x3D; node; &#125; else &#123; &#x2F;&#x2F; 如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; parkAndCheckInterrupt方法，就是挂起: 12345678private final boolean parkAndCheckInterrupt() &#123; &#x2F;&#x2F;调用park()使线程进入waiting状态 LockSupport.park(this); &#x2F;&#x2F;如果执行到这里，说明被唤醒，查看自己是不是被中断的。 return Thread.interrupted();&#125; 内部方法主要方法 acquire(int arg):独占式获取同步状态，如果当前线程获取成功则返回，否则加入等待队列 acquireInterruptibly(int arg):独占式获取同步状态(同上)，如果被打断直接抛异常 tryAcquire(int arg):独占式获取同步状态(供开发者重写) tryAcquireNanos(int arg，long nanosTimeout):独占式获取同步状态，增加超时限制 release(int arg):独占式释放同步状态，释放后将同步队列中第一个节点包含的线程唤醒 tryRelease(int arg):独占式释放同步状态(供开发者重写) acquireShared(int arg):共享式获取同步状态，如果当前线程获取成功则返回，否则加入等待队列 acquireSharedInterruptibly(int arg):共享式获取同步状态(同上)，如果被打断直接抛异常 tryAcquireShared(int arg):共享式获取同步状态(供开发者重写) tryAcquireSharedNanos(int arg，long nanosTimeout):共享式获取同步状态，增加超时限制 releaseShared(int arg):共享式释放同步状态，释放后将同步队列中第一个节点包含的线程唤醒 tryReleaseShared(int arg):共享式释放同步状态(供开发者重写) isHeldExclusively():当前同步器是否在独占式模式下被线程占用，一般该方法表示是否被当前线程所独占 方法虽然很多，不过很容易进行区分 首先争夺锁的方式有独占和共享 每种方式又包含加锁、释放锁方法 加锁的方法又分为直接加锁、超时加锁、中断加锁 直接加锁与中断加锁内部调用对应try开头的加锁方法处理 try开头的加锁方法采用模板模式，具体实现由开发者自己重写实现 最后一个是否独占并占用的查询 共享资源获取释放在需要开发者重写的获取资源方法中，独占式获取资源方法tryAcquire(int arg)返回值为boolean类型，仅仅需要告诉调用者获取成功还是失败即可。 而共享式获取资源方法acquireShared(int arg)返回int类型，大于等于零表示成功，小于零则表示失败，因为是共享所以允许多个线程访问获取，但有些时候我们需要限制访问数量。这就可以设置一个阈值，每次有线程进来时阈值-1消耗，当消耗为零的时候，后续线程就不允许访问了，直接进入等待队列。 同样的，共享式资源的释放相比较独占式逻辑也有不同，除了唤醒后继节点，还需要将阈值+1。 源码解析独占式获取同步状态 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; 先尝试用重写的tryAcquire(arg)方法，如果失败了就将线程封装成一个独占式锁加入队列中，紧接着尝试挂起线程。也就是说tryAcquire(arg)方法获取成功了就算拿到锁了，失败了也不要紧，在将自己挂起的过程中发现前驱节点已经放弃了也算拿到锁，其他情况就阻塞。 独占式释放锁 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h &#x3D; head; if (h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0) unparkSuccessor(h); return true; &#125; return false;&#125; 先尝试调用重写的tryRelease(int arg)释放锁，如果成功后判断自身状态，如果状态不等于0(也就是还没退出等待队列)，调用unparkSuccessor方法释放锁: 12345678910111213141516171819202122232425262728private void unparkSuccessor(Node node) &#123; &#x2F;&#x2F; 获取当前节点的状态 int ws &#x3D; node.waitStatus; &#x2F;&#x2F; 如果小于0，使用CAS设置为0，0代表退出等待队列 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); &#x2F;&#x2F; 获取后继节点 Node s &#x3D; node.next; &#x2F;&#x2F; 如果没有后继节点，或者后继节点状态大于0，也就是说已经退出队列了 if (s &#x3D;&#x3D; null || s.waitStatus &gt; 0) &#123; &#x2F;&#x2F; 方便GC回收 s &#x3D; null; &#x2F;&#x2F; 不停的往后面找，直到找到状态正常的为止 for (Node t &#x3D; tail; t !&#x3D; null &amp;&amp; t !&#x3D; node; t &#x3D; t.prev) if (t.waitStatus &lt;&#x3D; 0) s &#x3D; t; &#125; &#x2F;&#x2F; 如果找到了就唤醒 if (s !&#x3D; null) LockSupport.unpark(s.thread); &#125; 这个方法的逻辑也很简单，使用CAS方式将自身状态设置为0，紧接着根据自身的waitStatus判断后继节点是否需要被唤醒，如果后继节点因为响应中断等情况放弃了，就继续往后找，直到找到可以背唤醒的节点线程。 共享式共享式几乎和独占式的执行逻辑差不多… 简单应用看懂AQS的原理机制后，我们可以尝试自己写一个不可重入锁，首先定义一下锁资源(AQS中的state)的含义，0表示未被加锁，1表示已经加锁。直接上代码: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class CustomLock &#123; private Sync sync; &#x2F;&#x2F; 自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; &#x2F;&#x2F; 判断是否锁定状态 @Override protected boolean isHeldExclusively() &#123; return getState() &#x3D;&#x3D; 1; &#125; &#x2F;&#x2F; 获取资源 @Override protected boolean tryAcquire(int arg) &#123; &#x2F;&#x2F; 使用CAS修改状态，如果成功设置当前资源为独占资源 if(compareAndSetState(0, 1))&#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; &#x2F;&#x2F; 释放资源 @Override protected boolean tryRelease(int arg) &#123; &#x2F;&#x2F;既然释放，肯定就是已占有状态了，为了代码健壮一点加层判断 if (getState() &#x3D;&#x3D; 0) throw new IllegalMonitorStateException(); &#x2F;&#x2F; 清空独占记录 setExclusiveOwnerThread(null); &#x2F;&#x2F; 释放共享资源，tryRelease还没执行完，线程仍然持有锁，因此不需要CAS修改 setState(0); return true; &#125; &#125; &#x2F;&#x2F; 在自定义加锁对象创建时，为其初始化一个同步器 public CustomLock()&#123; sync &#x3D; new Sync(); &#125; &#x2F;&#x2F; 加锁 public void lock() &#123; sync.acquire(1); &#125; &#x2F;&#x2F; 单次加锁尝试 public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; &#x2F;&#x2F; 释放锁 public void unlock()&#123; sync.release(1); &#125; &#x2F;&#x2F; 锁是否处于加锁状态 public boolean isLocked()&#123; return sync.isHeldExclusively(); &#125;&#125; 可重入锁在加锁、释放锁的时候需要对state进行加减操作，并且确保退出的时候state为零，再此期间其他线程访问时如果state大于等于零，则获取锁失败。由于这段代码设计的是不可重入锁，不需要记录次数，仅仅有加锁(1)和未加锁(0)俩中状态，因此lock()、tryLock()、unlock()方法传参随便写都可以，在内部类Sync重写AQS方法中已经写死。 利用AQS我们可以实现很多种同步机制，比如CountDownLatch、CyclicBarrier、Semaphore、Lock诸多实现类，都是利用AQS来实现。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(七) synchronized关键字","slug":"synchronized关键字","date":"2020-03-07T05:00:00.000Z","updated":"2020-10-19T07:47:11.609Z","comments":true,"path":"2020/03/07/synchronized关键字/","link":"","permalink":"http://yoursite.com/2020/03/07/synchronized%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"简介如果我们想要保证单个共享变量的原子操作，可以借助CAS来实现，当我们想要保证多个共享变量的原子操作时，那就要把对多个变量的操作代码整合在一起建立临界区，临界区同一时刻只能有一个线程访问。而synchronized关键字就是java老牌的互斥锁，保证操作的原子性、可见性、有序性，同时还保证锁的可重入性。 synchronized使用 修饰方法的时候，如果是普通方法，加锁目标是此实例对象(new出来的、存放在堆中的某个对象) 修饰方法的时候，如果是静态方法，加锁目标是当前类的class对象(存在方法区的类结构对象) 修饰代码块的时候，需要指定某个实例对象或class对象作为加锁目标 jvm对象头无论哪种方式实现线程同步，都必须指定一个对象并获得此对象的锁才有资格执行同步方法或代码块，synchronized的实现完全依赖于jvm，因此理解synchronized的底层实现，就必须理解对象在jvm是如何存储的，关于锁的那部分数据信息又是如何维护的。 在JVM虚拟机中，对象在内存中的存储布局，一般情况下分为三个区域： 对象头(包括标记字段、类型指针) 实例数据(存储对象自身定义的数据) 对齐填充(jvm要求对象的内存大小必须是8字节整倍数，对齐填充用于补全大小到整倍数) 如果对象是数组，还会有个区域记录数组的长度，用于判断数组对象的内存大小 有关对象锁的数据全部存储在对象头区域中，我们使用java提供的jol工具来看看对象的头部信息详细结构(测试为64位操作系统): 1.先添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jol-core&lt;&#x2F;artifactId&gt; &lt;version&gt;0.9&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 2.创建测试用对象 12345678910111213141516171819public class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name &#x3D; name; this.age &#x3D; age; &#125; public synchronized void doSomething()&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; ... &#125; &#125;&#125; 3.执行main方法 1234public static void main(String[] args) &#123; Person person &#x3D; new Person(&quot;李逍遥&quot;,18); System.out.println(ClassLayout.parseInstance(person).toPrintable());&#125; 4.打印结果 表头代表的含义： 列名 描述 OFFSET 偏移地址，单位字节 SIZE 占用的内存大小，单位字节 TYPE DESCRIPTION 类型描述，其中object header为对象头类型 VALUE 类型对应的值 颜色标记区域代表的含义： 区域 描述 红色 标记字段，内部结构比较复杂，而且会不断变化，下面单独讲 蓝色 类型指针，通常由64位组成，但是我们jvm会默认对其压缩到32位，因此占用4字节 绿色 实例数据，基本数据类型会直接打印值，引用数据类型显示(object) 黄色 对齐填充，图中对象占用总内存为20字节，因此对齐填充补了4字节确保是8字节倍数 与synchronized底层原理关联最为密切的就是红色区域了，这个区域也比其他区域更为复杂一点，标记字段拥有8字节的内存大小(也就是64位)，对象锁状态的不同，这64位存储的内容也不同： 标记字段中存储的信息： hash:存储对象哈希码，只有在调用hashCode()方法的时候才会生成，默认是没值的 age:jvm分代年龄，用于判断是否晋升老年代 biased_lock:偏向锁标识位 lock:锁状态标识位 JavaThread:保存持有偏向锁的线程ID epoch:保存偏向时间戳(并不是我们理解的long类型时间戳) Pointer to Lock Record:指向线程栈中锁记录的地址 Pointer to Monitor:指向jvm监控对象的地址 无锁状态所谓无锁状态，就是对象还没有被加过锁，也就是说内部的synchronized修饰的方法还没有任何线程调用过，上面打印的截图是没有调用hashCode()方法的，我们写个调用hashCode()方法的测试代码： 12345public static void main(String[] args)&#123; Object lockObject &#x3D; new Object(); System.out.println(&quot;哈希码 : &quot; + lockObject.hashCode()); System.out.print(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果： 我们把二进制数据拼接起来，拼接规则是从下至上、从右到左。 最终拼接结果为:00000000 00000000 00000000 01111011 00011101 01111111 11111111 00000001 取出哈希码:1111011 00011101 01111111 11111111 随便找个进制转换器就能算出来结果是:2065530879，与main方法打印的一致。 偏向锁偏向锁是jdk1.6引入的一项锁优化，意思是偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。 JVM启动时会进行一系列的复杂活动，比如装载配置，系统类初始化等等。在这个过程中会使用大量synchronized关键字对对象加锁，且这些锁大多数都不是偏向锁。为了减少初始化的时间，JVM默认采用延时加载偏向锁的机制(大概4秒左右)。在延迟时间内是没有偏向锁概念的，对象创建完毕后是无锁状态，即使需要进行锁升级也是直接升级到轻量级锁，当到达延迟时间之后创建出来的对象，锁状态都是偏向锁状态。 所以我们直接执行main方法是看不到偏向锁信息的，当然也可以在创建对象之前sleep五秒，不过这个方法太low逼了，JVM提供了取消偏向锁延迟加载命令:-XX:BiasedLockingStartupDelay=0 测试类走起: 1234public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); System.out.println(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果: 打印结果可以看出，对象还没有被作为加锁对象使用，偏向线程是空的。我们写个持有偏向线程的代码，并且手动调用一次gc看看age有没有增长: 1234567public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); System.gc(); synchronized (lockObject)&#123; System.out.print(ClassLayout.parseInstance(lockObject).toPrintable()); &#125;&#125; 打印结果: 打印结果中并不存在hashcode，这是因为在HotSpot虚拟机中，偏向锁与hashcode不可以并存(我估计是JavaThread占用的太多，没地方了…)，如果在无锁状态调用hashcode方法，直接升级到轻量级锁，如果是偏向锁状态下调用hashcode()，直接进入偏向锁撤销阶段。这种规则仅限于没有重写hashcode()方法的情况下。 偏向锁工作流程图: CAS获取偏向锁步骤整个流程图最大的疑问在于CAS获取偏向锁的这一步骤，如果线程A获取偏向锁并开始执行同步代码或方法块期间，线程B试图访问同步方法或代码块，按照我们的理解CAS成功是必然的，因为此刻线程A还在执行临界区代码，不会对标记字段进行修改干扰到线程B，这不就出现2个线程同时进入同步代码了吗？ 实时并非如此，无论是无锁状态(001)下的CAS，还是偏向锁状态下的CAS，期望值参数永远是null，也就意味着多个线程同时对无锁状态的同步代码争夺偏向锁，仅有一个线程会成功并成为偏向线程，之后任何线程在尝试CAS获取偏向锁永远是失败的(因为JavaThread已经非null)，直接进入偏向锁撤销阶段。 锁撤销偏向锁的撤销需要到达JVM的STW才会执行，这个时间点内所有字节码都不会执行，紧接着挂起偏向线程，根据isAlive()判断偏向线程状态再做后续处理: 如果处于未活动状态，说明偏向线程已经执行完毕并死亡，说明没有发生竞争，直接释放偏向锁。 如果处于活动状态并且已经退出同步代码块，说明没有发生竞争，释放偏向锁后需要唤醒线程继续执行。 如果处于活动状态并且未退出同步代码块，说明发生竞争,直接升级到轻量级锁。 锁重偏向通过对撤销步骤的了解不难发现，只有在到达安全点后，偏向线程已经死亡或者退出同步代码块，加锁对象的markword中JavaThread和epoch才会被清空，直到下一个线程获得偏向锁，加锁对象重新偏向另一个线程。 锁批量撤销JVM会以class为单位，为每个class分配一个偏向锁撤销计数器，每次class的实例被撤销偏向锁时计数器+1，当某个class的计数器达到阈值时(JVM参数控制)，JVM会将该class的所有实例批量撤销偏向锁，并且该class后续创建的所有实例都是不可偏向的(直接是轻量级锁)。 批量撤销阈值: -XX:BiasedLockingBulkRevokeThreshold = 40 锁批量重偏向重偏向操作需要等到安全点才可以触发，如果刚触发锁撤销操作的时候，偏向线程就执行完同步代码块，那么此时等待安全点是没有任何意义的，并且锁撤销也会占用一定的STW时间。由此可以看出频繁的锁撤销会对性能带来一定影响，为了解决这个问题，JVM引入了批量重偏向概念来减少锁撤销的频率。 与批量撤销的相似，批量重偏向也是在class的计数器达到一定阈值时触发，执行过程: 当到达安全点时发现偏向次数到达阈值触发批量重偏向，会对class中的epoch进行+1运算得出epoch_new jvm扫描所有该class的实例对象，并筛选出处于偏向锁状态的实例对象，把所有筛选对象的epoch改成epoch_new 退出安全点后，有线程需要尝试获取偏向锁，检查加锁对象的epoch与对应class的epoch是否一致 如果一致，根据JavaThread是否为自身ID决定撤销锁还是直接进入同步代码(还是原来的逻辑) 如果不一致说明偏向锁已经无效，不会因为加锁对象偏向其他线程而触发撤销操作，而是直接尝试CAS获取锁 注:我猜测此时期望值不在是null而是重新获取加锁对象的markword，获取到锁之后还会把class的epoch归零，因为epoch就2位不可能一直递增。 批量重偏向阈值: -XX:BiasedLockingBulkRebiasThreshold = 20 锁撤销计数器重置即使在竞争很少发生的应用中，随着时间的流逝，各class的锁撤销计数器总有到达阈值的时候。比如某个class的所有实例对象一小时才触发一次锁撤销，那么默认40小时后会触发批量锁撤销，后续所有对象的创建全都是轻量级锁。这种竞争程度简直毛毛雨，根本没必要使用轻量级锁增加无意义的性能消耗。对此JVM增加了两次批量锁撤销事件触发时差的阈值判断，如果距离上次批量撤销时差小于等于阈值时差就执行批量锁撤销，否则仅仅将锁撤销计数重置为零。 批量锁撤销时差阈值(毫秒): -XX:BiasedLockingBulkRebiasThreshold = 25000 启用禁用偏向锁撤销的作用很明显了，根据线程对此临界代码的访问是否发生竞争，来决定将锁恢复到无锁状态还是升级到轻量级。没有发生竞争的情况下，偏向锁的逻辑仍然能保证很好的性能，一旦发生竞争，就需要更高级的锁来最大化性能。偏向锁在竞争稍微激烈的情况下其实没什么卵用，如果你觉得你的应用对于大多数锁的竞争都是比较频繁的，偏向锁完全没有存在的必要，可以设置JVM启动参数来禁用偏向锁(默认延迟打开): 禁用偏向锁: -XX:-UseBiasedLocking 可重入性偏向锁是在没有发生竞争的情况下才存在，线程拿到偏向锁后成为偏向线程，在没有发生偏向锁撤销情况下，后续访问是没有资源消耗的，可以直接执行临界代码，这就代表偏向锁阶段完全支持可重入。 非公平性不存在竞争因此也不存在是否公平性可言。 轻量级锁轻量级锁也是jdk1.6引入的一项锁优化，是在锁发生竞争但竞争不是特别激烈情况下的折中解决方案，降低重量级锁使用过程中的性能消耗。 我们写个测试类(使用 -XX:-UseBiasedLocking命令，禁用偏向锁): 123456public static void main(String[] args) &#123; Object lockObject &#x3D; new Object(); synchronized (lockObject)&#123; System.out.println(ClassLayout.parseInstance(lockObject).toPrintable()); &#125;&#125; 打印结果: 轻量级锁的标记字段结构很简单，只存储锁标志、锁记录俩个信息，hashcode和age转移到Lock Record中进行存储。 轻量级锁工作流程图: 自旋次数在自旋竞争锁过程中，如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。这个自旋次数在jdk1.5是写死的参数无法更改，到了jdk1.6版本可以通过jvm参数控制自旋次数(默认10)，jdk1.7版本后又去掉了此参数，因为这个时候的jvm已经相当成熟，会根据内部收集的性能日志自己判定自旋次数。 轻量级锁自旋次数: -XX:PreBlockSpin=10 锁释放持锁线程执行完释放锁后，将拷贝的markword作为期望值，使用CAS修改加锁对象的markword，可以理解为将hashcode、age等信息还回去。有可能此时已经膨胀到重量级锁，加锁对象的markword已经变更，这种情况下CAS必然失败，这时候直接执行重量级锁的唤醒逻辑。 解锁操作为什么要用CAS来操作呢? 这是为了防止在解锁的时候，锁由于竞争的激烈程度再次提高，已经升级到重量级锁并且把其他线程阻塞，这种情况下如果不唤醒阻塞的线程，这些线程将永远阻塞在这里。 可重入性偏向线程执行过程中遇到锁升级信号(已经发出偏向锁撤销请求)，JVM会在该线程栈中分配一个Lock Record，并把加锁对象的markword拷贝进来，如果已经是轻量级锁情况下，线程访问临界代码前也会执行同样操作。这也就意味着持有轻量级锁过程中，加锁对象的hashcode、age等信息转移到了持锁线程的Lock Record中，持锁线程的Lock Record同样也会保存加锁对象markword的地址，两者是互相引用的关系，这样既能保证加锁对象的hashcode、GC年龄随时可以访问，也可以解决可重入的问题。 非公平性顶多俩线程在竞争，一个在执行，一个在自旋等待，因此也没有是否公平性可言。 重量级锁轻量级锁膨胀之后，就升级为重量级锁了。重量级锁是依赖对象关联的monitor锁来实现的，每个java对象都有一个与之对应的monitor对象，随着java对象一起创建一起销毁。而monitor又依赖操作系统的MutexLock(互斥锁)来实现的，所以重量级锁也被成为互斥锁。 在HotSpot虚拟机中，Monitor是基于C++实现的，封装成ObjectMonitor对象，具体成员变量: 属性名 默认值 属性描述 _header NULL 锁对象的原始对象头 _count 0 用来记录该线程获取锁的次数 _waiters 0 进入wait状态的线程数 _recursions 0 锁的重入次数 _object NULL 关联的锁对象 _owner NULL 指向持有ObjectMonitor对象的线程，锁释放后设置为null _WaitSet NULL 调用wait()方法后进入的wait集合 _WaitSetLock 0 操作WaitSet链表的锁 _Responsible NULL 防止搁浅情况 _succ NULL 假定继承线程 _cxq NULL 被挂起线程等待重新竞争锁的单向链表，为了避免插入和取出元素的竞争，所以Owner会从列表尾部取元素 FreeNext NULL Free list linkage _EntryList NULL 处于block状态的线程集合，被notify唤醒后重新加入竞争也是进入此队列 _SpinFreq NULL 自旋成功率 _SpinClock 0 自旋时钟 OwnerlsThread 0 表明当前owner原来持有轻量级锁 _previous_owner_tid 0 上一个获取锁的线程id 写个重量级锁mode: 1234567891011121314151617181920212223242526272829public static void main(String[] args)&#123; Object lockObject &#x3D; new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lockObject) &#123; while (true) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (lockObject) &#123; while (true) &#123; &#x2F;&#x2F; ... &#125; &#125; &#125; &#125;).start(); System.out.println(ClassLayout.parseInstance(lockObject).toPrintable());&#125; 打印结果: 阻塞过程monitor对象在轻量级锁膨胀后初始化，并且将状态设置为膨胀中(INFLATING)，在膨胀期间有线程访问直接进入忙等状态。当一个线程尝试获取锁并且获取失败，则将线程封装为ObjectWaiter插入到cxq的队列的队首，进入cxq队列的线程还会再次尝试自旋获取锁，如果还是失败则调用park函数挂起线程。park函数涉及到内核态的切换，因此比较耗时，也是被称为'重'锁的原因。 自旋目的争夺锁失败插入cxq队列后仍然会进行自旋的目的在于，防止同步块中代代码较少、执行比较快的情况下，频繁的park函数调用导致频繁的内核态的切换影响性能。关于自旋次数在JDK1.6之前默认10次，之后版本改成了适应性自旋由JVM自己控制。 防止搁浅当线程获得锁后，会去查询当前是否还有其他线程等待获取锁，如果没有则将_Responsible设置为自身，在进入cxq后自旋仍然没获取锁会再次判断_Responsible是否为自身，如果是则调用有时间限制的park方法，估计是考虑到特殊场景下所有线程都处于阻塞导致没有线程进行释放锁操作，出现搁浅情况。 线程释放当锁被释放后，会从_cxq或_EntryList中挑选一个线程唤醒，被选中的线程为假定继承人赋值给_succ，即使_succ重新加入竞争也不能保证会获取到锁，所以_succ也只能称为假定继承人。 重量级锁工作流程图: 可重入性monitor通过_owner属性判断线程有无权限进入同步代码块，再根据_recursions属性用来记录重入次数，进入临界代码时+1、退出时-1，由此可以保证重入性。 非公平性jvm在唤醒线程时会根据内部参数QMode的值决定使用哪种唤醒策略，可能从_cxq中选取一个，也可能从_EntryList中选取一个，_cxq队列的线程也会因为策略被转移到_EntryList队列的首部或尾部。被选中的线程也不保证能拿到锁，因此synchronized是非公平的。 GC标记如果设置finalize()或许还有一线生机，没设置就等死吧…. 锁降级synchronized是由JVM来实现的，因此锁是否支持降级完全取决于JVM设计者，本文所有技术点均来自HotSpot虚拟机。HotSpot虚拟机在进入安全点的时候，会去检查是否有空闲的monitor，如果有就试图进行降级。在轻量级锁释放锁的时候会将拷贝的markwordCAS修改回去，如果成功，是不是也代表降级为偏向锁了呢？这个问题没有找到答案，以后搞懂了再改。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"多线程(六) 锁分类","slug":"锁分类","date":"2020-03-06T05:00:00.000Z","updated":"2020-10-19T08:17:40.042Z","comments":true,"path":"2020/03/06/锁分类/","link":"","permalink":"http://yoursite.com/2020/03/06/%E9%94%81%E5%88%86%E7%B1%BB/","excerpt":"","text":"前言java中的锁可谓是五花八门，各种锁功能相似又不同，有的是概念、有的是java接口、有的是实现类，让你很难找到明显的分界线去区分并记住他们。所以学习锁首先要打消一种想法，就是一个锁只属于一个分类，比如一个锁可以同时是乐观锁、可重入锁，公平锁，就像一个人可以是男人、程序员、健身爱好者。 synchronized与Lockjava代码中两种加锁方式 一种是用synchronized关键字，另一种是用Lock接口的实现类。形象地说，synchronized关键字是自动档，可以满足一切日常驾驶需求。但是如果你想要玩漂移或者各种骚操作，就需要手动档了——各种Lock的实现类，因为Lock的实现类可以通过设置不同的参数改变锁的作用达到灵活适应场景的作用，而synchronized是关键字，底层有jvm实现，很多参数都是写死的。 悲观锁与乐观锁锁的一种宏观分类方式是悲观锁和乐观锁。悲观锁与乐观锁并不是特指某个锁(Java中没有哪个Lock实现类就叫PessimisticLock或OptimisticLock)，而是在并发情况下的两种不同策略。 悲观锁(Pessimistic Lock)，就是很悲观，每次去拿数据的时候都认为别人会修改。所以每次在拿数据的时候都会上锁，这样别人想拿数据就被挡住，直到悲观锁被释放。比如上面说的synchronized与Lock。 乐观锁(Optimistic Lock), 就是很乐观，每次去拿数据的时候都认为别人不会修改。所以不会上锁，这里的上锁是指互斥性质的上锁，在说明白点就是我加锁了谁也别想碰，除非我释放锁，乐观锁采用的是类似CAS的方式，保证操作数据不会干扰到其他线程。 悲观锁阻塞事务，乐观锁回滚重试，它们各有优缺点，不要认为一种一定好于另一种。像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行重试，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 自旋锁有一种锁叫自旋锁。所谓自旋，说白了就是一个** while(true) ** 无限循环。这个自旋锁与Atomic类的while实现的自旋代码不是一回事，下一章AQS会详细讲 synchronized锁升级前面提到synchronized关键字就像是汽车的自动档。一脚油门踩下去，synchronized会从无锁升级为偏向锁，再升级为轻量级锁，最后升级为重量级锁，就像自动换挡一样。那么自旋锁在哪里呢？这里的轻量级锁就是一种自旋锁。 初次执行到synchronized代码块的时候，锁对象变成偏向锁(通过CAS修改对象头里的锁标志位，说明白点就是锁记住了第一次和他发生关系的线程)，字面意思是“偏向于第一个获得它的线程”的锁，执行完同步代码块后，线程并不会主动释放偏向锁。第二次访问如果还是此线程，那么就没有加锁释放锁这一说，正常执行。 一旦有第二个线程加入锁竞争并发现锁是偏向锁，会去断线程A是否仍然存活。如果线程A仍然存活，将线程A暂停，此时偏向锁升级为轻量级锁，之后线程A继续执行，线程B自旋。但是如果判断结果是线程A不存在了，则线程B持有此偏向锁，锁不升级。 在轻量级锁状态下继续锁竞争，没有抢到锁的线程将自旋，即不停地循环判断锁是否能够被成功获取。获取锁的操作，其实就是通过CAS修改对象头里的锁标志位。先比较当前锁标志位是否为“释放”，如果是则将其设置为“锁定”，比较并设置是原子性发生的。这就算抢到锁了，然后线程将当前锁的持有者信息修改为自己。 自旋锁避免不了的问题就是竞争特别激烈的情况下，其他线程只能在原地空耗CPU，执行不了任何有效的任务，这种现象叫做**忙等(busy-waiting)**。显然，此忙等是有限度的(有个计数器记录自旋次数，默认允许循环10次，可以通过虚拟机参数更改)。如果锁竞争情况严重，某个达到最大自旋次数的线程，会将轻量级锁升级为重量级锁(依然是CAS修改锁标志位，但不修改持有锁的线程ID)。当后续线程尝试获取锁时，发现被占用的锁是重量级锁，则直接将自己挂起(而不是忙等)，等待将来被唤醒。在JDK1.6之前，synchronized直接加重量级锁，很明显现在得到了很好的优化。 可重入锁(递归锁)可重入锁的字面意思是“可以重新进入的锁”，即允许同一个线程多次获取同一把锁。比如一个递归函数里有加锁操作，递归过程中这个锁会阻塞自己吗？如果不会，那么这个锁就是可重入锁(因为这个原因可重入锁也叫做递归锁)。 公平锁、非公平锁如果多个线程申请一把公平锁，那么当锁释放的时候，先申请的先得到，非常公平。显然如果是非公平锁，后申请的线程可能先获取到锁，是随机或者按照其他优先级排序的。 对ReentrantLock类而言，通过构造函数传参可以指定该锁是否是公平锁，默认是非公平锁。一般情况下，非公平锁的吞吐量比公平锁大，如果没有特殊要求，优先使用非公平锁。对于synchronized而言，它也是一种非公平锁，但是并没有任何办法使其变成公平锁。 可中断锁这里的关键是理解什么是中断。Java并没有提供任何直接中断某线程的方法，只提供了中断机制。何谓“中断机制”？线程A向线程B发出“请你停止运行”的请求(线程B也可以自己给自己发送此请求)，但线程B并不会立刻停止运行，而是自行选择合适的时机以自己的方式响应中断，也可以直接忽略此中断。也就是说，Java的中断不能直接终止线程，而是需要被中断的线程自己决定怎么处理。这好比是父母叮嘱在外的子女要注意身体，但子女是否注意身体，怎么注意身体则完全取决于自己。 读写锁、共享锁、互斥锁读写锁其实是一对锁，一个读锁(共享锁)和一个写锁(互斥锁、排他锁)，Java提供了ReadWriteLock接口和实现类ReentrantReadWriteLock来实现读写锁。 读锁：防止读的时候其他线程写，允许读的时候其他线程读 写锁：防止写的时候其他线程读或写 使用锁带来的问题死锁、活锁、饥饿","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(五) CAS","slug":"CAS","date":"2020-03-05T05:00:00.000Z","updated":"2020-10-19T07:53:53.632Z","comments":true,"path":"2020/03/05/CAS/","link":"","permalink":"http://yoursite.com/2020/03/05/CAS/","excerpt":"","text":"什么是CASCAS的全称是Compare and Swap(比较和交换)，是一种特殊的修改数据的方式，线程通过CAS修改数据时整个过程涉及到三个数据：要修改的内存数据V、执行CAS操作前读取V并将V的值复制到工作空间计作A(预期值)、修改后的数据B，执行CAS操作中当且仅当预期值A和内存值V相同时，将内存值V修改为B并返回true，否则视为修改失败返回false。 Atomic对CAS的应用Atomic包是Java.util.concurrent下的另一个专门为线程安全设计的Java包，包含多个原子操作类，我们以AtomicInteger为例看看java如何通过CAS实现原子性。 incrementAndGet方法，以原子方式将当前值增加1并返回增加后的值： 1234public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 我们发现incrementAndGet方法把这个操作委托给unsafe类的getAndAddInt方法处理，我们继续看getAndAddInt方法源码： 123456789101112public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; &#x2F;&#x2F; 读取AtomicInteger在内存中对应的值，并复制一份赋值给var5，作为期望值 var5 &#x3D; this.getIntVolatile(var1, var2); &#x2F;&#x2F; 将AtomicInteger对象引用、偏移量、预期值、修改后的值交给compareAndSwapInt也就是CAS方法循环执行，直到true &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; &#125; 代码中我们可以看到，真正的CAS修改操作是compareAndSwapInt方法，我们继续往下看： 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 到这里的时候我们发现compareAndSwapInt方法是被native修饰的，说明接下来的代码是使用C++实现的了。源码就不贴了，这个方法实际上是利用处理器提供的汇编指令CMPXCHG。当CPU执行此修改指令时发现带有CMPXCHG前缀，那么会采用CAS方式(比较并交换操作数)修改数据，并且保证比较、交换俩个步骤不会被上下文切换打断。当且仅当预期值var4与要修改的内存值相等时，将内存值修改为var5。 如果你细心的话会发现，在多核CPU的操作系统中仅仅保证CAS的俩个步骤不被上下文切换打断没什么卵用，如果俩个线程并行同时对某个AtomicInteger(0)执行incrementAndGet方法，怎么保证高速缓存中取出的期望值不是脏数据？怎么保证多个处理器不会同时执行到CAS的比较操作并且都返回true，继而同时修改内存值为1，最终导致结果应该是2却因为线程安全问题变为1？ 我们回头看看AtomicInteger的其他源码： 12345678910111213141516... private volatile int value; public AtomicInteger(int initialValue) &#123; value &#x3D; initialValue; &#125; public AtomicInteger() &#123; &#125; public final int get() &#123; return value; &#125; ... AtomicInteger内部有个int类型的value属性，代表着自身的值，并且AtomicInteger读写操作都是围绕这个值进行的，并且这个类被volatile修饰的。到这里思路就清晰了，volatile修饰符保证了value值的可见性，线程不会出现读到脏数据的情况。 对于第二种情况百度的资料很少提及，所以也无法确定CPU到底如何解决这个问题。但是我在知乎上看到了俩个感觉还算靠谱的答案。首先被volatile修饰的变量会使用MESI协议确保同一时刻只有一个处理器修改值，并且把其他处理器此值的缓存设为无效，当第二个处理器想要修改值时发现无效，CAS操作失败，返回false，另一个答案则表示当多个处理器同时使用cmpxchg指令(也就是CAS)操作同一个数据时，总线会进行仲裁只有一个处理器执行CAS，其他处理器连比较操作都不会执行，直到上一个处理器执行完毕后总线再次仲裁并选中自己。 第一种答案强调使用MESI的失效机制解决问题，第二种答案则强调将CAS视为一个整体，在执行比较操作的时候就会利用MESI协议将数据修改为M状态。不同的CPU架构可能解决问题的方式也不同，总之CPU保证多处理器并行执行CAS不会出错，Java保证volatile+自旋CAS修改数据的原子性，以后搞懂了再更新。 ABA问题我实在是不想写这个问题，我也想不到ABA会带来什么后果，通过CAS修改数据也想不到啥业务场景需要记录修改了多少次，百度一堆人云亦云此A非彼A瞎鸡吧复制，就是讲不明白此A和彼A到底有啥区别。但是Java在1.5版本引进了AtomicStampedReference类，采用版本号的机制解决这个操蛋的问题。 总结 CAS是典型的乐观派操作，每次都迷之自信认为操作一定成功，但是在高并发比较严重的情况下会导致大量线程不断的循环，增大CPU的消耗。 CAS只能保证单个共享变量的原子操作，如果操作涉及多个共享变量，必须要排他锁解决 仅仅依靠CAS无法保证原子性，必须配合CPU缓存锁一起保证。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(四) volatile关键字","slug":"volatile关键字","date":"2020-03-04T05:00:00.000Z","updated":"2020-10-19T07:53:31.881Z","comments":true,"path":"2020/03/04/volatile关键字/","link":"","permalink":"http://yoursite.com/2020/03/04/volatile%E5%85%B3%E9%94%AE%E5%AD%97/","excerpt":"","text":"概述volatile是Java的一个修饰符，它在多线程编程开发中保证了共享变量的可见性和有序性。相对于各种排他锁，volatile在使用和执行成本上占用资源较少。 实现原理那么volatile如何保证可见性和有序性呢？我们写一段单例模式的java代码： 123456789101112131415161718192021package com.test;public class SingletonObject &#123; &#x2F;&#x2F; 单例对象 private static volatile SingletonObject instance; &#x2F;&#x2F; 获取单例对象方法 public static SingletonObject get()&#123; if(instance &#x3D;&#x3D; null)&#123; instance &#x3D; new SingletonObject(); &#125; return instance; &#125; public static void main(String[] args) &#123; SingletonObject.get(); &#125;&#125; 然后用idea运行main方法并打印汇编代码，jvm参数：-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly-XX:CompileCommand=compileonly,*SingletonObject.get (只打印SingletonObject的get方法) 运行打印结果： 1234567891011121314# &#123;method&#125; &#123;0x0000000128e022b0&#125; &#39;get&#39; &#39;()Lcom&#x2F;test&#x2F;SingletonObject;&#39; in &#39;com&#x2F;test&#x2F;SingletonObject&#39;# [sp+0x40] (sp of caller) 省略代码..... 0x000000010af1fb54: movb $0x0,(%rax,%rsi,1) 0x000000011b6f4e58: lock addl $0x0,(%rsp) ;*putstatic instance ; - com.test.SingletonObject::get@13 (line 12) 省略代码..... 0x000000010af1f701: mov %r12b,(%r11,%r10,1) 0x000000011b6f4a05: lock addl $0x0,(%rsp) ;*putstatic instance ; - com.test.SingletonObject::get@13 (line 12) 省略代码..... 我们可以看到被volatile修饰的共享变量进行写操作的时候，会比普通公共变量的读写操作多一行lock addl $0x0,(%rsp)前缀的代码，lock前缀指令有俩个作用： 使用总线锁或缓存一致性协议来保证数据的可见性。 不是内存屏障却能完成类似内存屏障的功能，阻止屏障两遍的指令重排序保证有序性。 总结volatile的使用场景不是很多，常用在多线程下的状态标记量和双重检查等，也有很多地方配合CAS来实现无锁编程。因为volatile只能保证线程每次拿到的数据是最新的，对于数据的单纯查询没有任何问题(jvm自动保证基本数据类型和引用的取值赋值为原子操作)，但是对于i++、懒汉式单例模式等对变量操作依赖当前值的情况，就显得无能为力。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(三) 生命周期和常用方法","slug":"多线程生命周期和常用方法","date":"2020-03-03T05:00:00.000Z","updated":"2020-11-03T01:42:03.748Z","comments":true,"path":"2020/03/03/多线程生命周期和常用方法/","link":"","permalink":"http://yoursite.com/2020/03/03/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%92%8C%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/","excerpt":"","text":"线程状态以及转化NEW(新建) 使用new创建出线程后，进入新建状态 此时jvm为其分配内存以及其成员变量 除此之外没有任何特征，方法也不会被执行 RUNNABLE(就绪) 调用对象的start()方法，进入就绪状态 此时jvm会为其创建方法调用栈和程序计数器 线程拥有被CPU调度资格，开始疯狂争夺使用权 RUNNING(运行) 抢到CPU使用权时，开始执行run()方法，进入运行状态 线程只有通过start()后争夺到CPU时间片的方式运行run()方法，才可以实现异步执行 如果直接调用run()方法运行，系统会当作普通方法，不会异步执行 BLOCKED(阻塞) 处于运行状态的线程在进入synchronized关键字修饰的方法或代码块时，进入阻塞状态 阻塞的过程就是线程在抢夺锁的过程，因此阻塞是被动的 阻塞在某个锁上的线程，在锁被释放后会主动去争取，争取到锁后回到运行状态，因此脱离阻塞状态是主动的 WAITING(等待) 调用wait()、join()方法时，进入等待状态 因此进入等待状态是主动的，需要有事件主动唤醒 TIMED_WAITING(等待) 调用sleep(long)、wait(long)、join(long)方法时，进入超时等待状态 同等待状态，到达参数指定时间自动唤醒 TERMINATED(终止) run()方法或call()方法运行完毕，线程正常结束 线程执行代码过程中抛出未捕获异常或直接ERROR 调用stop()方法，也是个奇葩的方法，不推荐使用 附加状态转化图： 类型转化。 isAlive()1public final native boolean isAlive(); 判断当前线程是否活着，只有当线程进入RUNNABLE(就绪)或RUNNING(运行)状态才返回true。 sleep(long millis)1public static native void sleep(long millis) throws InterruptedException; Thread的静态方法，使当前线程放弃CPU时间片，在指定时间内不参与CPU竞争，在到达指定时间后变为runnable状态并重新加入CPU竞争。如果当前线程持有锁，在睡眠过程中不会放弃锁的占有权 join(long millis)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&#x2F;&#x2F; 无参方法，调用重载方法传入固定参数0public final void join() throws InterruptedException &#123; join(0);&#125;&#x2F;&#x2F; 支持超时的join方法public final synchronized void join(long millis) throws InterruptedException &#123; &#x2F;&#x2F; 获取当前时间戳 long base &#x3D; System.currentTimeMillis(); &#x2F;&#x2F; 记录已经延迟多久 long now &#x3D; 0; &#x2F;&#x2F; 参数校验，不能小于0 if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; &#x2F;&#x2F; 没有超时限制情况下 if (millis &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 线程只有处于活着状态才进行处理 while (isAlive()) &#123; &#x2F;&#x2F; 这里意味着调用此方法的线程直接被wait方法挂起，没有提供任何notify方法唤醒，只能被动的等待线程运行完毕后死亡 wait(0); &#125; &#125; else &#123; &#x2F;&#x2F; 线程只有处于活着状态才进行处理 while (isAlive()) &#123; &#x2F;&#x2F; 还需要延迟多久 long delay &#x3D; millis - now; &#x2F;&#x2F; 如果已达到延迟时间限制，跳出循环 if (delay &lt;&#x3D; 0) &#123; break; &#125; &#x2F;&#x2F; 挂起进入等待状态 wait(delay); &#x2F;&#x2F; 执行到这里说明等待时间已到，重新计算已经延迟多久了，等待下一次进入while循环调用break now &#x3D; System.currentTimeMillis() - base; &#125; &#125;&#125; 源码可以看出来join是用的wait()实现的，wait方法是object的方法，作用是让调用这个Object.wait()的线程处于等待状态，除非其他线程调用这个Object.notify()唤醒，或者这个Object死亡阻塞状态才会变成可运行状态，如果join方法带参数，那就等到参数时间结束自动唤醒自己。 如果在一个线程执行中创建另外一个线程并使用join()，那么主线程会被挂起，等待子线程执行完在继续往下执行。说白了和执行过程中调用另一个方法没什么区别，无非就是有个超时时间限制，超过时间限制主线程就取消等待继续执行。使用isAlive()进行判断，也就意味着线程如果没有进入RUNNABLE(就绪)或RUNNING(运行)状态，join方法不会起任何作用。 join其实合理理解成是线程合并，当在一个线程调用另一个线程的join方法时，当前线程阻塞等待被调用join方法的线程执行完毕才能继续执行，所以join的好处能够保证线程的执行顺序，但是如果调用线程的join方法其实已经失去了并行的意义，虽然存在多个线程，但是本质上还是串行的，最后join的实现其实是基于等待通知机制(wait+notify)的。 yield()1public static native void yield(); Thread的静态方法，暂停当前正在执行的线程对象，并执行其他线程。被暂停的线程会让出CPU的使用权给其他线程获得运行机会，自身转化为RUNNABLE(就绪)状态，但是这么做并不一定能达到让出CPU资源的目的，因为让出CPU使用权的时候，自身回到可运行状态与其他同优先级线程一起再去竞争CPU时间片，如果这个线程是个欧皇还会被再次选中，出现这种情况也就意味着此次yield()方法并没有任何效果。 目前想不到什么应用场景，如果一个线程的优先级特别低，执行内容也不是很重要，又怕他被CPU调度的次数多，可以适当的调用此方法减少执行的次数，把CPU资源给其他重要的线程工作。 interrupt()1234567891011121314151617public void interrupt() &#123; &#x2F;&#x2F;如果调用中断的是线程自身，则不需要进行安全性判断 if (this !&#x3D; Thread.currentThread()) checkAccess(); &#x2F;&#x2F; synchronized (blockerLock) &#123; Interruptible b &#x3D; blocker; if (b !&#x3D; null) &#123; interrupt0(); &#x2F;&#x2F; 只是设置中断标志 b.interrupt(this); return; &#125; &#125; interrupt0();&#125; 每个线程内部都维护了一个中断标志(默认false)，调用线程的interrupt()方法时会根据当前线程的中断标志和阻塞情况，判断是否需要抛出异常： 如果中断标志为false，且没有被阻塞，修改中断标志为true。 如果中断标志为true，此时调用wait、sleep、join方法时会抛出InterruptedException异常，恢复中断标志为false。 如果已经被wait、sleep、join方法阻塞，调用interrupt()会抛出InterruptedException异常，恢复中断标志为false。 这里提到的阻塞，只是因为wait、sleep、join方法导致线程被堵住无法继续执行，并不是线程七大状态的BLOCKED(阻塞)状态。BLOCKED(阻塞)状态只由synchronized导致，而且不能被打断，相同的，IO阻塞也不能被打断。 由此可以看出来interrupt()方法中断的不是线程的运行，而是中断线程的阻塞状态，并且采用抛异常的方式引起线程的注意，被中断线程可以通过try catch方式自己决定如何应对中断信号。 比如使用kafka采用while(true)的方式消费数据时，又希望在某个时刻终止这个线程，并且终止过程中要保证此刻正在处理的那条消息处理完毕后才能终止，可以采用interrupt()方法+wait、sleep、join的一种来实现： 1234567891011121314151617181920212223242526272829303132public void run()&#123; &#x2F;&#x2F; 创建消费者 Properties props &#x3D; createProperties(&quot;localhost:9092&quot;, &quot;groups&quot;); props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;); KafkaConsumer&lt;String, String&gt; consumer &#x3D; new KafkaConsumer&lt;&gt;(props); &#x2F;&#x2F; 设置消费topic consumer.subscribe(Arrays.asList(&quot;topic-name&quot;)); while (true) &#123; &#x2F;&#x2F; 每次拉取消息 ConsumerRecords&lt;String, String&gt; records &#x3D; consumer.poll(100); &#x2F;&#x2F; 循环处理 for (ConsumerRecord&lt;String, String&gt; record : records) &#123; &#x2F;&#x2F; 消费逻辑.. &#x2F;&#x2F; wait或sleep或join阻塞1毫秒，试探线程有没有被中断 try &#123; Thread.wait(1); &#125; catch (InterruptedException e) &#123; &#x2F;&#x2F; 关闭消费者对象 consumer.close(); return; &#125; &#125; &#125;&#125; stop()强制终止线程的运行，并立即释放掉此线程持有的锁，这些锁可能用来维护数据一致性的，所以此方法被废弃。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(二) 并发编程三大特性","slug":"并发编程三大特性","date":"2020-03-02T05:00:00.000Z","updated":"2020-10-19T07:51:20.861Z","comments":true,"path":"2020/03/02/并发编程三大特性/","link":"","permalink":"http://yoursite.com/2020/03/02/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B8%89%E5%A4%A7%E7%89%B9%E6%80%A7/","excerpt":"","text":"CPU读写内存数据计算机中程序的执行，本质上是线程指令在CPU处理器上的执行，并且在执行必然牵涉到数据的读和写，程序运行过程的临时数据都是存放在主内存(RAM)中，因此CPU在处理数据的时候也必然牵涉到和主内存的交互。处理器访问内存时，需要先获取内存总线的控制权，任何时刻只能有一个处理器获得内存总线的控制权，可以理解为同一时刻某个内存地址只可能被一个处理器访问。 随着硬件技术的不断发展，现在的CPU处理速度已经远远超过主内存的访问速度，如果任何时候对数据的操作都要和内存进行交互，会大大降低指令的执行速度，因此就有了CPU高速缓存： 高速缓存的产生大大减少了CPU直接访问主内存的频率，也减少了内存访问速度对CPU的拖累，提高了CPU的执行效率。如果是单核CPU的操作系统中，只有一个高速缓存，没有任何问题。但是在多核CPU的操作系统中，每个处理器都有自己的高速缓存，就带来了缓存一致性问题。 比如i++操作，编译成指令后大概有三步骤：1.将i=0从主内存复制到2.对i进行加1运算3.将运算后的值刷回 在多线程编程情况下，如果我们不做任何措施，会导致运行结果与预期不一致： 对此，早期的解决方案是总线加锁，一个处理器在总线上输出LOCK#信号，使得其他处理器对内存的操作请求都会被阻塞，该处理器独占共享内存。方法简单粗暴，就是锁定范围太大(整个共享内存)，导致CPU利用率急剧下降。 为了解决总线锁开销过大问题，CPU提出了缓存一致性解决方案，主要有Directory协议、Snoopy协议、MESI协议。这个说下MESI协议，这个协议只会对高速缓存中的某个数据加锁(如果数据不在缓存中，还是会总线加锁)，不会影响到内存中其他数据的读写。MESI协议将数据划分为四种状态，通过总线嗅探机制让所有处理器监听数据状态的变化，缓存一致的目的。 我们重点关注一下修改缓存数据的情况，对于E状态的数据，只有自己在读，可以直接把数据设置为M状态，对于S状态的数据，说明有多个处理器在读，必须将其他处理器对此数据的缓存作废，然后才能把数据的状态设置为M。当其他处理器发现自己的缓存是I状态时，就去主内存再次读取，而MESI协议保证其他处理器去主内存读取此数据前，将修改后的数据从高速缓存刷回主内存，并把数据状态改为E。 高并发情况下可能出现俩个处理器同时修改变量，并同时向总线发出将各自的缓存行更改为M状态的情况，此时总线会采取裁决机制进行裁决，将其中一个置为M状态，另一个置为I状态，且I状态的缓存行修改无效。 原子性原子性操作是指一个或多个操作，要么全部执行且在执行过程中不被任何因素打断，要么全部不执行。并且针对某个值的原子操作在被执行的过程中，CPU绝不会再去进行其他的针对该值的操作 java作为一门高级语言，一个可执行线程会被编译成多条指令序列交由CPU执行，既然是多条指令，在执行过程中就存在被上下文切换打断的可能。在多线程编程中如果有的操作不具有原子性，会导致运行结果与预期的不一致，比如i++操作： CPU如何保证原子性？首先，处理器自动保证单条指令、基本内存操作的原子性，因此中断只会发生在指令之间。在单核CPU中保证操作原子性非常简单，只要禁止CPU在原子操作过程中发生上下文切换，那么就可以保证多线程对某个公共变量的多步骤操作都是串行的。嗯，有点线程安全的味道了。到了多核CPU时代，仅仅保证原子操作的执行不被CPU打断已经没什么卵用了，因为多个线程可以并行执行修改一个公共变量，线程之间又出现了干扰。对此，CPU又提出了CAS来解决这个问题(CAS下一章会讲)。 Java自带的原子性操作： 基本数据类型的赋值(long、double无法保证) 所有引用类型的赋值 synchronized关键字(采用jvm的monitor，monitor底层采用CPU的CAS) Lock相关类(采用aqs，aqs底层采用CPU的CAS) java.concurrent.Atomic包下所有类(采用CPU的CAS) 注:CPU和Java(内存读写)的原子性与数据库的原子性还是有区别的，CPU和Java(内存读写)执行原子操作过程中发生中断的唯一可能就是断电，这时候所有内存数据全部消失，也就没讨论的意义了。而数据库的增删改操作涉及的都是持久化的磁盘数据，就算执行过程发生断电，持久化的数据仍然存在，因此数据库的原子操作增加了事务回滚概念，只要事务没提交，就相当于没执行。无论CPU还是Java还是数据库，都是强调整体的成败，不允许仅执行部分操作的存在。 可见性可见性是指一个线程对共享变量的修改，其他线程可以立即感知到这个变化 可见性问题主要发生在多核CPU的场景中，如果线程对数据的读取都是通过内存实现，不会有任何可见性问题，因为上面说过某个内存地址任何时刻只会被一个处理器访问，但是高速缓存的诞生打破了这个规则，如果高速缓存中存在就从缓存访问，这就意味着某个内存数据可以被多个处理器同时访问。处理器对数据的修改在没有做任何措施的情况下，不会及时通知到其他处理器的缓存，这就导致其他处理器的数据是脏数据。比如i++操作： CPU如何保证可见性？这个很明显了，MESI缓存一致协议。 Java自带的可见性操作： volatile关键字(采用MESI协议保证，如果数据不在缓存中就用总线锁) synchronized关键字(同一时刻就一个线程操作，还有啥不可见的) Lock相关类(跟synchronized一个套路) 有序性有序性是指程序按照写代码的顺序执行 处理器和编译器为了提高程序运行效率，可能会对输入代码进行优化，并且不保证程序中各个语句的执行先后顺序同代码中的顺序一致。当然，CPU和编译器是在遵循as-if-serial语意的前提下对指令重排，而不是随意重排。首先CPU保证调度线程过程中，单线程的执行结果不会受指令重排影响导致结果不一致，编译器保证编译过程中不会对有依赖关系的数据进行指令重排。由此看出多线程情况下还是会有问题： CPU如何保证有序性？处理器主要通过内存屏障机制来解决有序性问题，如果不想让它重排，在两条指令中间加一道屏障。拿X86平台来说，有几种主要的内存屏障： lfence，是一种Load Barrier(读屏障)，在lfence指令前的所有读操作当必须在lfence指令后的所有读操作前完成 sfence, 是一种Store Barrier(写屏障)，在sfence指令前的所有写操作当必须在sfence指令后的所有写操作前完成 mfence, 是一种General Barrier(通用屏障)，在mfence指令前的所有读写操作当必须在mfence指令后的所有读写操作前完成 除了内存屏障，也可以使用原子指令，如x86上的”lock…”前缀 Java自带的有序性操作： volatile关键字(内存屏障) synchronized关键字(单线程操作，as-if-serial语意自动保证) Lock相关类(单线程操作，as-if-serial语意自动保证) 总结原子性、可见性、有序性问题是一切线程安全问题的根源，单纯的保证操作具有某一种特性只能解决某一部分场景问题。Java提供了很多类以及修饰符，提供了不同维度的保证，底层也都是封装CPU提供的措施来实现。","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"多线程(一) 基本概念","slug":"多线程基本概念","date":"2020-03-01T05:00:00.000Z","updated":"2020-10-19T07:50:50.872Z","comments":true,"path":"2020/03/01/多线程基本概念/","link":"","permalink":"http://yoursite.com/2020/03/01/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","excerpt":"","text":"进程操作系统进行资源分配和调度的基本单位，每一个进程都是一个应用程序的执行实例，比如我们启动的一个java项目就是一个jvm进程，操作系统为jvm分配运行内存等资源，进程中包含一个或多个线程，线程之间共享进程的资源(比如堆、栈、方法区等)。 线程CPU运行的最小单位，线程之间共享进程的资源，也有自己的私有空间，比如虚拟机栈、本地方法栈、程序计数器。 进程上下文切换线程上下文切换CPU通过分配时间片来执行任务，当一个任务的时间片用完，就会切换到另一个任务。在切换之前会保存上一个任务的状态，当下次再切换到该任务，就会加载这个状态，任务从保存到再加载的过程就是一次上下文切换。 切出：一个线程被剥夺处理器的使用权而被暂停运行 切入：一个线程被系统选中占用处理器开始或继续运行 线程的上下文是什么？对于CPU来说一个线程就是多条指令集合，线程的运行实质上是多条指令在CPU上的运行，而上下文是指线程私有空间的内容。比如虚拟机栈、本地方法栈保存了某一时刻线程局部变量的值，程序计数器保存了线程此刻执行到哪一条指令的位置。 导致上下文切换的原因？ CPU分配的时间片用完了 有个优先级更高的线程需要被执行 手动操作比如java线程的sleep、yield、wait、join、synchronized、lock等 读取数据库操作由于数据量较大引起IO阻塞,线程会被挂起直到读取完毕再次回归等待被CPU调度 上下文切换的过程？放发生切换的时候，CPU会把被挂起线程的上下文保存在程序计数器和寄存器中，程序计数器存储正在执行的指令序列的位置、寄存器存储工作变量，然后从高速缓存中清除掉被挂起线程的上下文，去加载新线程的上下文到高速缓存中。因此线程上下文的切换需要消耗CPU的资源。 并发与并行单CPU操作系统中多个线程同时运行，实质上是交替占有CPU使用权的过程，同时运行只是CPU处理过快造成的错觉，这种现象可以称作为线程并发运行。 到了多CPU时代才实现真正意义上的多线程同时运行，比如4颗CPU的操作系统可以做到4个线程的同时运行，但是操作系统中可能有很多线程需要被执行，比如有16个线程在运行，那么平均4个线程仍然要争夺一个CPU的使用权，只是同一时刻必然有4个争夺到使用权，这种现象称作为线程并行运行。 由此可以看出，操作系统中CPU的数量对多线程编程非常重要。因此项目开发中要尽量参考所在服务器的CPU配置，作出适当的线程池参数以避免频繁的上下文切换带来的性能损耗。同样在选取机器配置上尽量考虑放置服务的线程特点，比如存放redis服务选用多处理器的CPU没有任何意义，redis永远只在一个处理器上面运行。 线程安全线程安全问题","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}],"tags":[]},{"title":"IO流(一) 字节流","slug":"字节流","date":"2020-02-01T05:00:00.000Z","updated":"2020-10-19T08:22:23.656Z","comments":true,"path":"2020/02/01/字节流/","link":"","permalink":"http://yoursite.com/2020/02/01/%E5%AD%97%E8%8A%82%E6%B5%81/","excerpt":"","text":"啊锁啊锁大","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"IO流","slug":"java基础/IO流","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/IO%E6%B5%81/"}],"tags":[]},{"title":"集合(一) HashMap","slug":"HashMap","date":"2020-01-01T05:00:00.000Z","updated":"2020-10-19T08:22:41.428Z","comments":true,"path":"2020/01/01/HashMap/","link":"","permalink":"http://yoursite.com/2020/01/01/HashMap/","excerpt":"","text":"啊锁啊锁大","categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"集合","slug":"java基础/集合","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E9%9B%86%E5%90%88/"}],"tags":[]}],"categories":[{"name":"java基础","slug":"java基础","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/"},{"name":"多线程","slug":"java基础/多线程","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"IO流","slug":"java基础/IO流","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/IO%E6%B5%81/"},{"name":"集合","slug":"java基础/集合","permalink":"http://yoursite.com/categories/java%E5%9F%BA%E7%A1%80/%E9%9B%86%E5%90%88/"}],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"http://yoursite.com/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]}